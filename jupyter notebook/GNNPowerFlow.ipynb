{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Dm_QSMHnh5qa",
        "jkFs_7lLiDgc",
        "4sIrVikD1cFX",
        "FlVgf3zs8X7G"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEZO9Oc5ifIT",
        "outputId": "30af16d7-e1bb-4261-d504-9b2de2c5662d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'GNN-OptimalPowerFlow' already exists and is not an empty directory.\n",
            "/content/GNN-OptimalPowerFlow/GNN-OptimalPowerFlow/GNN-OptimalPowerFlow\n",
            " Datasets   document  'jupyter notebook'   README.md\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clone GitHub repository\n",
        "!git clone https://github.com/Amirtalebi83/GNN-OptimalPowerFlow.git\n",
        "%cd GNN-OptimalPowerFlow\n",
        "\n",
        "# Check the contents of the cloned repo\n",
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch and PyTorch Geometric\n",
        "!pip install torch\n",
        "!pip install torch-geometric\n",
        "!pip install pandas openpyxl  # For data handling\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFKnT4mUkcMj",
        "outputId": "b61a2d26-755a-4802-aed8-f4f8c898be3d"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset --hard HEAD #Reset Any Local Changes:\n",
        "!git pull origin main #Pull the Latest Changes from GitHub:"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC2cAxHHyg27",
        "outputId": "c5ab2155-209a-4fe0-9531-ba794dee9d0d"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HEAD is now at 977e02c FS\n",
            "From https://github.com/Amirtalebi83/GNN-OptimalPowerFlow\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content #Remove the local folder and cloning the repository again:\n",
        "!rm -rf GNN-OptimalPowerFlow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQropCnvyrhy",
        "outputId": "0b6ab068-69a9-49b7-d689-5d652be6d10c"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content #Remove the local folder and cloning the repository again:'\n",
            "/content\n",
            "Cloning into 'GNN-OptimalPowerFlow'...\n",
            "remote: Enumerating objects: 245, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (57/57), done.\u001b[K\n",
            "remote: Total 245 (delta 23), reused 68 (delta 17), pack-reused 168 (from 1)\u001b[K\n",
            "Receiving objects: 100% (245/245), 149.75 MiB | 38.58 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Amirtalebi83/GNN-OptimalPowerFlow.git\n",
        "!ls -la GNN-OptimalPowerFlow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L92XdvEc0BQx",
        "outputId": "18b1fcd4-b78d-4898-df79-4844c5df9234"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 36\n",
            "drwxr-xr-x 6 root root  4096 Nov 14 03:55  .\n",
            "drwxr-xr-x 7 root root  4096 Nov 14 03:55  ..\n",
            "drwxr-xr-x 5 root root  4096 Nov 14 03:55  Datasets\n",
            "drwxr-xr-x 2 root root  4096 Nov 14 03:55  document\n",
            "drwxr-xr-x 8 root root  4096 Nov 14 03:55  .git\n",
            "drwxr-xr-x 2 root root  4096 Nov 14 03:55 'jupyter notebook'\n",
            "-rw-r--r-- 1 root root 10321 Nov 14 03:55  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z9b3fjl7z_Vj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PAXH3kw-lhBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_geometric.nn import GCNConv, GraphConv, SAGEConv, GATConv, ChebConv\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set print options for better readability\n",
        "np.set_printoptions(precision=5, suppress=True)\n",
        "torch.set_printoptions(precision=5, sci_mode=False)\n"
      ],
      "metadata": {
        "id": "baBqQiLOjL_U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandapower"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d_kPAYJLXfp",
        "outputId": "03c16fcc-94dd-4204-992d-7e24d2289630"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandapower\n",
            "  Downloading pandapower-2.14.11.zip (13.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (2.2.2)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from pandapower) (3.4.2)\n",
            "Requirement already satisfied: scipy<1.14 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pandapower) (24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pandapower) (4.66.6)\n",
            "Collecting deepdiff (from pandapower)\n",
            "  Downloading deepdiff-8.0.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Collecting orderly-set==5.2.2 (from deepdiff->pandapower)\n",
            "  Downloading orderly_set-5.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->pandapower) (1.16.0)\n",
            "Downloading deepdiff-8.0.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orderly_set-5.2.2-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: pandapower\n",
            "  Building wheel for pandapower (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandapower: filename=pandapower-2.14.11-py3-none-any.whl size=13131028 sha256=b0ec6f7d186e622ddc601d70000c7ef6de5f29dc0fbd60bb201ca63f319ee2cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/de/5a/7b00f385eb06d1fb1f7c1cd06f9bb901709c038d3899548cf1\n",
            "Successfully built pandapower\n",
            "Installing collected packages: orderly-set, deepdiff, pandapower\n",
            "Successfully installed deepdiff-8.0.1 orderly-set-5.2.2 pandapower-2.14.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Preparation**"
      ],
      "metadata": {
        "id": "NBWjoAqRoHaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data, DataLoader"
      ],
      "metadata": {
        "id": "xKA8rxaeLOzQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import is_\n",
        "def slice_dataset(dataset, percentage):\n",
        "    data_size = len(dataset)\n",
        "    return dataset[:int(data_size * percentage / 100)]\n",
        "\n",
        "def make_dataset(dataset, n_bus):\n",
        "    x_raw, y_raw = [], []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        x_sample, y_sample = [], []\n",
        "        for n in range(n_bus):\n",
        "            # Define bus type: Slack (1), PQ (2), PV (3)\n",
        "            is_pv = 0\n",
        "            is_pq = 0\n",
        "            is_slack = 0\n",
        "            if n == 0:  # Slack bus is always bus 0\n",
        "                is_slack = 1\n",
        "            elif dataset[i, 4 * n + 2] == 0:  # Q = 0 indicates PV bus\n",
        "                is_pv = 1\n",
        "            else:\n",
        "                is_pq = 1  # PQ bus\n",
        "\n",
        "            # Include P, Q, V, delta, and bus type as features\n",
        "            x_sample.append([\n",
        "                dataset[i, 4 * n + 1],  # P\n",
        "                dataset[i, 4 * n + 2],  # Q\n",
        "                dataset[i, 4 * n + 3],  # V\n",
        "                dataset[i, 4 * n + 4],  # delta\n",
        "                is_pv,                # Bus type\n",
        "                is_pq,\n",
        "                is_slack\n",
        "            ])\n",
        "\n",
        "            # Use P and Q as targets\n",
        "            y_sample.append([\n",
        "                dataset[i, 4 * n + 1],  # P (target)\n",
        "                dataset[i, 4 * n + 2],   # Q (target)\n",
        "                # dataset[i, 4 * n + 3],   # V (target)\n",
        "                # dataset[i, 4 * n + 4]   # D (target)\n",
        "            ])\n",
        "\n",
        "        x_raw.append(x_sample)\n",
        "        y_raw.append(y_sample)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    x_raw = torch.tensor(x_raw, dtype=torch.float)\n",
        "    y_raw = torch.tensor(y_raw, dtype=torch.float)\n",
        "    return x_raw, y_raw\n"
      ],
      "metadata": {
        "id": "xqY7cbqkngcS"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_dataset(x, y):\n",
        "    # Compute mean and standard deviation for features and targets\n",
        "    x_mean, x_std = torch.mean(x, 0), torch.std(x, 0)\n",
        "    y_mean, y_std = torch.mean(y, 0), torch.std(y, 0)\n",
        "\n",
        "    # Handle zero standard deviation to avoid division by zero\n",
        "    x_std[x_std == 0] = 1\n",
        "    y_std[y_std == 0] = 1\n",
        "\n",
        "    # Normalize the input features except for the bus type\n",
        "    # Bus type (5th feature) should not be normalized as it is categorical (1, 2, or 3)\n",
        "    x_norm = (x - x_mean) / x_std\n",
        "    x_norm[:, :, 4] = x[:, :, 4]  # Preserve bus type without normalization\n",
        "\n",
        "    # Normalize the targets\n",
        "    y_norm = (y - y_mean) / y_std\n",
        "\n",
        "    return x_norm, y_norm, x_mean, y_mean, x_std, y_std\n",
        "\n",
        "def denormalize_output(y_norm, y_mean, y_std):\n",
        "    return y_norm * y_std + y_mean\n",
        "\n",
        "def MSE(yhat, y):\n",
        "    return torch.mean((yhat - y) ** 2)\n"
      ],
      "metadata": {
        "id": "IHHpynA4oRtO"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "Ng5F0c6T1AeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "def slice_dataset(dataset, percentage):\n",
        "    data_size = len(dataset)\n",
        "    return dataset[:int(data_size * percentage / 100)]\n",
        "\n",
        "def make_dataset(dataset, n_bus):\n",
        "    x_raw, y_raw, mask = [], [], []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        x_sample, y_sample, mask_sample = [], [], []\n",
        "        for n in range(n_bus):\n",
        "            # Use P, Q, V, and delta as input features\n",
        "            P = dataset[i, 4 * n + 1]\n",
        "            Q = dataset[i, 4 * n + 2]\n",
        "            V = dataset[i, 4 * n + 3]\n",
        "            delta = dataset[i, 4 * n + 4]\n",
        "\n",
        "            # Append input features\n",
        "            x_sample.append([P, Q, V, delta])\n",
        "\n",
        "            # Use P and Q as targets\n",
        "            y_sample.extend([P, Q])\n",
        "\n",
        "            # Create mask (0 if feature is constant, 1 otherwise)\n",
        "            mask_sample.append([1 if P != 0 else 0,\n",
        "                                1 if Q != 0 else 0,\n",
        "                                1 if V != 0 else 0,\n",
        "                                1 if delta != 0 else 0])\n",
        "\n",
        "            #x_sample.append([\n",
        "            #    dataset[i, 4 * n + 1],  # P\n",
        "            #    dataset[i, 4 * n + 2],  # Q\n",
        "            #    dataset[i, 4 * n + 3],  # V\n",
        "            #    dataset[i, 4 * n + 4]   # delta\n",
        "            #])\n",
        "\n",
        "            ## Use P and Q as targets\n",
        "            #y_sample.extend([\n",
        "            #    dataset[i, 4 * n + 1],  # P (target)\n",
        "            #    dataset[i, 4 * n + 2]   # Q (target)\n",
        "            #])\n",
        "\n",
        "        x_raw.append(x_sample)\n",
        "        y_raw.append(y_sample)\n",
        "        mask.append(mask_sample)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    x_raw = torch.tensor(x_raw, dtype=torch.float)\n",
        "    y_raw = torch.tensor(y_raw, dtype=torch.float)\n",
        "    mask = torch.tensor(mask, dtype=torch.float)\n",
        "\n",
        "    return x_raw, y_raw, mask\n",
        "\n",
        "def normalize_dataset(x, y):\n",
        "    x_mean, x_std = torch.mean(x, 0), torch.std(x, 0)\n",
        "    y_mean, y_std = torch.mean(y, 0), torch.std(y, 0)\n",
        "\n",
        "    # Handle zero standard deviation\n",
        "    x_std[x_std == 0] = 1  # Avoid division by zero\n",
        "    y_std[y_std == 0] = 1  # Avoid division by zero\n",
        "\n",
        "    x_norm = (x - x_mean) / x_std\n",
        "    y_norm = (y - y_mean) / y_std\n",
        "    return x_norm, y_norm, x_mean, y_mean, x_std, y_std\n",
        "\n",
        "def denormalize_output(y_norm, y_mean, y_std):\n",
        "    return y_norm * y_std + y_mean\n",
        "\n",
        "def MSE(yhat, y):\n",
        "    return torch.mean((yhat - y) ** 2)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "CRoUAOdUji6k",
        "outputId": "a9ab4a06-9048-4a4b-a8ef-d3765b6e8785"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-41-fc4ebabb7b91>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-fc4ebabb7b91>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset**"
      ],
      "metadata": {
        "id": "5ESaGHxvmHAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **14 Bus Only**"
      ],
      "metadata": {
        "id": "Dm_QSMHnh5qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import torch\n",
        "\n",
        "# Load dataset from Excel files\n",
        "dataset1 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/14Bus/PF_Dataset_1.xlsx').values\n",
        "dataset2 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/14Bus/PF_Dataset_2.xlsx').values\n",
        "\n",
        "# Split the dataset\n",
        "train_percentage = 80\n",
        "val_percentage = 20\n",
        "\n",
        "train_dataset = slice_dataset(dataset1, train_percentage)\n",
        "val_dataset = slice_dataset(dataset2, val_percentage)\n",
        "\n",
        "n_bus = 14\n",
        "\n",
        "# Prepare training and validation data\n",
        "x_raw_train, y_raw_train = make_dataset(train_dataset, n_bus)\n",
        "x_raw_val, y_raw_val = make_dataset(val_dataset, n_bus)\n",
        "\n",
        "# Normalize the data\n",
        "x_norm_train, y_norm_train, _, _, _, _ = normalize_dataset(x_raw_train, y_raw_train)\n",
        "x_norm_val, y_norm_val, x_val_mean, y_val_mean, x_val_std, y_val_std = normalize_dataset(x_raw_val, y_raw_val)\n",
        "\n",
        "# Prepare DataLoader for PyTorch Geometric\n",
        "# Load the IEEE 14-bus test case\n",
        "net = nw.case14()\n",
        "nw.case14()\n",
        "\n",
        "# Get the 'from_bus' and 'to_bus' for each line in the network\n",
        "from_buses = net.line['from_bus'].values\n",
        "to_buses = net.line['to_bus'].values\n",
        "\n",
        "# Construct the edge index (bidirectional edges)\n",
        "edge_index = torch.tensor([list(from_buses) + list(to_buses), list(to_buses) + list(from_buses)], dtype=torch.long)\n",
        "\n",
        "print(\"Edge Index for IEEE 14-bus System:\")\n",
        "print(edge_index)\n",
        "\n",
        "# edge_index = torch.tensor([[0, 1, 1, 2, 1, 3, 2, 4, 3, 5, 4, 6, 4, 7, 5, 8, 5, 9, 1, 10, 10, 11, 11, 12, 11, 13],\n",
        "#                           [1, 0, 2, 1, 3, 1, 4, 2, 5, 3, 6, 4, 7, 4, 8, 5, 9, 5, 10, 1, 11, 10, 12, 11, 13, 11]], dtype=torch.long)\n",
        "\n",
        "# Create Data objects for PyTorch Geometric\n",
        "train_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_train, y_norm_train)]\n",
        "val_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_val, y_norm_val)]\n",
        "\n",
        "train_loader = DataLoader(train_data_list, batch_size=1)\n",
        "val_loader = DataLoader(val_data_list, batch_size=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxr4mBoojyA-",
        "outputId": "979a6c06-2d94-4c44-b0c8-9d730d7f81d2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge Index for IEEE 14-bus System:\n",
            "tensor([[ 0,  0,  1,  1,  1,  2,  3,  5,  5,  5,  8,  8,  9, 11, 12,  1,  4,  2,\n",
            "          3,  4,  3,  4, 10, 11, 12,  9, 13, 10, 12, 13],\n",
            "        [ 1,  4,  2,  3,  4,  3,  4, 10, 11, 12,  9, 13, 10, 12, 13,  0,  0,  1,\n",
            "          1,  1,  2,  3,  5,  5,  5,  8,  8,  9, 11, 12]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **30 Bus Only**\n",
        "\n",
        "1. **Data Preparation:** Load and filter the dataset\n",
        "\n",
        "2. **Normalization:**\n",
        "Normalize the data (normalize_dataset)\n",
        "\n",
        "3. **Filter Constant Features:** Identify and remove constant features"
      ],
      "metadata": {
        "id": "duxl-KR0h-yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_raw_train.shape)\n",
        "print(y_norm_train.shape)\n",
        "\n",
        "print(x_raw_train.shape)\n",
        "print(x_norm_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtCPIW4MyITc",
        "outputId": "b7c11861-f449-4afe-ba0b-3f3d6f57d055"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1600, 30, 2])\n",
            "torch.Size([1600, 30, 2])\n",
            "torch.Size([1600, 30, 7])\n",
            "torch.Size([1600, 30, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# Load dataset from Excel files\n",
        "dataset1 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/30Bus/PF_Dataset_1.xlsx').values\n",
        "dataset2 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/30Bus/PF_Dataset_2.xlsx').values\n",
        "\n",
        "# Split the dataset\n",
        "train_percentage = 80\n",
        "val_percentage = 20\n",
        "\n",
        "train_dataset = slice_dataset(dataset1, train_percentage)\n",
        "val_dataset = slice_dataset(dataset2, val_percentage)\n",
        "\n",
        "n_bus = 30\n",
        "\n",
        "# # Prepare training and validation data\n",
        "x_raw_train, y_raw_train = make_dataset(train_dataset, n_bus)\n",
        "x_raw_val, y_raw_val = make_dataset(val_dataset, n_bus)\n",
        "\n",
        "# Normalize the raw data\n",
        "x_norm_train, y_norm_train, x_train_mean, y_train_mean, x_train_std, y_train_std = normalize_dataset(x_raw_train, y_raw_train)\n",
        "x_norm_val, y_norm_val, x_val_mean, y_val_mean, x_val_std, y_val_std = normalize_dataset(x_raw_val, y_raw_val)\n",
        "\n",
        "# Prepare DataLoader for PyTorch Geometric\n",
        "# Load the IEEE 30-bus test case using pandapower\n",
        "net = nw.case30()\n",
        "\n",
        "# Get the 'from_bus' and 'to_bus' for each line in the network\n",
        "from_buses = net.line['from_bus'].values\n",
        "to_buses = net.line['to_bus'].values\n",
        "\n",
        "# Construct the edge index (bidirectional edges)\n",
        "edge_index = torch.tensor([list(from_buses) + list(to_buses), list(to_buses) + list(from_buses)], dtype=torch.long)\n",
        "\n",
        "print(\"Edge Index for IEEE 30-bus System:\")\n",
        "print(edge_index)\n",
        "\n",
        "# Create Data objects for PyTorch Geometric without mask\n",
        "train_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_train, y_norm_train)]\n",
        "val_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_val, y_norm_val)]\n",
        "\n",
        "# Prepare DataLoaders\n",
        "train_loader = DataLoader(train_data_list, batch_size=1)\n",
        "val_loader = DataLoader(val_data_list, batch_size=1)\n",
        "\n",
        "print(\"Data preparation completed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaQbb0UuLiUa",
        "outputId": "62741143-d868-4356-f62d-95151fd0bb26"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge Index for IEEE 30-bus System:\n",
            "tensor([[ 0,  0,  1,  2,  1,  1,  3,  4,  5,  5,  5,  5,  8,  8,  3, 11, 11, 11,\n",
            "         11, 13, 15, 14, 17, 18,  9,  9,  9,  9, 20, 14, 21, 22, 23, 24, 24, 27,\n",
            "         26, 26, 28,  7,  5,  1,  2,  3,  3,  4,  5,  5,  6,  6,  7,  8,  9, 10,\n",
            "          9, 11, 12, 13, 14, 15, 14, 16, 17, 18, 19, 19, 16, 20, 21, 21, 22, 23,\n",
            "         23, 24, 25, 26, 26, 28, 29, 29, 27, 27],\n",
            "        [ 1,  2,  3,  3,  4,  5,  5,  6,  6,  7,  8,  9, 10,  9, 11, 12, 13, 14,\n",
            "         15, 14, 16, 17, 18, 19, 19, 16, 20, 21, 21, 22, 23, 23, 24, 25, 26, 26,\n",
            "         28, 29, 29, 27, 27,  0,  0,  1,  2,  1,  1,  3,  4,  5,  5,  5,  5,  8,\n",
            "          8,  3, 11, 11, 11, 11, 13, 15, 14, 17, 18,  9,  9,  9,  9, 20, 14, 21,\n",
            "         22, 23, 24, 24, 27, 26, 26, 28,  7,  5]])\n",
            "Data preparation completed successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "RP6v7qQi0qnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# Load dataset from Excel files\n",
        "dataset1 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/30Bus/PF_Dataset_1.xlsx').values\n",
        "dataset2 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/30Bus/PF_Dataset_2.xlsx').values\n",
        "\n",
        "# Split the dataset\n",
        "train_percentage = 80\n",
        "val_percentage = 20\n",
        "\n",
        "train_dataset = slice_dataset(dataset1, train_percentage)\n",
        "val_dataset = slice_dataset(dataset2, val_percentage)\n",
        "\n",
        "n_bus = 30\n",
        "\n",
        "# Prepare training and validation data using updated make_dataset function\n",
        "x_raw_train, y_raw_train, mask_train = make_dataset(train_dataset, n_bus)\n",
        "x_raw_val, y_raw_val, mask_val = make_dataset(val_dataset, n_bus)\n",
        "\n",
        "# Function to normalize the dataset with handling of zero standard deviation\n",
        "def normalize_dataset(x, y):\n",
        "    x_mean = torch.mean(x, dim=0)\n",
        "    x_std = torch.std(x, dim=0)\n",
        "    x_std[x_std == 0] = 1  # Replace zero std with 1 to prevent division by zero\n",
        "    x_norm = (x - x_mean) / x_std\n",
        "\n",
        "    y_mean = torch.mean(y, dim=0)\n",
        "    y_std = torch.std(y, dim=0)\n",
        "    y_std[y_std == 0] = 1  # Replace zero std with 1 to prevent division by zero\n",
        "    y_norm = (y - y_mean) / y_std\n",
        "\n",
        "    return x_norm, y_norm, x_mean, y_mean, x_std, y_std\n",
        "\n",
        "# Normalize the raw data\n",
        "x_norm_train, y_norm_train, x_train_mean, y_train_mean, x_train_std, y_train_std = normalize_dataset(x_raw_train, y_raw_train)\n",
        "x_norm_val, y_norm_val, x_val_mean, y_val_mean, x_val_std, y_val_std = normalize_dataset(x_raw_val, y_raw_val)\n",
        "\n",
        "# Prepare DataLoader for PyTorch Geometric\n",
        "# Load the IEEE 30-bus test case using pandapower\n",
        "net = nw.case30()\n",
        "\n",
        "# Get the 'from_bus' and 'to_bus' for each line in the network\n",
        "from_buses = net.line['from_bus'].values\n",
        "to_buses = net.line['to_bus'].values\n",
        "\n",
        "# Construct the edge index (bidirectional edges)\n",
        "edge_index = torch.tensor([list(from_buses) + list(to_buses), list(to_buses) + list(from_buses)], dtype=torch.long)\n",
        "\n",
        "print(\"Edge Index for IEEE 30-bus System:\")\n",
        "print(edge_index)\n",
        "\n",
        "# Create Data objects for PyTorch Geometric with the mask\n",
        "train_data_list = [Data(x=x, y=y, edge_index=edge_index, mask=mask) for x, y, mask in zip(x_norm_train, y_norm_train, mask_train)]\n",
        "val_data_list = [Data(x=x, y=y, edge_index=edge_index, mask=mask) for x, y, mask in zip(x_norm_val, y_norm_val, mask_val)]\n",
        "\n",
        "# Prepare DataLoaders\n",
        "train_loader = DataLoader(train_data_list, batch_size=1)\n",
        "val_loader = DataLoader(val_data_list, batch_size=1)\n",
        "\n",
        "print(\"Data preparation completed successfully.\")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBY8GpwLPiOL",
        "outputId": "62208927-0316-4322-bf6c-210b1dbcbc86"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge Index for IEEE 30-bus System:\n",
            "tensor([[ 0,  0,  1,  2,  1,  1,  3,  4,  5,  5,  5,  5,  8,  8,  3, 11, 11, 11,\n",
            "         11, 13, 15, 14, 17, 18,  9,  9,  9,  9, 20, 14, 21, 22, 23, 24, 24, 27,\n",
            "         26, 26, 28,  7,  5,  1,  2,  3,  3,  4,  5,  5,  6,  6,  7,  8,  9, 10,\n",
            "          9, 11, 12, 13, 14, 15, 14, 16, 17, 18, 19, 19, 16, 20, 21, 21, 22, 23,\n",
            "         23, 24, 25, 26, 26, 28, 29, 29, 27, 27],\n",
            "        [ 1,  2,  3,  3,  4,  5,  5,  6,  6,  7,  8,  9, 10,  9, 11, 12, 13, 14,\n",
            "         15, 14, 16, 17, 18, 19, 19, 16, 20, 21, 21, 22, 23, 23, 24, 25, 26, 26,\n",
            "         28, 29, 29, 27, 27,  0,  0,  1,  2,  1,  1,  3,  4,  5,  5,  5,  5,  8,\n",
            "          8,  3, 11, 11, 11, 11, 13, 15, 14, 17, 18,  9,  9,  9,  9, 20, 14, 21,\n",
            "         22, 23, 24, 24, 27, 26, 26, 28,  7,  5]])\n",
            "Data preparation completed successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"x_std_raw:\", x_std_raw)\n",
        "#print(\"y_std_raw:\", y_std_raw)\n",
        "\n",
        "# print(\"Number of NaNs in x_norm_train:\", torch.isnan(x_norm_train).sum().item())\n",
        "# print(\"Number of NaNs in y_norm_train:\", torch.isnan(y_norm_train).sum().item())\n",
        "print(x_raw_train)\n",
        "# print(\"Standard deviation of features:\", x_val_std)\n",
        "# print(\"y_val_mean:\", y_val_mean)\n",
        "# print(\"y_val_std:\", y_val_std)\n",
        "\n",
        "#print(f\"Number of non-constant input features: {num_filtered_features}\")\n",
        "#print(f\"Number of non-constant target features: {num_filtered_targets}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ubhNQHZ003L",
        "outputId": "eb4ae54a-94ec-4c4a-98cf-d67a3401cfcb"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [14.40134, 13.22018,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 2.99126,  1.21511,  0.98492,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.97893,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 2.91809,  0.84565,  0.97803,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [12.16662,  1.42966,  0.96580,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [13.52838,  9.30579,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 1.90479,  0.94073,  0.98512,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.97815,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 1.76046,  0.89814,  0.98310,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 9.43754,  1.22884,  0.97348,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [13.81231, 12.01729,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 2.23502,  1.32606,  0.97863,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.96654,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 2.21770,  0.68536,  0.98190,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 9.79359,  1.63231,  0.97117,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [20.66368, 14.85904,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 2.15676,  1.25817,  0.98560,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.97962,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 1.51396,  1.01141,  0.98318,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 7.97616,  2.07334,  0.97348,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [17.38465, 11.98350,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 3.13643,  0.73614,  0.97972,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.96866,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 2.23619,  1.00753,  0.97945,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 9.43333,  2.64651,  0.96758,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [15.96255, 14.98837,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 1.56813,  0.96419,  0.98209,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.97111,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 2.90847,  1.07888,  0.97534,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [12.82191,  2.13076,  0.96133,  ...,  0.00000,  1.00000,  0.00000]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **57 Bus Only**"
      ],
      "metadata": {
        "id": "jkFs_7lLiDgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# Load dataset from Excel files\n",
        "dataset1 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/57Bus/PF_Dataset_1.xlsx').values\n",
        "dataset2 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/57Bus/PF_Dataset_2.xlsx').values\n",
        "\n",
        "# Split the dataset\n",
        "train_percentage = 80\n",
        "val_percentage = 20\n",
        "\n",
        "train_dataset = slice_dataset(dataset1, train_percentage)\n",
        "val_dataset = slice_dataset(dataset2, val_percentage)\n",
        "\n",
        "n_bus = 57\n",
        "\n",
        "# # Prepare training and validation data\n",
        "x_raw_train, y_raw_train = make_dataset(train_dataset, n_bus)\n",
        "x_raw_val, y_raw_val = make_dataset(val_dataset, n_bus)\n",
        "\n",
        "# Normalize the raw data\n",
        "x_norm_train, y_norm_train, x_train_mean, y_train_mean, x_train_std, y_train_std = normalize_dataset(x_raw_train, y_raw_train)\n",
        "x_norm_val, y_norm_val, x_val_mean, y_val_mean, x_val_std, y_val_std = normalize_dataset(x_raw_val, y_raw_val)\n",
        "\n",
        "# Prepare DataLoader for PyTorch Geometric\n",
        "# Load the IEEE 57-bus test case using pandapower\n",
        "net = nw.case57()\n",
        "\n",
        "# Get the 'from_bus' and 'to_bus' for each line in the network\n",
        "from_buses = net.line['from_bus'].values\n",
        "to_buses = net.line['to_bus'].values\n",
        "\n",
        "# Construct the edge index (bidirectional edges)\n",
        "edge_index = torch.tensor([list(from_buses) + list(to_buses), list(to_buses) + list(from_buses)], dtype=torch.long)\n",
        "\n",
        "print(\"Edge Index for IEEE 57-bus System:\")\n",
        "print(edge_index)\n",
        "\n",
        "# Create Data objects for PyTorch Geometric without mask\n",
        "train_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_train, y_norm_train)]\n",
        "val_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_val, y_norm_val)]\n",
        "\n",
        "# Prepare DataLoaders\n",
        "train_loader = DataLoader(train_data_list, batch_size=1)\n",
        "val_loader = DataLoader(val_data_list, batch_size=1)\n",
        "\n",
        "print(\"Data preparation completed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W8Sef5XiCt-",
        "outputId": "38cb502e-284b-4b27-c692-9562d48fb26f"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge Index for IEEE 57-bus System:\n",
            "tensor([[ 0,  1,  2,  3,  3,  5,  5,  7,  8,  8,  8,  8, 12, 12,  0,  0,  0,  2,\n",
            "          4,  6,  9, 10, 11, 11, 11, 13, 17, 18, 20, 21, 22, 25, 26, 27, 24, 29,\n",
            "         30, 31, 33, 34, 35, 36, 36, 35, 21, 40, 40, 37, 45, 46, 47, 48, 49, 28,\n",
            "         51, 52, 53, 43, 55, 55, 56, 37, 37,  1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
            "         10, 11, 12, 13, 14, 14, 15, 16, 14,  5,  7, 11, 12, 12, 15, 16, 14, 18,\n",
            "         19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 37,\n",
            "         41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 44, 40, 41, 55, 48, 47],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 14, 15, 16, 14,\n",
            "          5,  7, 11, 12, 12, 15, 16, 14, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30,\n",
            "         31, 32, 34, 35, 36, 37, 38, 39, 37, 41, 42, 43, 46, 47, 48, 49, 50, 51,\n",
            "         52, 53, 54, 44, 40, 41, 55, 48, 47,  0,  1,  2,  3,  3,  5,  5,  7,  8,\n",
            "          8,  8,  8, 12, 12,  0,  0,  0,  2,  4,  6,  9, 10, 11, 11, 11, 13, 17,\n",
            "         18, 20, 21, 22, 25, 26, 27, 24, 29, 30, 31, 33, 34, 35, 36, 36, 35, 21,\n",
            "         40, 40, 37, 45, 46, 47, 48, 49, 28, 51, 52, 53, 43, 55, 55, 56, 37, 37]])\n",
            "Data preparation completed successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5dDK5_qgRaT",
        "outputId": "eb108bd7-4c5e-4c7e-ea54-6e24cdeb9ece"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  1,  2,  1,  1,  3,  4,  5,  5,  5,  5,  8,  8,  3, 11, 11, 11,\n",
              "         11, 13, 15, 14, 17, 18,  9,  9,  9,  9, 20, 14, 21, 22, 23, 24, 24, 27,\n",
              "         26, 26, 28,  7,  5,  1,  2,  3,  3,  4,  5,  5,  6,  6,  7,  8,  9, 10,\n",
              "          9, 11, 12, 13, 14, 15, 14, 16, 17, 18, 19, 19, 16, 20, 21, 21, 22, 23,\n",
              "         23, 24, 25, 26, 26, 28, 29, 29, 27, 27],\n",
              "        [ 1,  2,  3,  3,  4,  5,  5,  6,  6,  7,  8,  9, 10,  9, 11, 12, 13, 14,\n",
              "         15, 14, 16, 17, 18, 19, 19, 16, 20, 21, 21, 22, 23, 23, 24, 25, 26, 26,\n",
              "         28, 29, 29, 27, 27,  0,  0,  1,  2,  1,  1,  3,  4,  5,  5,  5,  5,  8,\n",
              "          8,  3, 11, 11, 11, 11, 13, 15, 14, 17, 18,  9,  9,  9,  9, 20, 14, 21,\n",
              "         22, 23, 24, 24, 27, 26, 26, 28,  7,  5]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define GNN Model**\n",
        "\n",
        "We will use a simple GCN as the first model and later extend it to include other GNN topologies:"
      ],
      "metadata": {
        "id": "IwMNOyWDpPIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class My_GNN_Model(nn.Module):\n",
        "    def __init__(self, in_channels=7, hidden_channels=8, out_channels=2):\n",
        "        super(My_GNN_Model, self).__init__()\n",
        "        # Define the GNN layers\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Define the output GNN layer for direct prediction\n",
        "        self.conv_out = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        if out_channels is None:\n",
        "            out_channels = 2\n",
        "\n",
        "        self.lin = Linear(hidden_channels * n_bus, out_channels * n_bus)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        '''\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        x = x.view(-1)\n",
        "        x = self.lin(x)\n",
        "        return x.view(-1, num_filtered_targets)\n",
        "        ;'''\n",
        "\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply GCN layers with ReLU activation\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        # Apply the output GCN layer\n",
        "        x = self.lin(x.view(-1))\n",
        "\n",
        "        return x.view(-1, 2)\n",
        "\n",
        "# Initialize the model with the correct input and output sizes\n",
        "model = My_GNN_Model(in_channels=7, out_channels=2)\n"
      ],
      "metadata": {
        "id": "WvkgOj-sQHys"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "_KGnM5dw1F2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "class My_GNN_Model(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels=8, out_channels=None, n_nodes=None):\n",
        "        super(My_GNN_Model, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Use the filtered number of nodes (buses) instead of the original n_bus\n",
        "        if n_nodes is None:\n",
        "            n_nodes = x_filtered_train.shape[0]  # Use the number of filtered nodes\n",
        "\n",
        "        # Dynamically set the output size based on the filtered target size\n",
        "        if out_channels is None:\n",
        "            out_channels = num_filtered_targets\n",
        "\n",
        "        self.lin = Linear(hidden_channels * n_nodes, out_channels * n_nodes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        x = x.view(-1)\n",
        "        x = self.lin(x)\n",
        "        return x.view(-1, num_filtered_targets)\n",
        "\n",
        "# Initialize the model with the correct input and output sizes\n",
        "model = My_GNN_Model(in_channels=num_filtered_features, out_channels=num_filtered_targets)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "Tid42BkhcQOx",
        "outputId": "660b7c22-d555-4579-8353-84e18a97a9f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-10-833c09dfadc8>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-833c09dfadc8>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#**Update Edge Index**\n",
        "\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "# Get the list of non-constant nodes\n",
        "filtered_nodes = np.where(non_constant_x.numpy())[0]\n",
        "print(f\"Filtered Nodes: {filtered_nodes}\")\n",
        "\n",
        "# Create a mapping from old node indices to new filtered indices\n",
        "node_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(filtered_nodes)}\n",
        "\n",
        "# Update the edge index using the filtered node indices\n",
        "new_from_buses = []\n",
        "new_to_buses = []\n",
        "\n",
        "for from_bus, to_bus in zip(from_buses, to_buses):\n",
        "    # Check if both 'from_bus' and 'to_bus' are in the filtered nodes\n",
        "    if from_bus in node_mapping and to_bus in node_mapping:\n",
        "        new_from_buses.append(node_mapping[from_bus])\n",
        "        new_to_buses.append(node_mapping[to_bus])\n",
        "\n",
        "# Construct the new edge index with updated indices\n",
        "edge_index = torch.tensor([new_from_buses + new_to_buses, new_to_buses + new_from_buses], dtype=torch.long)\n",
        "\n",
        "print(\"Updated Edge Index:\")\n",
        "print(edge_index)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "-HBtSfds1OCB",
        "outputId": "5523e2d4-c708-4f39-964b-eb3316b1edff"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-75-370784a66dcd>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-370784a66dcd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    **Update Edge Index**\"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_filtered_train, y_filtered_train)]\n",
        "#val_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_filtered_val, y_filtered_val)]\n",
        "\n",
        "#train_loader = DataLoader(train_data_list, batch_size=1)\n",
        "#val_loader = DataLoader(val_data_list, batch_size=1)\n",
        "\n",
        "#print(\"Data preparation completed successfully.\")"
      ],
      "metadata": {
        "id": "HVneaZ5m1mn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)\n",
        "print(y_val_mean.shape)\n",
        "print(y_val_std.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofHG-SUh1wNu",
        "outputId": "e98488ff-e0a3-4b6d-92cb-c53095386192"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([60])\n",
            "torch.Size([30, 2])\n",
            "torch.Size([30, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Loop**"
      ],
      "metadata": {
        "id": "B0345-HgpZa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer with L2 regularization (weight decay)\n",
        "lambda_l2 = 1e-3  # L2 regularization strength\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=lambda_l2)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0  # Track the total loss for the epoch\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(batch)\n",
        "        target = batch.y # Use only the filtered target features\n",
        "\n",
        "        ## Get the mask for non-constant target features (P and Q)\n",
        "        #target = (y_val_std[:2] != 0).to(batch.y.device)\n",
        "\n",
        "        ## Apply the mask to the predictions and targets\n",
        "        #y_pred_masked = y_pred * target_mask\n",
        "        #target_masked = batch.y * target_mask\n",
        "\n",
        "        ## Compute loss using the masked predictions and targets\n",
        "        #loss = MSE(\n",
        "        #    denormalize_output(y_pred_masked, y_val_mean[:2], y_val_std[:2]),\n",
        "        #    denormalize_output(target_masked, y_val_mean[:2], y_val_std[:2])\n",
        "        #)\n",
        "\n",
        "\n",
        "        # Reshape y_pred to have the shape [n_bus, 4]\n",
        "        y_pred = y_pred.view(n_bus, 2)\n",
        "\n",
        "        # Compute loss using the masked predictions and targets\n",
        "        loss = MSE(\n",
        "            denormalize_output(y_pred, y_val_mean, y_val_std),\n",
        "            denormalize_output(target, y_val_mean, y_val_std)\n",
        "        )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss for reporting\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print the average loss for each epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue-47I31Q-RW",
        "outputId": "1ece8323-efdc-43e4-b7cf-6d4560e01e57"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 28.573385\n",
            "Epoch 2, Average Loss: 21.358171\n",
            "Epoch 3, Average Loss: 18.430391\n",
            "Epoch 4, Average Loss: 16.451854\n",
            "Epoch 5, Average Loss: 14.902440\n",
            "Epoch 6, Average Loss: 13.648475\n",
            "Epoch 7, Average Loss: 12.607355\n",
            "Epoch 8, Average Loss: 11.738885\n",
            "Epoch 9, Average Loss: 10.986672\n",
            "Epoch 10, Average Loss: 10.332103\n",
            "Epoch 11, Average Loss: 9.753467\n",
            "Epoch 12, Average Loss: 9.258669\n",
            "Epoch 13, Average Loss: 8.812268\n",
            "Epoch 14, Average Loss: 8.401218\n",
            "Epoch 15, Average Loss: 8.046548\n",
            "Epoch 16, Average Loss: 7.698450\n",
            "Epoch 17, Average Loss: 7.393844\n",
            "Epoch 18, Average Loss: 7.102926\n",
            "Epoch 19, Average Loss: 6.838992\n",
            "Epoch 20, Average Loss: 6.605532\n",
            "Epoch 21, Average Loss: 6.365446\n",
            "Epoch 22, Average Loss: 6.149999\n",
            "Epoch 23, Average Loss: 5.949882\n",
            "Epoch 24, Average Loss: 5.751297\n",
            "Epoch 25, Average Loss: 5.575956\n",
            "Epoch 26, Average Loss: 5.399973\n",
            "Epoch 27, Average Loss: 5.249211\n",
            "Epoch 28, Average Loss: 5.103893\n",
            "Epoch 29, Average Loss: 4.955111\n",
            "Epoch 30, Average Loss: 4.800827\n",
            "Epoch 31, Average Loss: 4.695440\n",
            "Epoch 32, Average Loss: 4.566101\n",
            "Epoch 33, Average Loss: 4.444342\n",
            "Epoch 34, Average Loss: 4.341703\n",
            "Epoch 35, Average Loss: 4.256858\n",
            "Epoch 36, Average Loss: 4.156176\n",
            "Epoch 37, Average Loss: 4.065779\n",
            "Epoch 38, Average Loss: 3.970697\n",
            "Epoch 39, Average Loss: 3.889630\n",
            "Epoch 40, Average Loss: 3.805519\n",
            "Epoch 41, Average Loss: 3.735908\n",
            "Epoch 42, Average Loss: 3.706082\n",
            "Epoch 43, Average Loss: 3.627724\n",
            "Epoch 44, Average Loss: 3.562728\n",
            "Epoch 45, Average Loss: 3.514702\n",
            "Epoch 46, Average Loss: 3.460781\n",
            "Epoch 47, Average Loss: 3.392097\n",
            "Epoch 48, Average Loss: 3.329383\n",
            "Epoch 49, Average Loss: 3.287147\n",
            "Epoch 50, Average Loss: 3.268485\n",
            "Epoch 51, Average Loss: 3.217114\n",
            "Epoch 52, Average Loss: 3.200688\n",
            "Epoch 53, Average Loss: 3.152257\n",
            "Epoch 54, Average Loss: 3.078298\n",
            "Epoch 55, Average Loss: 3.070381\n",
            "Epoch 56, Average Loss: 3.029529\n",
            "Epoch 57, Average Loss: 2.970021\n",
            "Epoch 58, Average Loss: 2.975078\n",
            "Epoch 59, Average Loss: 2.921491\n",
            "Epoch 60, Average Loss: 2.871446\n",
            "Epoch 61, Average Loss: 2.849298\n",
            "Epoch 62, Average Loss: 2.831673\n",
            "Epoch 63, Average Loss: 2.788358\n",
            "Epoch 64, Average Loss: 2.751620\n",
            "Epoch 65, Average Loss: 2.787410\n",
            "Epoch 66, Average Loss: 2.711886\n",
            "Epoch 67, Average Loss: 2.672783\n",
            "Epoch 68, Average Loss: 2.693000\n",
            "Epoch 69, Average Loss: 2.720631\n",
            "Epoch 70, Average Loss: 2.662879\n",
            "Epoch 71, Average Loss: 2.556250\n",
            "Epoch 72, Average Loss: 2.639781\n",
            "Epoch 74, Average Loss: 2.570312\n",
            "Epoch 75, Average Loss: 2.586403\n",
            "Epoch 76, Average Loss: 2.546065\n",
            "Epoch 77, Average Loss: 2.475582\n",
            "Epoch 78, Average Loss: 2.484884\n",
            "Epoch 79, Average Loss: 2.406971\n",
            "Epoch 80, Average Loss: 2.390860\n",
            "Epoch 81, Average Loss: 2.426994\n",
            "Epoch 82, Average Loss: 2.266495\n",
            "Epoch 83, Average Loss: 2.337854\n",
            "Epoch 84, Average Loss: 2.289492\n",
            "Epoch 85, Average Loss: 2.309129\n",
            "Epoch 86, Average Loss: 2.257000\n",
            "Epoch 87, Average Loss: 2.258767\n",
            "Epoch 88, Average Loss: 2.256309\n",
            "Epoch 89, Average Loss: 2.241555\n",
            "Epoch 90, Average Loss: 2.283218\n",
            "Epoch 91, Average Loss: 2.194567\n",
            "Epoch 92, Average Loss: 2.113560\n",
            "Epoch 93, Average Loss: 2.183136\n",
            "Epoch 94, Average Loss: 2.126266\n",
            "Epoch 95, Average Loss: 2.049438\n",
            "Epoch 96, Average Loss: 2.128373\n",
            "Epoch 97, Average Loss: 2.102931\n",
            "Epoch 98, Average Loss: 2.090108\n",
            "Epoch 99, Average Loss: 2.133611\n",
            "Epoch 100, Average Loss: 1.999235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "4sIrVikD1cFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(batch)\n",
        "\n",
        "        # Flatten the prediction and match the filtered target size\n",
        "        y_pred = y_pred.view(-1)[:num_filtered_targets] # Ensure it matches the filtered target size\n",
        "        target = batch.y[:num_filtered_targets] # Use only the filtered target features\n",
        "\n",
        "        # Debugging prints for shapes\n",
        "        print(f\"Shape of input (batch.x): {batch.x.shape}\")\n",
        "        print(f\"Shape of prediction (y_pred): {y_pred.shape}\")\n",
        "        print(f\"Shape of target (batch.y): {batch.y.shape}\")\n",
        "\n",
        "\n",
        "        # Compute loss using the filtered targets\n",
        "        loss = MSE(denormalize_output(y_pred, y_val_mean[:num_filtered_targets], y_val_std[:num_filtered_targets]),\n",
        "                   denormalize_output(target, y_val_mean[:num_filtered_targets], y_val_std[:num_filtered_targets]))\n",
        "\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the loss for each epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.6f}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2NNzVG1YN2Bb",
        "outputId": "57c35fcc-0cac-4cb2-f8a4-3b24a4553936"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (18x4 and 18x8)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-210-aa452a8c8e0a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Flatten the prediction and match the filtered target size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-207-278b28dbb96a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (18x4 and 18x8)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of y_pred: {y_pred.shape}\")\n",
        "print(f\"Shape of y_pred_filtered: {y_pred_filtered.shape}\")\n",
        "print(f\"Shape of target_filtered: {target_filtered.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QFdqP9ZJSp6Y",
        "outputId": "be142000-2586-4cd4-c465-5486df8a325f"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred_filtered' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-202-9e63b2ee23cb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of y_pred: {y_pred.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of y_pred_filtered: {y_pred_filtered.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of target_filtered: {target_filtered.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred_filtered' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.isnan(y_pred_filtered).any() or torch.isnan(target_filtered).any():\n",
        "    print(\"NaNs detected in predictions or targets!\")\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "g98p8RIRZ41b",
        "outputId": "ae31570d-ff9d-4fda-e0d4-c64970840f77"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'break' outside loop (<ipython-input-201-175092088542>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-201-175092088542>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape after conv1: {x.shape}\")\n",
        "print(f\"Shape after conv2: {x.shape}\")\n",
        "print(f\"Shape before Linear layer: {x.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "F120MKswWMeo",
        "outputId": "8ec2836f-d5c1-49cb-fc3b-6903b4e57a61"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-9cf19e096ece>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape after conv1: {x.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape after conv2: {x.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape before Linear layer: {x.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Topologies to Test:**\n",
        "The following topologies will be tested to compare the effectiveness of different GNN architecture.\n",
        "\n",
        "Each topology offers different strengths, such as handling local versus long-range relationships, incorporating attention mechanisms, and scaling to larger grid sizes.\n",
        "\n",
        "1. **Graph Convolutional Networks (GCN):**\n",
        "\n",
        " GCN is a basic form of GNN where each node aggregates features from its immediate neighbors. It’s simplicity makes it a good first model. It is widely used for node classification and regression tasks. GCN will serves as a baseline model that can handle local relationships effectively but may struggle with long-range dependencies.\n",
        "\n",
        "2. **Graph Attention Networks (GAT):**\n",
        "'GATConv'\n",
        "\n",
        "GAT assigns different attention weights to each neighboring node during aggregation and help the network focus on the most important nodes. It allows dynamic weighting of neighbors, which is useful when certain nodes (like generator buses) have more influence\n",
        "in OPF.\n",
        "\n",
        "3. **Chebyshev Networks (ChebNet):**\n",
        "'ChebConv'\n",
        "\n",
        "ChebNet approximates graph convolutions using Chebyshev polynomials and can capture information from nodes multiple hops away without needing many layers. ChebNet can effectively model multi-hop relationships while reducing the need for deep GCNs, which is important for capturing system-wide behavior in the grid.\n",
        "\n",
        "4. **GraphSAGE (SAmple and aggreGatE):**\n",
        "'SAGEConv'\n",
        "\n",
        "GraphSAGE is designed for inductive learning and allows us to sample a fixed-size neighborhood of nodes which will make it scalable to large graphs.\n",
        "GraphSAGE could be useful for OPF tasks in large power grids, as it can efficiently scale to larger\n",
        "networks.\n",
        "\n",
        "5. **GraphConv (GraphConv):**\n",
        "\n",
        "GraphConv is designed to enhance feature learning by incorporating self-loops (each node aggregates its own feature along with its neighbors).\n",
        "It performs a weighted sum of neighbor features, including the node’s own feature. This helps in capturing more node-specific information.\n",
        "It is useful when self-loops or enhanced node feature aggregation can improve model performance. It might perform better on grids where local node information (like generator buses) is crucial.\n",
        "\n",
        "6. **Multi-Head Graph Attention Networks (MH-GAT):**\n",
        "\n",
        "Multi-head attention computes multiple\n",
        "attention distributions in parallel, capturing various aspects of node relationships. This topology\n",
        "could be valuable for learning different aspects of node and edge interactions, especially when OPF\n",
        "solutions are influenced by both local and distant nodes"
      ],
      "metadata": {
        "id": "edjbvxFqU8dK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experiment Order:** (and an Idea for the comparison paper?)"
      ],
      "metadata": {
        "id": "BTFYOHpKWwj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline:** GCN (to set a benchmark).\n",
        "\n",
        "**Attention-Based:** GATConv (to see if attention helps in OPF tasks).\n",
        "\n",
        "**Multi-Hop Relationship:** ChebConv (to model long-range dependencies).\n",
        "\n",
        "**Scalability Test:** SAGEConv (to see how well it scales to larger bus systems).\n",
        "\n",
        "**Enhanced Node Feature Learning:** GraphConv (to check if self-loops improve performance)."
      ],
      "metadata": {
        "id": "Dp6u3VjWWLxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_GNN_GNN_NN(nn.Module):\n",
        "    def __init__(self, node_size, feat_in, feat_size1, feat_size2, hidden_size1, output_size, gnn_type='GATConv', dropout=0.3, use_batch_norm=False):\n",
        "        super(My_GNN_GNN_NN, self).__init__()\n",
        "\n",
        "        self.use_batch_norm = use_batch_norm\n",
        "\n",
        "        # GNN Layer Selection\n",
        "        if gnn_type == 'GCN':\n",
        "            self.conv1 = GCNConv(feat_in, feat_size1)\n",
        "            self.conv2 = GCNConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'GraphConv':\n",
        "            self.conv1 = GraphConv(feat_in, feat_size1)\n",
        "            self.conv2 = GraphConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'SAGEConv':\n",
        "            self.conv1 = SAGEConv(feat_in, feat_size1)\n",
        "            self.conv2 = SAGEConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'GATConv':\n",
        "            self.conv1 = GATConv(feat_in, feat_size1)\n",
        "            self.conv2 = GATConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'ChebConv':\n",
        "            self.conv1 = ChebConv(feat_in, feat_size1, K=2)\n",
        "            self.conv2 = ChebConv(feat_size1, feat_size2, K=2)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid GNN type. Choose from 'GCN', 'GraphConv', 'SAGEConv', 'GATConv', 'ChebConv'.\")\n",
        "\n",
        "        # Batch Normalization Layers (Optional)\n",
        "        if use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm1d(feat_size1)\n",
        "            self.bn2 = nn.BatchNorm1d(feat_size2)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.lin1 = Linear(node_size * feat_size2, hidden_size1)\n",
        "        self.lin2 = Linear(hidden_size1, output_size)\n",
        "\n",
        "        # Dropout Layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # GNN Layer 1\n",
        "        x = self.conv1(x, edge_index)\n",
        "        if self.use_batch_norm:\n",
        "            x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # GNN Layer 2\n",
        "        x = self.conv2(x, edge_index)\n",
        "        if self.use_batch_norm:\n",
        "            x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Flatten the node features for fully connected layers\n",
        "        x = x.flatten(start_dim=0)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def save_weights(self, filename):\n",
        "        torch.save(self.state_dict(), filename)\n",
        "\n",
        "    def load_weights(self, filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "        self.eval()\n"
      ],
      "metadata": {
        "id": "Q6CBvBJIjDjX"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Initialization**"
      ],
      "metadata": {
        "id": "lM4NMS22ggeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "feat_in = 7  # Number of input features per node (P, Q, V, delta, bus type, etc.)\n",
        "feat_size1 = 16  # Size of the first GNN layer\n",
        "feat_size2 = 8   # Size of the second GNN layer\n",
        "hidden_size1 = 64  # Size of the first fully connected layer\n",
        "output_size = n_bus * 2  # Output size (P and Q for each bus)\n",
        "gnn_type = 'GATConv'  # Choose from 'GCN', 'GraphConv', 'SAGEConv', 'GATConv', 'ChebConv'\n",
        "dropout = 0.3  # Dropout rate for regularization\n",
        "use_batch_norm = True  # Use Batch Normalization\n",
        "\n",
        "# Initialize the model with specified hyperparameters\n",
        "model = My_GNN_GNN_NN(\n",
        "    node_size=n_bus,\n",
        "    feat_in=feat_in,\n",
        "    feat_size1=feat_size1,\n",
        "    feat_size2=feat_size2,\n",
        "    hidden_size1=hidden_size1,\n",
        "    output_size=output_size,\n",
        "    gnn_type=gnn_type,\n",
        "    dropout=dropout,\n",
        "    use_batch_norm=use_batch_norm\n",
        ")\n",
        "\n",
        "# Print model details for verification\n",
        "print(\"Initialized Model:\")\n",
        "print(model)\n",
        "\n",
        "# Define the optimizer and learning rate scheduler\n",
        "learning_rate = 0.001 #0.0001 for 30 bus 0.001 for 57 bus\n",
        "lambda_l2 = 1e-3  # L2 regularization strength\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=40, verbose=True\n",
        ")\n",
        "\n",
        "# Print model parameter details for debugging\n",
        "print(\"\\nModel Parameters:\")\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"{name}: {param.size()}\")\n",
        "\n",
        "# Calculate the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal number of trainable parameters: {total_params:,}\")\n",
        "\n",
        "# Example usage of the scheduler during training:\n",
        "# scheduler.step(loss)  # Call this after each epoch if using ReduceLROnPlateau\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFdksTBy3xJk",
        "outputId": "0e47ef92-502f-4c21-a572-494d5714b7ab"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized Model:\n",
            "My_GNN_GNN_NN(\n",
            "  (conv1): GATConv(7, 16, heads=1)\n",
            "  (conv2): GATConv(16, 8, heads=1)\n",
            "  (bn1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (lin1): Linear(in_features=240, out_features=64, bias=True)\n",
            "  (lin2): Linear(in_features=64, out_features=60, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n",
            "\n",
            "Model Parameters:\n",
            "conv1.att_src: torch.Size([1, 1, 16])\n",
            "conv1.att_dst: torch.Size([1, 1, 16])\n",
            "conv1.bias: torch.Size([16])\n",
            "conv1.lin.weight: torch.Size([16, 7])\n",
            "conv2.att_src: torch.Size([1, 1, 8])\n",
            "conv2.att_dst: torch.Size([1, 1, 8])\n",
            "conv2.bias: torch.Size([8])\n",
            "conv2.lin.weight: torch.Size([8, 16])\n",
            "bn1.weight: torch.Size([16])\n",
            "bn1.bias: torch.Size([16])\n",
            "bn2.weight: torch.Size([8])\n",
            "bn2.bias: torch.Size([8])\n",
            "lin1.weight: torch.Size([64, 240])\n",
            "lin1.bias: torch.Size([64])\n",
            "lin2.weight: torch.Size([60, 64])\n",
            "lin2.bias: torch.Size([60])\n",
            "\n",
            "Total number of trainable parameters: 19,684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Enhanced Training Loop**"
      ],
      "metadata": {
        "id": "9IniYKPphG0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store loss values\n",
        "train_loss_list, val_loss_list = [], []\n",
        "\n",
        "# Early stopping parameters\n",
        "patience = 60\n",
        "count = 0\n",
        "best_epoch = 0\n",
        "lossMin = float('inf')\n",
        "\n",
        "# Flatten y_val_mean and y_val_std to match the predictions\n",
        "y_val_mean_flattened = y_val_mean.view(-1)  # Shape: [60] for 30-bus system\n",
        "y_val_std_flattened = y_val_std.view(-1)    # Shape: [60] for 30-bus system\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(400):  # Changed from 2001\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # Training phase\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(batch)\n",
        "        y_pred = y_pred.view(-1)  # Flatten predictions to match target shape\n",
        "\n",
        "        # Compute loss using the flattened mean and std\n",
        "        loss = MSE(\n",
        "            denormalize_output(y_pred, y_val_mean_flattened, y_val_std_flattened),\n",
        "            denormalize_output(batch.y.view(-1), y_val_mean_flattened, y_val_std_flattened)\n",
        "        )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        train_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    # Compute average training loss\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            # Forward pass for validation\n",
        "            y_val_pred = model(batch)\n",
        "            y_val_pred = y_val_pred.view(-1)\n",
        "\n",
        "            # Compute validation loss\n",
        "            loss = MSE(\n",
        "                denormalize_output(y_val_pred, y_val_mean_flattened, y_val_std_flattened),\n",
        "                denormalize_output(batch.y.view(-1), y_val_mean_flattened, y_val_std_flattened)\n",
        "            )\n",
        "            val_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    # Compute average validation loss\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_loss_list.append(val_loss)\n",
        "\n",
        "    # Learning rate adjustment based on validation loss\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Early stopping mechanism\n",
        "    if val_loss < lossMin:\n",
        "        lossMin = val_loss\n",
        "        count = 0\n",
        "        best_epoch = epoch\n",
        "        best_train_loss = train_loss\n",
        "        best_val_loss = val_loss\n",
        "\n",
        "        # Save the best model weights\n",
        "        #model.save_weights(\"[30 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "        model.save_weights(\"[57 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "\n",
        "    else:\n",
        "        count += 1\n",
        "        if count > patience:\n",
        "            print(f\"Early stopping at epoch {epoch} | Best epoch: {best_epoch}\")\n",
        "            print(f\"Best train loss: {best_train_loss:.7f} | Best val loss: {best_val_loss:.7f}\")\n",
        "            break\n",
        "\n",
        "    # Log progress every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch} | Train loss: {train_loss:.7f} | Val loss: {val_loss:.7f}\")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(f\"Best Epoch: {best_epoch} | Best Train Loss: {best_train_loss:.7f} | Best Val Loss: {best_val_loss:.7f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyGTAYTt5duJ",
        "outputId": "dc4000b9-6375-4052-a394-b68824863d55"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train loss: 2.6216982 | Val loss: 2.5997449\n",
            "Epoch 10 | Train loss: 1.4106592 | Val loss: 1.7519384\n",
            "Epoch 20 | Train loss: 1.2226789 | Val loss: 1.7576041\n",
            "Epoch 30 | Train loss: 1.1592023 | Val loss: 1.6226435\n",
            "Epoch 40 | Train loss: 1.1014722 | Val loss: 1.6940861\n",
            "Epoch 50 | Train loss: 1.0688306 | Val loss: 1.4017618\n",
            "Epoch 60 | Train loss: 1.0199030 | Val loss: 1.6009744\n",
            "Epoch 70 | Train loss: 1.0144008 | Val loss: 1.4537815\n",
            "Epoch 80 | Train loss: 1.0056522 | Val loss: 1.6437261\n",
            "Epoch 90 | Train loss: 0.9703034 | Val loss: 1.5673971\n",
            "Epoch 100 | Train loss: 0.9469797 | Val loss: 1.5780115\n",
            "Epoch 110 | Train loss: 0.9754456 | Val loss: 1.6546613\n",
            "Early stopping at epoch 115 | Best epoch: 64\n",
            "Best train loss: 1.0209342 | Best val loss: 1.2923939\n",
            "Training complete.\n",
            "Best Epoch: 64 | Best Train Loss: 1.0209342 | Best Val Loss: 1.2923939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "FlVgf3zs8X7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "train_loss_list, val_loss_list = [], []\n",
        "patience = 50\n",
        "count = 0\n",
        "lossMin = float('inf')\n",
        "\n",
        "for epoch in range(600): #Changed from 2001\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(batch)\n",
        "        y_pred = y_pred.view(-1)  # Flatten predictions\n",
        "        loss = MSE(denormalize_output(y_pred, y_val_mean, y_val_std), denormalize_output(batch.y, y_val_mean, y_val_std))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            y_val_pred = model(batch)\n",
        "            y_val_pred = y_val_pred.view(-1)\n",
        "            loss = MSE(denormalize_output(y_val_pred, y_val_mean, y_val_std), denormalize_output(batch.y, y_val_mean, y_val_std))\n",
        "            val_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_loss_list.append(val_loss)\n",
        "\n",
        "    # Learning rate adjustment\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Early stopping\n",
        "    if val_loss < lossMin:\n",
        "        lossMin = val_loss\n",
        "        count = 0\n",
        "        best_epoch = epoch\n",
        "        best_train_loss = train_loss\n",
        "        best_val_loss = val_loss\n",
        "        model.save_weights(model, \"[14 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "        #model.save_weights(model, \"[30 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "        #model.save_weights(model, \"[57 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "    else:\n",
        "        count += 1\n",
        "        if count > patience:\n",
        "            print(f\"Early stopping at epoch {epoch} | Best epoch: {best_epoch}\")\n",
        "            print(f\"Best train loss: {best_train_loss:.7f} | Best val loss: {best_val_loss:.7f}\")\n",
        "            break\n",
        "\n",
        "    # Log progress every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch} | Train loss: {train_loss:.7f} | Val loss: {val_loss:.7f}\")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "WAZmEwSpj9Sq",
        "outputId": "edb4c754-5cbe-4b7a-d875-798dcda314f2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (60) must match the size of tensor b (2) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-1905f43eb45c>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         loss = MSE(\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mdenormalize_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mdenormalize_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-69-2cc95821ce5c>\u001b[0m in \u001b[0;36mdenormalize_output\u001b[0;34m(y_norm, y_mean, y_std)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdenormalize_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0my_norm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_std\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (60) must match the size of tensor b (2) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotting Loss Curves**"
      ],
      "metadata": {
        "id": "HkhKmVL-hLQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "#plt.title('Training and Validation Loss Curve for GNN-Based OPF on IEEE 14-Bus System', fontsize=14)\n",
        "#plt.title('Training and Validation Loss Curve for GNN-Based OPF on IEEE 30-Bus System', fontsize=14)\n",
        "plt.title('Training and Validation Loss Curve for GNN-Based OPF on IEEE 57-Bus System', fontsize=14)\n",
        "\n",
        "plt.plot(train_loss_list, label=\"Train Loss\", color='blue', linewidth=2)\n",
        "plt.plot(val_loss_list, label=\"Validation Loss\", color='orange', linewidth=2)\n",
        "plt.yscale('log')  # Use logarithmic scale for better visualization\n",
        "plt.xlabel(\"Epoch\", fontsize=12)\n",
        "plt.ylabel(\"Loss (Log Scale)\", fontsize=12)\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "plt.legend(loc='best', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final and best losses\n",
        "print(f\"Last epoch: {epoch + 1}, Train loss: {train_loss:.7f}, Val loss: {val_loss:.7f}\")\n",
        "print(f\"Best epoch: {best_epoch + 1}, Best Train loss: {best_train_loss:.7f}, Best Val loss: {best_val_loss:.7f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "YWYYyI3cj-22",
        "outputId": "80fca77d-7c21-46fd-9ef9-6a2ccef554a0"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last epoch: 116, Train loss: 0.9315722, Val loss: 1.6013086\n",
            "Best epoch: 65, Best Train loss: 1.0209342, Best Val loss: 1.2923939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "MhfPkA3bhVX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_val_targets.shape)\n",
        "print(y_val_predictions[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9RFvWquIKR2",
        "outputId": "4c337b09-b9ab-4ed9-bac0-abbd8f08bf51"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([400, 30, 2])\n",
            "torch.Size([30, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Function to calculate regression metrics\n",
        "def evaluate_regression_metrics(y_true, y_pred):\n",
        "    # Denormalize the outputs\n",
        "    y_true = denormalize_output(y_true, y_val_mean, y_val_std)\n",
        "    y_pred = denormalize_output(y_pred, y_val_mean, y_val_std)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_true.reshape(-1, 2), y_pred.reshape(-1, 2))\n",
        "    rmse = np.sqrt(mse)\n",
        "    nrmse = rmse / np.std(y_true)\n",
        "    mae = mean_absolute_error(y_true.reshape(-1, 2), y_pred.reshape(-1, 2))\n",
        "    r2 = r2_score(y_true.reshape(-1, 2), y_pred.reshape(-1, 2))\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.6f}\")\n",
        "    print(f\"Normalized RMSE (NRMSE): {nrmse:.6f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.6f}\")\n",
        "    print(f\"R^2 Score: {r2:.6f}\")\n",
        "\n",
        "    return mse, rmse, nrmse, mae, r2\n",
        "\n",
        "# Evaluation after training\n",
        "model.eval()\n",
        "y_val_predictions = []\n",
        "\n",
        "# Collect all predictions and ground truth for the validation set\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        # Forward pass for validation\n",
        "        y_val_pred = model(batch)\n",
        "\n",
        "        # Reshape predictions to [n_bus, 2] to match the targets' structure\n",
        "        y_val_pred = y_val_pred.view(n_bus, 2)\n",
        "        y_val_predictions.append(y_val_pred)\n",
        "\n",
        "# Stack predictions and targets with the shape [n_samples, n_bus, 2]\n",
        "y_val_predictions = torch.stack(y_val_predictions, dim=0)\n",
        "y_val_targets = torch.stack([batch.y.view(n_bus, 2) for batch in val_loader], dim=0)\n",
        "\n",
        "# Calculate and print regression metrics\n",
        "mse, rmse, nrmse, mae, r2 = evaluate_regression_metrics(y_val_targets, y_val_predictions)\n",
        "\n",
        "# Save the metrics to a dictionary for later comparison\n",
        "metrics = {\n",
        "    'MSE': mse,\n",
        "    'RMSE': rmse,\n",
        "    'NRMSE': nrmse,\n",
        "    'MAE': mae,\n",
        "    'R2': r2\n",
        "}\n",
        "\n",
        "# Optionally save the metrics to a CSV file\n",
        "metrics_df = pd.DataFrame([metrics])\n",
        "\n",
        "# Save the metrics to the CSV file\n",
        "#metrics_df.to_csv(\"14_bus_validation_metrics.csv\", index=False)\n",
        "#print(\"\\nMetrics saved to '14_bus_validation_metrics.csv'.\")\n",
        "\n",
        "#metrics_df.to_csv(\"30_bus_validation_metrics.csv\", index=False)\n",
        "#print(\"\\nMetrics saved to '30_bus_validation_metrics.csv'.\")\n",
        "\n",
        "metrics_df.to_csv(\"57_bus_validation_metrics.csv\", index=False)\n",
        "print(\"\\nMetrics saved to '57_bus_validation_metrics.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMI26hcw4NVL",
        "outputId": "003c6eb4-5c1d-480b-e4c1-bb50bb7661d4"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 1.601307\n",
            "Root Mean Squared Error (RMSE): 1.265427\n",
            "Normalized RMSE (NRMSE): 0.173280\n",
            "Mean Absolute Error (MAE): 0.595381\n",
            "R^2 Score: 0.968978\n",
            "\n",
            "Metrics saved to '30_bus_validation_metrics.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Single datapoint evaluation**"
      ],
      "metadata": {
        "id": "EDe5Wxil6opK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Device configuration (ensure compatibility)\n",
        "device = next(model.parameters()).device\n",
        "\n",
        "# Function for single datapoint evaluation\n",
        "def evaluate_single_datapoint(data, y_mean, y_std, y_raw):\n",
        "    # Move the data to the correct device\n",
        "    data = data.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Reshape predictions to match the target structure [n_bus, 2]\n",
        "    y_pred = y_pred.view(n_bus, 2)\n",
        "    data_y = data.y.view(n_bus, 2)\n",
        "\n",
        "    # Denormalize the prediction and the ground truth\n",
        "    y_pred_denorm = denormalize_output(y_pred, y_mean, y_std)\n",
        "    y_target_denorm = denormalize_output(data_y, y_mean, y_std)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = MSE(y_pred_denorm, y_target_denorm)\n",
        "\n",
        "    # Print ground truth and prediction\n",
        "    print(\"Ground-truth:\", y_raw.detach().cpu().numpy())\n",
        "    print(\"Prediction:\", y_pred_denorm.detach().cpu().numpy())\n",
        "    print(f\"Loss (MSE): {loss:.7f}\")\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Evaluate on a single training datapoint\n",
        "print(\"\\nEvaluation on a single training datapoint:\")\n",
        "train_loss_1 = evaluate_single_datapoint(\n",
        "    train_loader.dataset[0], y_val_mean, y_val_std, y_raw_train[0]\n",
        ")\n",
        "\n",
        "# Evaluate on a single validation datapoint\n",
        "print(\"\\nEvaluation on a single validation datapoint:\")\n",
        "val_loss_1 = evaluate_single_datapoint(\n",
        "    val_loader.dataset[0], y_val_mean, y_val_std, y_raw_val[0]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VafI4QFlAGRe",
        "outputId": "8c9160dc-54dd-49cf-a8f6-2f8f0abd1049"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation on a single training datapoint:\n",
            "Ground-truth: [[ 0.       0.     ]\n",
            " [14.40134 13.22018]\n",
            " [ 2.99126  1.21511]\n",
            " [ 6.92581  2.21079]\n",
            " [ 0.       0.     ]\n",
            " [ 0.       0.     ]\n",
            " [15.86692 13.9925 ]\n",
            " [23.75827 19.8484 ]\n",
            " [ 0.       0.     ]\n",
            " [ 7.46975  2.51386]\n",
            " [ 0.       0.     ]\n",
            " [14.24347  8.09227]\n",
            " [ 0.       0.     ]\n",
            " [ 5.19604  1.98946]\n",
            " [ 8.39846  3.13083]\n",
            " [ 3.95501  1.30192]\n",
            " [ 6.31731  7.41053]\n",
            " [ 4.2316   1.24807]\n",
            " [10.36428  3.84165]\n",
            " [ 2.98069  0.45465]\n",
            " [21.10863 13.66907]\n",
            " [ 0.       0.     ]\n",
            " [ 3.72223  1.43751]\n",
            " [ 6.03425  8.3942 ]\n",
            " [ 0.       0.     ]\n",
            " [ 2.47779  2.2616 ]\n",
            " [ 0.       0.     ]\n",
            " [ 0.       0.     ]\n",
            " [ 2.91809  0.84565]\n",
            " [12.16662  1.42966]]\n",
            "Prediction: [[ 0.00015 -0.00003]\n",
            " [15.22614 12.48808]\n",
            " [ 2.53103  1.17675]\n",
            " [ 7.73088  1.53132]\n",
            " [-0.0011   0.00188]\n",
            " [-0.00019 -0.00061]\n",
            " [14.01692 13.56758]\n",
            " [22.05197 24.59631]\n",
            " [-0.00128  0.00202]\n",
            " [ 7.08322  2.24986]\n",
            " [ 0.00008  0.00045]\n",
            " [12.55663  7.52172]\n",
            " [-0.00049  0.00017]\n",
            " [ 6.23372  1.67437]\n",
            " [ 8.40166  2.8925 ]\n",
            " [ 2.95755  1.77186]\n",
            " [ 9.047    6.42654]\n",
            " [ 4.021    0.98798]\n",
            " [11.10416  3.5837 ]\n",
            " [ 2.4617   0.73139]\n",
            " [19.80107 13.10075]\n",
            " [-0.00155  0.00041]\n",
            " [ 3.39747  1.74116]\n",
            " [ 7.06763  7.57847]\n",
            " [ 0.0015  -0.00011]\n",
            " [ 2.17815  2.1841 ]\n",
            " [ 0.00098  0.00088]\n",
            " [-0.00127 -0.00029]\n",
            " [ 2.65723  0.80212]\n",
            " [13.00121  1.48842]]\n",
            "Loss (MSE): 0.8235725\n",
            "\n",
            "Evaluation on a single validation datapoint:\n",
            "Ground-truth: [[ 0.       0.     ]\n",
            " [21.77992 16.27756]\n",
            " [ 2.61392  1.09328]\n",
            " [ 8.66518  1.38933]\n",
            " [ 0.       0.     ]\n",
            " [ 0.       0.     ]\n",
            " [16.24091 14.30709]\n",
            " [32.60472 23.55684]\n",
            " [ 0.       0.     ]\n",
            " [ 4.53463  1.21784]\n",
            " [ 0.       0.     ]\n",
            " [13.99406  7.27761]\n",
            " [ 0.       0.     ]\n",
            " [ 7.48298  1.80067]\n",
            " [ 8.23748  2.97107]\n",
            " [ 4.35331  1.35519]\n",
            " [ 8.28205  4.96784]\n",
            " [ 2.91661  0.57248]\n",
            " [10.14928  3.6665 ]\n",
            " [ 2.68847  0.57743]\n",
            " [18.24032  7.77604]\n",
            " [ 0.       0.     ]\n",
            " [ 2.04826  0.9852 ]\n",
            " [10.65625  9.28347]\n",
            " [ 0.       0.     ]\n",
            " [ 3.31512  2.02198]\n",
            " [ 0.       0.     ]\n",
            " [ 0.       0.     ]\n",
            " [ 2.97651  0.77062]\n",
            " [12.07064  2.12551]]\n",
            "Prediction: [[ 0.00006 -0.00014]\n",
            " [21.8125  15.9172 ]\n",
            " [ 2.81366  1.23666]\n",
            " [ 8.03823  1.54286]\n",
            " [-0.00087  0.0016 ]\n",
            " [-0.00014 -0.00034]\n",
            " [19.38161 13.21155]\n",
            " [33.21606 25.01344]\n",
            " [-0.00111  0.00157]\n",
            " [ 4.88336  1.45559]\n",
            " [ 0.00019  0.00055]\n",
            " [14.26756  7.73116]\n",
            " [-0.00038  0.00006]\n",
            " [ 6.88083  1.72513]\n",
            " [ 8.69199  2.73776]\n",
            " [ 3.899    1.62291]\n",
            " [ 8.48357  4.74667]\n",
            " [ 2.91132  0.92288]\n",
            " [10.2836   3.49071]\n",
            " [ 2.23038  0.65264]\n",
            " [16.41428  9.32579]\n",
            " [-0.00113  0.00052]\n",
            " [ 2.86016  1.76473]\n",
            " [ 8.78376  7.56516]\n",
            " [ 0.00132 -0.00005]\n",
            " [ 3.77373  2.39185]\n",
            " [ 0.00045  0.00094]\n",
            " [-0.00131 -0.00025]\n",
            " [ 2.80046  0.89134]\n",
            " [11.85303  1.99319]]\n",
            "Loss (MSE): 0.4988298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing on Multiple Datasets**\n",
        "\n",
        "Loading the Best Model"
      ],
      "metadata": {
        "id": "7SXapJIxhdqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = My_GNN_GNN_NN(n_bus, feat_in, feat_size1, feat_size2, hidden_size1, output_size)\n",
        "\n",
        "# Load the saved state dictionary\n",
        "#state_dict = torch.load(\"[14 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "#state_dict = torch.load(\"[30 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "state_dict = torch.load(\"[57 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "\n",
        "best_model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "best_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwIyhE7I7Dkf",
        "outputId": "b22094b2-9f45-47b8-f4d2-c26c54c1672d"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-145-02b386e07922>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(\"[30 bus] Best_GNN_GNN_NN_model.pt\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "My_GNN_GNN_NN(\n",
              "  (conv1): GCNConv(7, 16)\n",
              "  (conv2): GCNConv(16, 8)\n",
              "  (lin1): Linear(in_features=240, out_features=64, bias=True)\n",
              "  (lin2): Linear(in_features=64, out_features=60, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NRMSE Function**"
      ],
      "metadata": {
        "id": "MF6bivy1Eyhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NRMSE(yhat, y):\n",
        "    rmse = torch.sqrt(torch.mean((yhat - y) ** 2))\n",
        "    nrmse = rmse / torch.std(y)\n",
        "    return nrmse"
      ],
      "metadata": {
        "id": "v1vG8VRM7y7u"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Dataset Evaluation Loop**"
      ],
      "metadata": {
        "id": "KUMCfL-kE3Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_list = []\n",
        "\n",
        "for i in range(10):\n",
        "    # Load the test dataset\n",
        "    #dataset = pd.read_excel(f'/content/GNN-OptimalPowerFlow/Datasets/14Bus/PF_Dataset_{i + 1}.xlsx').values\n",
        "    #dataset = pd.read_excel(f'/content/GNN-OptimalPowerFlow/Datasets/30Bus/PF_Dataset_{i + 1}.xlsx').values\n",
        "    dataset = pd.read_excel(f'/content/GNN-OptimalPowerFlow/Datasets/57Bus/PF_Dataset_{i + 1}.xlsx').values\n",
        "\n",
        "    test_dataset = slice_dataset(dataset, 20)  # Use 20% of the test dataset\n",
        "    x_raw_test, y_raw_test = make_dataset(test_dataset, n_bus)\n",
        "    x_norm_test, y_norm_test, y_test_mean, y_test_std, _, _ = normalize_dataset(x_raw_test, y_raw_test)\n",
        "\n",
        "    # Extract only the target statistics (P and Q) from mean and std\n",
        "    y_test_mean_targets = y_test_mean[:, :2]  # Shape: [30, 2]\n",
        "    y_test_std_targets = y_test_std[:, :2]    # Shape: [30, 2]\n",
        "\n",
        "    # Prepare test data loader\n",
        "    data_test_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_test, y_norm_test)]\n",
        "    test_loader = DataLoader(data_test_list, batch_size=1)\n",
        "\n",
        "    # Initialize predictions\n",
        "    yhat = torch.empty(0, n_bus, 2)  # Shape: [n_samples, n_bus, 2]\n",
        "\n",
        "    # Collect predictions\n",
        "    for batch in test_loader:\n",
        "        y_pred = best_model(batch)\n",
        "        y_pred = y_pred.view(n_bus, 2)  # Reshape to [n_bus, 2]\n",
        "        yhat = torch.cat((yhat, y_pred.unsqueeze(0)))  # Add batch dimension\n",
        "\n",
        "    # Denormalize using only target statistics (P and Q)\n",
        "    yhat = denormalize_output(yhat, y_test_mean_targets, y_test_std_targets)\n",
        "    y_raw_test_denorm = denormalize_output(y_norm_test[:, :, :2], y_test_mean_targets, y_test_std_targets)\n",
        "\n",
        "    # Calculate NRMSE for the test dataset\n",
        "    test_loss_NRMSE = NRMSE(yhat, y_raw_test_denorm)\n",
        "\n",
        "    print(f\"Dataset {i + 1} | Test loss (NRMSE): {test_loss_NRMSE:.7f}\")\n",
        "    test_loss_list.append(test_loss_NRMSE)\n",
        "\n",
        "# Print summary of test losses\n",
        "print(\"Test Losses for All Datasets:\", test_loss_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoIbS0G4kDGM",
        "outputId": "fd33eda0-4af6-44cc-fd7b-8271e7c08302"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 1 | Test loss (NRMSE): 0.6313335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 2 | Test loss (NRMSE): 0.6338344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 3 | Test loss (NRMSE): 0.6350325\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 4 | Test loss (NRMSE): 0.6327797\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 5 | Test loss (NRMSE): 0.6354052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 6 | Test loss (NRMSE): 0.6348307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 7 | Test loss (NRMSE): 0.6327806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 8 | Test loss (NRMSE): 0.6342018\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 9 | Test loss (NRMSE): 0.6367190\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 10 | Test loss (NRMSE): 0.6351225\n",
            "Test Losses for All Datasets: [tensor(0.63133, grad_fn=<DivBackward0>), tensor(0.63383, grad_fn=<DivBackward0>), tensor(0.63503, grad_fn=<DivBackward0>), tensor(0.63278, grad_fn=<DivBackward0>), tensor(0.63541, grad_fn=<DivBackward0>), tensor(0.63483, grad_fn=<DivBackward0>), tensor(0.63278, grad_fn=<DivBackward0>), tensor(0.63420, grad_fn=<DivBackward0>), tensor(0.63672, grad_fn=<DivBackward0>), tensor(0.63512, grad_fn=<DivBackward0>)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving Test Losses**"
      ],
      "metadata": {
        "id": "Sq5bBwEOFib_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the test_loss_list is converted to a format that can be saved\n",
        "new_list = []\n",
        "\n",
        "# Convert each test loss value to a float and detach from the computation graph if needed\n",
        "for x in test_loss_list:\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        new_list.append(x.item())  # Use .item() for scalar tensors\n",
        "    else:\n",
        "        new_list.append(float(x))  # Convert to float if it's already a number\n",
        "\n",
        "# Create a DataFrame from the list\n",
        "test_loss_df = pd.DataFrame(new_list, columns=[\"Test Loss\"])\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "#test_loss_df.to_excel(\"[14 bus] Test Losses.xlsx\", index=False)\n",
        "#print(\"\\nTest loss file saved successfully as '[14 bus] Test Losses.xlsx'!\")\n",
        "\n",
        "#test_loss_df.to_excel(\"[30 bus] Test Losses.xlsx\", index=False)\n",
        "#print(\"\\nTest loss file saved successfully as '[30 bus] Test Losses.xlsx'!\")\n",
        "\n",
        "test_loss_df.to_excel(\"[57 bus] Test Losses.xlsx\", index=False)\n",
        "print(\"\\nTest loss file saved successfully as '[57 bus] Test Losses.xlsx'!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U-A856gFHz2",
        "outputId": "172880a4-c3a1-4c52-9de3-5c9bb07a97e2"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test loss file saved successfully as '[30 bus] Test Losses.xlsx'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Save test losses to Excel\n",
        "new_list = []\n",
        "for x in test_loss_list:\n",
        "    new_list.append(x.detach().numpy())\n",
        "\n",
        "test_loss_df = pd.DataFrame(new_list, columns=[\"Test Loss\"])\n",
        "test_loss_df.to_excel(\"[14 bus] Test Losses.xlsx\", index=False)\n",
        "print(\"\\nTest loss file saved!\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiuQ4Z22-0iZ",
        "outputId": "6b1eceff-21d3-4c70-b571-b61cafdd4dee"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test loss file saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IEEE 30 Bus DataSet Generation**\n",
        "\n",
        "It Contains 30 buses, 6 generators, 21 loads, and 41 branches.\n",
        "\n",
        "A classic test case for load flow and optimal power flow (OPF) studies.\n"
      ],
      "metadata": {
        "id": "6_lpkv2gTeoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandapower"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tKJsBPkTioB",
        "outputId": "1b70a494-0874-499e-ba18-ddf8f0f81fc1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandapower in /usr/local/lib/python3.10/dist-packages (2.14.11)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (2.2.2)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from pandapower) (3.4.2)\n",
            "Requirement already satisfied: scipy<1.14 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pandapower) (24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pandapower) (4.66.6)\n",
            "Requirement already satisfied: deepdiff in /usr/local/lib/python3.10/dist-packages (from pandapower) (8.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: orderly-set==5.2.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff->pandapower) (5.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->pandapower) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Create the output folder\n",
        "output_folder = \"datasets_30Bus\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Create the 30-bus test system using pandapower\n",
        "net = nw.case30()\n",
        "\n",
        "# Number of datasets and samples per dataset\n",
        "num_datasets = 10\n",
        "samples_per_dataset = 2000\n",
        "variation_range = 0.4  # ±40% random load variation\n",
        "\n",
        "# columns for the output Excel file\n",
        "bus_ids = net.bus.index\n",
        "columns = []\n",
        "\n",
        "# column names based on dataset format\n",
        "for bus in bus_ids:\n",
        "    columns.extend([f\"P_{bus + 1} (PQ)\", f\"Q_{bus + 1} (PQ)\", f\"V_{bus + 1}\", f\"d_{bus + 1}\"])\n",
        "\n",
        "# Store original load values for resetting\n",
        "original_p_values = net.load['p_mw'].copy()\n",
        "original_q_values = net.load['q_mvar'].copy()\n",
        "\n",
        "# Generate the datasets\n",
        "for dataset_n in range(1, num_datasets + 1):\n",
        "    print(f\"Generating dataset {dataset_n}...\")\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # initial power flow to stabilize the network\n",
        "    #try:\n",
        "    #    pp.runpp(net, algorithm='nr', max_iteration=20)\n",
        "    #except pp.LoadflowNotConverged:\n",
        "    #    print(f\"Initial load flow did not converge for dataset {dataset_n}, skipping this dataset.\")\n",
        "    #    continue\n",
        "\n",
        "    for sample in range(1, samples_per_dataset + 1):\n",
        "        # Reset the load values to the original values\n",
        "        net.load['p_mw'] = original_p_values\n",
        "        net.load['q_mvar'] = original_q_values\n",
        "\n",
        "        # Apply random variation based on the original values\n",
        "        for load in net.load.index:\n",
        "            net.load.at[load, 'p_mw'] = original_p_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "            net.load.at[load, 'q_mvar'] = original_q_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "\n",
        "        # Run AC power flow with Newton-Raphson algorithm\n",
        "        try:\n",
        "            pp.runpp(net, algorithm='nr', max_iteration=20)\n",
        "        except pp.LoadflowNotConverged:\n",
        "            print(f\"Load flow did not converge for sample {sample} in dataset {dataset_n}, skipping this sample.\")\n",
        "            continue\n",
        "\n",
        "        # Collect data for the current sample\n",
        "        row = []\n",
        "\n",
        "        for bus in bus_ids:\n",
        "            # Extract P and Q values for the bus (PQ buses only)\n",
        "            if bus in net.load['bus'].values:\n",
        "                p_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'p_mw'].sum()\n",
        "                q_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'q_mvar'].sum()\n",
        "            else:\n",
        "                p_load, q_load = 0, 0\n",
        "\n",
        "            # Extract V (voltage magnitude) and d (voltage angle)\n",
        "            v_mag = net.res_bus.at[bus, 'vm_pu']\n",
        "            v_ang = net.res_bus.at[bus, 'va_degree']\n",
        "\n",
        "            # Append data to the row in the specified format\n",
        "            row.extend([p_load, q_load, v_mag, v_ang])\n",
        "\n",
        "        # Add the row to the dataset\n",
        "        data.append(row)\n",
        "\n",
        "    # Create a DataFrame and add headers in the requested format\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "    df.insert(0, \"Data\", [f\"Data {i + 1}\" for i in range(len(df))])\n",
        "    df.insert(0, \"Dataset\", [f\"PF Dataset_{dataset_n}\"] + [\"\"] * (len(df) - 1))\n",
        "\n",
        "    # Save the DataFrame to Excel\n",
        "    output_filename = os.path.join(output_folder, f\"PF_Dataset_{dataset_n}.xlsx\")\n",
        "    df.to_excel(output_filename, index=False)\n",
        "    print(f\"Dataset {dataset_n} saved to {output_filename}\")\n",
        "\n",
        "print(\"All datasets generated successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93oaOPiuTp0B",
        "outputId": "738cff88-02e6-43c0-9e48-5dec8aee9c86"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dataset 1...\n",
            "Dataset 1 saved to datasets/PF_Dataset_1.xlsx\n",
            "Generating dataset 2...\n",
            "Dataset 2 saved to datasets/PF_Dataset_2.xlsx\n",
            "Generating dataset 3...\n",
            "Dataset 3 saved to datasets/PF_Dataset_3.xlsx\n",
            "Generating dataset 4...\n",
            "Dataset 4 saved to datasets/PF_Dataset_4.xlsx\n",
            "Generating dataset 5...\n",
            "Dataset 5 saved to datasets/PF_Dataset_5.xlsx\n",
            "Generating dataset 6...\n",
            "Dataset 6 saved to datasets/PF_Dataset_6.xlsx\n",
            "Generating dataset 7...\n",
            "Dataset 7 saved to datasets/PF_Dataset_7.xlsx\n",
            "Generating dataset 8...\n",
            "Dataset 8 saved to datasets/PF_Dataset_8.xlsx\n",
            "Generating dataset 9...\n",
            "Dataset 9 saved to datasets/PF_Dataset_9.xlsx\n",
            "Generating dataset 10...\n",
            "Dataset 10 saved to datasets/PF_Dataset_10.xlsx\n",
            "All datasets generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **30 Bus Generator Limits**\n",
        "\n",
        " Generated Active and Reactive Power (P and Q) should be bounded by their maximum and minimum capability for each bus.\n",
        "\n",
        " Otherwise the OPF will not converge for the network."
      ],
      "metadata": {
        "id": "AeQ0MuKV4_o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for cleaner output (optional)\n",
        "import pandas as pd\n",
        "\n",
        "# generator bus information\n",
        "gen_buses = net.gen['bus'].values  # The bus indices with generators\n",
        "p_gen = net.res_gen['p_mw'].values\n",
        "q_gen = net.res_gen['q_mvar'].values\n",
        "\n",
        "# detailed information for each generator\n",
        "print(\"Generator Information:\")\n",
        "for i, bus in enumerate(gen_buses):\n",
        "    p_max = net.gen.at[i, 'max_p_mw'] if 'max_p_mw' in net.gen.columns else \"N/A\"\n",
        "    q_max = net.gen.at[i, 'max_q_mvar'] if 'max_q_mvar' in net.gen.columns else \"N/A\"\n",
        "    print(f\"Bus {bus} | Active Power (P_gen): {p_gen[i]:.2f} MW | Reactive Power (Q_gen): {q_gen[i]:.2f} MVar | P_max: {p_max} MW | Q_max: {q_max} MVar\")\n",
        "\n",
        "print(\"\\nFull Generator DataFrame:\")\n",
        "print(net.gen)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYArq7UJuCfS",
        "outputId": "6b93e851-7870-483a-f48e-cc3f032748a3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Information:\n",
            "Bus 1 | Active Power (P_gen): 60.97 MW | Reactive Power (Q_gen): 37.38 MVar | P_max: 80.0 MW | Q_max: 60.0 MVar\n",
            "Bus 21 | Active Power (P_gen): 21.59 MW | Reactive Power (Q_gen): 40.45 MVar | P_max: 50.0 MW | Q_max: 62.5 MVar\n",
            "Bus 26 | Active Power (P_gen): 26.91 MW | Reactive Power (Q_gen): 11.79 MVar | P_max: 55.0 MW | Q_max: 48.7 MVar\n",
            "Bus 22 | Active Power (P_gen): 19.20 MW | Reactive Power (Q_gen): 7.34 MVar | P_max: 30.0 MW | Q_max: 40.0 MVar\n",
            "Bus 12 | Active Power (P_gen): 37.00 MW | Reactive Power (Q_gen): 10.96 MVar | P_max: 40.0 MW | Q_max: 44.7 MVar\n",
            "\n",
            "Full Generator DataFrame:\n",
            "   name  bus   p_mw  vm_pu  sn_mva  min_q_mvar  max_q_mvar  scaling  slack  \\\n",
            "0  None    1  60.97    1.0     NaN       -20.0        60.0      1.0  False   \n",
            "1  None   21  21.59    1.0     NaN       -15.0        62.5      1.0  False   \n",
            "2  None   26  26.91    1.0     NaN       -15.0        48.7      1.0  False   \n",
            "3  None   22  19.20    1.0     NaN       -10.0        40.0      1.0  False   \n",
            "4  None   12  37.00    1.0     NaN       -15.0        44.7      1.0  False   \n",
            "\n",
            "   in_service  slack_weight  type  controllable  max_p_mw  min_p_mw  \n",
            "0        True           0.0  None          True      80.0       0.0  \n",
            "1        True           0.0  None          True      50.0       0.0  \n",
            "2        True           0.0  None          True      55.0       0.0  \n",
            "3        True           0.0  None          True      30.0       0.0  \n",
            "4        True           0.0  None          True      40.0       0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize lists to track generator outputs\n",
        "p_gen_list = []\n",
        "q_gen_list = []\n",
        "\n",
        "# Run power flow and log generator outputs for multiple test cases\n",
        "for i in range(10):  # 10 datasets\n",
        "    try:\n",
        "        pp.runpp(net, algorithm='nr', max_iteration=20)\n",
        "\n",
        "        # Get generator active and reactive power outputs\n",
        "        p_gen = net.res_gen['p_mw'].values\n",
        "        q_gen = net.res_gen['q_mvar'].values\n",
        "\n",
        "        # Log the generator outputs\n",
        "        p_gen_list.append(p_gen)\n",
        "        q_gen_list.append(q_gen)\n",
        "\n",
        "        print(f\"Test Case {i + 1}:\")\n",
        "        print(\"Active Power (P_gen):\", p_gen)\n",
        "        print(\"Reactive Power (Q_gen):\", q_gen)\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "    except pp.LoadflowNotConverged:\n",
        "        print(f\"Load flow did not converge for Test Case {i + 1}, skipping...\")\n",
        "        continue\n",
        "\n",
        "# Convert to DataFrame for easier comparison\n",
        "p_gen_df = pd.DataFrame(p_gen_list, columns=[f\"P_gen_{i}\" for i in range(len(p_gen))])\n",
        "q_gen_df = pd.DataFrame(q_gen_list, columns=[f\"Q_gen_{i}\" for i in range(len(q_gen))])\n",
        "\n",
        "# Save the results to Excel for further analysis\n",
        "p_gen_df.to_excel(\"P_gen_changes.xlsx\", index=False)\n",
        "q_gen_df.to_excel(\"Q_gen_changes.xlsx\", index=False)\n",
        "\n",
        "print(\"Generator outputs logged and saved to 'P_gen_changes.xlsx' and 'Q_gen_changes.xlsx'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vn0PtHlwYKz",
        "outputId": "67734627-7d5e-429b-9e22-3b602d611c0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 1:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 2:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 3:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 4:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 5:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 6:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 7:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 8:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 9:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 10:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 11:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 12:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 13:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 14:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 15:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 16:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 17:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 18:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 19:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 20:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 21:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 22:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 23:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 24:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 25:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 26:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 27:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 28:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 29:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 30:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 31:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 32:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 33:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 34:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 35:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 36:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 37:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 38:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 39:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 40:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 41:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 42:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 43:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 44:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 45:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 46:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 47:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 48:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 49:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 50:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 51:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 52:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 53:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 54:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 55:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 56:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 57:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 58:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 59:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 60:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 61:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 62:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 63:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 64:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 65:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 66:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 67:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 68:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 69:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 70:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 71:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 72:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 73:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 74:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 75:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 76:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 77:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 78:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 79:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 80:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 81:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 82:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 83:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 84:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 85:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 86:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 87:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 88:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 89:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 90:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 91:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 92:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 93:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 94:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 95:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 96:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 97:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 98:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 99:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 100:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 101:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 102:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Generator outputs logged and saved to 'P_gen_changes.xlsx' and 'Q_gen_changes.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IEEE 57 Bus DataSet Generation**\n",
        "\n",
        "Contains 57 buses, 7 generators, 42 loads, and 80 branches.\n",
        "\n",
        "Commonly used for testing load flow and contingency analysis."
      ],
      "metadata": {
        "id": "ySJfKeBtCDkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandapower"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHOCYB1bOk0i",
        "outputId": "066f7775-07a2-47ca-8d12-3baa89ea6f60"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandapower in /usr/local/lib/python3.10/dist-packages (2.14.11)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (2.2.2)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from pandapower) (3.4.2)\n",
            "Requirement already satisfied: scipy<1.14 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pandapower) (24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pandapower) (4.66.6)\n",
            "Requirement already satisfied: deepdiff in /usr/local/lib/python3.10/dist-packages (from pandapower) (8.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: orderly-set==5.2.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff->pandapower) (5.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->pandapower) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Create the output folder\n",
        "output_folder = \"datasets_57Bus\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load the 57-bus test system using pandapower\n",
        "net = nw.case57()\n",
        "\n",
        "# Number of datasets and samples per dataset\n",
        "num_datasets = 10\n",
        "samples_per_dataset = 2000\n",
        "variation_range = 0.4  # ±40% random load variation\n",
        "\n",
        "# Define the columns for the output Excel file\n",
        "bus_ids = net.bus.index\n",
        "columns = []\n",
        "\n",
        "# Create column names based on your dataset format\n",
        "for bus in bus_ids:\n",
        "    columns.extend([f\"P_{bus + 1} (PQ)\", f\"Q_{bus + 1} (PQ)\", f\"V_{bus + 1}\", f\"d_{bus + 1}\"])\n",
        "\n",
        "# Store original load values for resetting\n",
        "original_p_values = net.load['p_mw'].copy()\n",
        "original_q_values = net.load['q_mvar'].copy()\n",
        "\n",
        "# Generate the datasets\n",
        "for dataset_n in range(1, num_datasets + 1):\n",
        "    print(f\"Generating dataset {dataset_n}...\")\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for sample in range(1, samples_per_dataset + 1):\n",
        "        # Reset the load values to the original values\n",
        "        net.load['p_mw'] = original_p_values\n",
        "        net.load['q_mvar'] = original_q_values\n",
        "\n",
        "        # Apply random variation based on the original values\n",
        "        for load in net.load.index:\n",
        "            net.load.at[load, 'p_mw'] = original_p_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "            net.load.at[load, 'q_mvar'] = original_q_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "\n",
        "        # Run AC power flow with Newton-Raphson algorithm\n",
        "        try:\n",
        "            pp.runpp(net, algorithm='nr', max_iteration=30)\n",
        "        except pp.LoadflowNotConverged:\n",
        "            print(f\"Load flow did not converge for sample {sample} in dataset {dataset_n}, skipping this sample.\")\n",
        "            continue\n",
        "\n",
        "        # Collect data for the current sample\n",
        "        row = []\n",
        "\n",
        "        for bus in bus_ids:\n",
        "            # Extract P and Q values for the bus (PQ buses only)\n",
        "            if bus in net.load['bus'].values:\n",
        "                p_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'p_mw'].sum()\n",
        "                q_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'q_mvar'].sum()\n",
        "            else:\n",
        "                p_load, q_load = 0, 0\n",
        "\n",
        "            # Extract V (voltage magnitude) and d (voltage angle)\n",
        "            v_mag = net.res_bus.at[bus, 'vm_pu']\n",
        "            v_ang = net.res_bus.at[bus, 'va_degree']\n",
        "\n",
        "            # Append data to the row in the specified format\n",
        "            row.extend([p_load, q_load, v_mag, v_ang])\n",
        "\n",
        "        # Add the row to the dataset\n",
        "        data.append(row)\n",
        "\n",
        "    # Create a DataFrame and add headers in the requested format\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    df.insert(0, \"Data\", [f\"Data {i + 1}\" for i in range(len(df))])\n",
        "    df.insert(0, \"Dataset\", [f\"PF Dataset_{dataset_n}\"] + [\"\"] * (len(df) - 1))\n",
        "\n",
        "    # Save the DataFrame to Excel\n",
        "    output_filename = os.path.join(output_folder, f\"PF_Dataset_{dataset_n}.xlsx\")\n",
        "    df.to_excel(output_filename, index=False)\n",
        "    print(f\"Dataset {dataset_n} saved to {output_filename}\")\n",
        "\n",
        "print(\"All datasets generated successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKT0Xj1IOcrf",
        "outputId": "87bdc83d-c839-4026-bc85-e3909a108110"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dataset 1...\n",
            "Dataset 1 saved to datasets_57Bus/PF_Dataset_1.xlsx\n",
            "Generating dataset 2...\n",
            "Dataset 2 saved to datasets_57Bus/PF_Dataset_2.xlsx\n",
            "Generating dataset 3...\n",
            "Dataset 3 saved to datasets_57Bus/PF_Dataset_3.xlsx\n",
            "Generating dataset 4...\n",
            "Dataset 4 saved to datasets_57Bus/PF_Dataset_4.xlsx\n",
            "Generating dataset 5...\n",
            "Dataset 5 saved to datasets_57Bus/PF_Dataset_5.xlsx\n",
            "Generating dataset 6...\n",
            "Dataset 6 saved to datasets_57Bus/PF_Dataset_6.xlsx\n",
            "Generating dataset 7...\n",
            "Dataset 7 saved to datasets_57Bus/PF_Dataset_7.xlsx\n",
            "Generating dataset 8...\n",
            "Dataset 8 saved to datasets_57Bus/PF_Dataset_8.xlsx\n",
            "Generating dataset 9...\n",
            "Dataset 9 saved to datasets_57Bus/PF_Dataset_9.xlsx\n",
            "Generating dataset 10...\n",
            "Dataset 10 saved to datasets_57Bus/PF_Dataset_10.xlsx\n",
            "All datasets generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**57 Bus Generator Limits**\n",
        "\n",
        " Generated Active and Reactive Power (P and Q) should be bounded by their maximum and minimum capability for each bus.\n",
        "\n",
        " Otherwise the OPF will not converge for the network."
      ],
      "metadata": {
        "id": "0my7n9SIPNvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for cleaner output\n",
        "import pandas as pd\n",
        "\n",
        "# generator bus information\n",
        "gen_buses = net.gen['bus'].values  # The bus indices with generators\n",
        "p_gen = net.res_gen['p_mw'].values\n",
        "q_gen = net.res_gen['q_mvar'].values\n",
        "\n",
        "# detailed information for each generator\n",
        "print(\"Generator Information:\")\n",
        "for i, bus in enumerate(gen_buses):\n",
        "    p_max = net.gen.at[i, 'max_p_mw'] if 'max_p_mw' in net.gen.columns else \"N/A\"\n",
        "    q_max = net.gen.at[i, 'max_q_mvar'] if 'max_q_mvar' in net.gen.columns else \"N/A\"\n",
        "    print(f\"Bus {bus} | Active Power (P_gen): {p_gen[i]:.2f} MW | Reactive Power (Q_gen): {q_gen[i]:.2f} MVar | P_max: {p_max} MW | Q_max: {q_max} MVar\")\n",
        "\n",
        "print(\"\\nFull Generator DataFrame:\")\n",
        "print(net.gen)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0XK26Y4CDUc",
        "outputId": "339174ab-6db4-4976-9353-ded89e057daf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Information:\n",
            "Bus 1 | Active Power (P_gen): 0.00 MW | Reactive Power (Q_gen): 29.40 MVar | P_max: 100.0 MW | Q_max: 50.0 MVar\n",
            "Bus 2 | Active Power (P_gen): 40.00 MW | Reactive Power (Q_gen): -9.46 MVar | P_max: 140.0 MW | Q_max: 60.0 MVar\n",
            "Bus 5 | Active Power (P_gen): 0.00 MW | Reactive Power (Q_gen): 12.11 MVar | P_max: 100.0 MW | Q_max: 25.0 MVar\n",
            "Bus 7 | Active Power (P_gen): 450.00 MW | Reactive Power (Q_gen): 74.54 MVar | P_max: 550.0 MW | Q_max: 200.0 MVar\n",
            "Bus 8 | Active Power (P_gen): 0.00 MW | Reactive Power (Q_gen): -21.24 MVar | P_max: 100.0 MW | Q_max: 9.0 MVar\n",
            "Bus 11 | Active Power (P_gen): 310.00 MW | Reactive Power (Q_gen): 109.47 MVar | P_max: 410.0 MW | Q_max: 155.0 MVar\n",
            "\n",
            "Full Generator DataFrame:\n",
            "   name  bus   p_mw  vm_pu  sn_mva  min_q_mvar  max_q_mvar  scaling  slack  \\\n",
            "0  None    1    0.0  1.010     NaN       -17.0        50.0      1.0  False   \n",
            "1  None    2   40.0  0.985     NaN       -10.0        60.0      1.0  False   \n",
            "2  None    5    0.0  0.980     NaN        -8.0        25.0      1.0  False   \n",
            "3  None    7  450.0  1.005     NaN      -140.0       200.0      1.0  False   \n",
            "4  None    8    0.0  0.980     NaN        -3.0         9.0      1.0  False   \n",
            "5  None   11  310.0  1.015     NaN      -150.0       155.0      1.0  False   \n",
            "\n",
            "   in_service  slack_weight  type  controllable  max_p_mw  min_p_mw  \n",
            "0        True           0.0  None          True     100.0       0.0  \n",
            "1        True           0.0  None          True     140.0       0.0  \n",
            "2        True           0.0  None          True     100.0       0.0  \n",
            "3        True           0.0  None          True     550.0       0.0  \n",
            "4        True           0.0  None          True     100.0       0.0  \n",
            "5        True           0.0  None          True     410.0       0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Histogram**\n",
        "\n",
        "Histograms is used to see which architecture has a better and more consistent performance (narrower, left-skewed distribution)\n",
        "\n",
        "Histograms is used to compare:\n",
        "\n",
        "1.   Different bus systems (e.g., 14-bus vs. 30-bus vs. 57-bus) using the same GNN architecture.\n",
        "\n",
        "2.   It can also be used to compare different GNN architectures for a same network to see the effect\n",
        "\n",
        "\n",
        "**Histogram Goal:**\n",
        "\n",
        "\n",
        "\n",
        "*   Mean and Median Values: Lower mean and median values indicate better performance.\n",
        "\n",
        "*   Spread of Distribution: A narrower histogram indicates more consistent performance (less variance).\n",
        "\n",
        "*   Left-Skewed Distribution: A left-skewed histogram (with most losses near zero) indicates good generalization.\n",
        "\n"
      ],
      "metadata": {
        "id": "pmyF3Eb1KKQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the test loss data from each Excel file\n",
        "bus_14_loss_data = pd.read_excel('[14 bus] Test Losses.xlsx').values.flatten()\n",
        "bus_30_loss_data = pd.read_excel('[30 bus] Test Losses.xlsx').values.flatten()\n",
        "\n",
        "# mean and median for each bus system\n",
        "mean_14 = np.mean(bus_14_loss_data)\n",
        "median_14 = np.median(bus_14_loss_data)\n",
        "\n",
        "mean_30 = np.mean(bus_30_loss_data)\n",
        "median_30 = np.median(bus_30_loss_data)\n",
        "\n",
        "\n",
        "# Print the statistics\n",
        "print(f\"14-bus system - Mean: {mean_14:.5f}, Median: {median_14:.5f}\")\n",
        "print(f\"30-bus system - Mean: {mean_30:.5f}, Median: {median_30:.5f}\")\n",
        "\n",
        "# histogram plotting parameters\n",
        "kwargs = dict(histtype='stepfilled', alpha=0.5, density=True, bins=20)\n",
        "\n",
        "# labels for the histograms\n",
        "label_14 = f\"14-bus, Mean: {mean_14:.5f}, Median: {median_14:.5f}\"\n",
        "label_30 = f\"30-bus, Mean: {mean_30:.5f}, Median: {median_30:.5f}\"\n",
        "\n",
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(bus_14_loss_data, label=label_14, **kwargs)\n",
        "plt.hist(bus_30_loss_data, label=label_30, **kwargs)\n",
        "\n",
        "# plot details\n",
        "plt.title('Comparison of Test Loss Distributions Across Different Test Case Networks')\n",
        "plt.xlabel('Test Loss (MSE or NRMSE)')\n",
        "plt.ylabel('Density')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Qc_Y31iUKMWJ",
        "outputId": "2f667993-768e-4851-f639-55e1b9b9912a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '[14 bus] Test Losses.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bf62279d52f2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the test loss data from each Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbus_14_loss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[14 bus] Test Losses.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbus_30_loss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[30 bus] Test Losses.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '[14 bus] Test Losses.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Wqd4N8uM6os"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}