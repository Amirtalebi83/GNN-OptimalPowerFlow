{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "duxl-KR0h-yT",
        "RP6v7qQi0qnq",
        "jkFs_7lLiDgc",
        "d6FSlADZvciE",
        "_KGnM5dw1F2t",
        "A292k3swxQIB",
        "4sIrVikD1cFX",
        "_ftmcK3i1hBr",
        "uEV6qiKl1yLZ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEZO9Oc5ifIT",
        "outputId": "0c70e7b5-d609-4d39-ac18-7dc6eab1b31c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'GNN-OptimalPowerFlow'...\n",
            "remote: Enumerating objects: 283, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 283 (delta 8), reused 6 (delta 6), pack-reused 273 (from 1)\u001b[K\n",
            "Receiving objects: 100% (283/283), 260.31 MiB | 40.50 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n",
            "/content/GNN-OptimalPowerFlow\n",
            " Datasets   document  'jupyter notebook'   README.md\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Clone GitHub repository\n",
        "!git clone https://github.com/Amirtalebi83/GNN-OptimalPowerFlow.git\n",
        "%cd GNN-OptimalPowerFlow\n",
        "\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyTorch and PyTorch Geometric\n",
        "!pip install torch\n",
        "!pip install torch-geometric\n",
        "!pip install pandas openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFKnT4mUkcMj",
        "outputId": "478c7e10-2973-4842-e26e-df8e64e4336b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset --hard HEAD #Reset Any Local Changes\n",
        "!git pull origin main #Pull the Latest Changes from GitHub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC2cAxHHyg27",
        "outputId": "dccf16bd-7388-4ea3-a230-a3e98e5cac2f"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/Amirtalebi83/GNN-OptimalPowerFlow\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content #Remove the local folder and cloning the repository again\n",
        "!rm -rf GNN-OptimalPowerFlow"
      ],
      "metadata": {
        "id": "eQropCnvyrhy"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf GNN-OptimalPowerFlow"
      ],
      "metadata": {
        "id": "wkf78Nes-ZHp"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Amirtalebi83/GNN-OptimalPowerFlow.git\n",
        "!ls -la GNN-OptimalPowerFlow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L92XdvEc0BQx",
        "outputId": "8fec4c2c-66f9-46c5-f943-40356ddbe274"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GNN-OptimalPowerFlow'...\n",
            "remote: Enumerating objects: 283, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 283 (delta 8), reused 6 (delta 6), pack-reused 273 (from 1)\u001b[K\n",
            "Receiving objects: 100% (283/283), 260.31 MiB | 31.53 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n",
            "Updating files: 100% (54/54), done.\n",
            "total 36\n",
            "drwxr-xr-x 6 root root  4096 Nov 14 23:19  .\n",
            "drwxr-xr-x 7 root root  4096 Nov 14 23:19  ..\n",
            "drwxr-xr-x 5 root root  4096 Nov 14 23:19  Datasets\n",
            "drwxr-xr-x 2 root root  4096 Nov 14 23:19  document\n",
            "drwxr-xr-x 8 root root  4096 Nov 14 23:19  .git\n",
            "drwxr-xr-x 2 root root  4096 Nov 14 23:19 'jupyter notebook'\n",
            "-rw-r--r-- 1 root root 10321 Nov 14 23:19  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "z9b3fjl7z_Vj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PAXH3kw-lhBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "import torch_geometric.nn as pyg_nn\n",
        "from torch_geometric.nn import GCNConv, GraphConv, SAGEConv, GATConv, ChebConv\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set print options for better readability\n",
        "np.set_printoptions(precision=5, suppress=True)\n",
        "torch.set_printoptions(precision=5, sci_mode=False)\n"
      ],
      "metadata": {
        "id": "baBqQiLOjL_U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandapower"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d_kPAYJLXfp",
        "outputId": "b3ae56d0-212a-4f67-c0ca-38edae570319"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandapower\n",
            "  Downloading pandapower-2.14.11.zip (13.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (2.2.2)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from pandapower) (3.4.2)\n",
            "Requirement already satisfied: scipy<1.14 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pandapower) (24.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pandapower) (4.66.6)\n",
            "Collecting deepdiff (from pandapower)\n",
            "  Downloading deepdiff-8.0.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Collecting orderly-set==5.2.2 (from deepdiff->pandapower)\n",
            "  Downloading orderly_set-5.2.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->pandapower) (1.16.0)\n",
            "Downloading deepdiff-8.0.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orderly_set-5.2.2-py3-none-any.whl (11 kB)\n",
            "Building wheels for collected packages: pandapower\n",
            "  Building wheel for pandapower (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandapower: filename=pandapower-2.14.11-py3-none-any.whl size=13131028 sha256=25193508472e367355ef7a2e1c605f1cb11d40109ca7aab3743f0a537b7c905b\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/de/5a/7b00f385eb06d1fb1f7c1cd06f9bb901709c038d3899548cf1\n",
            "Successfully built pandapower\n",
            "Installing collected packages: orderly-set, deepdiff, pandapower\n",
            "Successfully installed deepdiff-8.0.1 orderly-set-5.2.2 pandapower-2.14.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Preparation**"
      ],
      "metadata": {
        "id": "NBWjoAqRoHaU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data, DataLoader"
      ],
      "metadata": {
        "id": "xKA8rxaeLOzQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import is_\n",
        "def slice_dataset(dataset, percentage):\n",
        "    data_size = len(dataset)\n",
        "    return dataset[:int(data_size * percentage / 100)]\n",
        "\n",
        "def make_dataset(dataset, n_bus):\n",
        "    x_raw, y_raw = [], []\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        x_sample, y_sample = [], []\n",
        "        for n in range(n_bus):\n",
        "            # Define bus type: Slack (1), PQ (2), PV (3)\n",
        "            is_pv = 0\n",
        "            is_pq = 0\n",
        "            is_slack = 0\n",
        "            if n == 0:  # Slack bus is always bus 0\n",
        "                is_slack = 1\n",
        "            elif dataset[i, 4 * n + 2] == 0:  # Q = 0 indicates PV bus\n",
        "                is_pv = 1\n",
        "            else:\n",
        "                is_pq = 1  # PQ bus\n",
        "\n",
        "            # Include P, Q, V, delta, and bus type as features\n",
        "            x_sample.append([\n",
        "                dataset[i, 4 * n + 1],  # P\n",
        "                dataset[i, 4 * n + 2],  # Q\n",
        "                dataset[i, 4 * n + 3],  # V\n",
        "                dataset[i, 4 * n + 4],  # delta\n",
        "                is_pv,                # Bus type\n",
        "                is_pq,\n",
        "                is_slack\n",
        "            ])\n",
        "\n",
        "            # Use P and Q as targets\n",
        "            y_sample.append([\n",
        "                # dataset[i, 4 * n + 1],  # P (target)\n",
        "                # dataset[i, 4 * n + 2],   # Q (target)\n",
        "                dataset[i, 4 * n + 3],   # V (target)\n",
        "                dataset[i, 4 * n + 4]   # D (target)\n",
        "            ])\n",
        "\n",
        "        x_raw.append(x_sample)\n",
        "        y_raw.append(y_sample)\n",
        "\n",
        "    # Convert to PyTorch tensors\n",
        "    x_raw = torch.tensor(x_raw, dtype=torch.float)\n",
        "    y_raw = torch.tensor(y_raw, dtype=torch.float)\n",
        "    return x_raw, y_raw\n"
      ],
      "metadata": {
        "id": "xqY7cbqkngcS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_dataset(x, y):\n",
        "    # Compute mean and standard deviation for features and targets\n",
        "    x_mean, x_std = torch.mean(x, 0), torch.std(x, 0)\n",
        "    y_mean, y_std = torch.mean(y, 0), torch.std(y, 0)\n",
        "\n",
        "    # Handle zero standard deviation to avoid division by zero\n",
        "    x_std[x_std == 0] = 1\n",
        "    y_std[y_std == 0] = 1\n",
        "\n",
        "    # Normalize the input features except for the bus type, Bus type should not be normalized as it is (1, 2, or 3)\n",
        "    x_norm = (x - x_mean) / x_std\n",
        "    x_norm[:, :, 4] = x[:, :, 4]\n",
        "\n",
        "    # Normalize the targets\n",
        "    y_norm = (y - y_mean) / y_std\n",
        "\n",
        "    return x_norm, y_norm, x_mean, y_mean, x_std, y_std\n",
        "\n",
        "def denormalize_output(y_norm, y_mean, y_std):\n",
        "    return y_norm * y_std + y_mean\n",
        "\n",
        "def MSE(yhat, y):\n",
        "    return torch.mean((yhat - y) ** 2)\n"
      ],
      "metadata": {
        "id": "IHHpynA4oRtO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Dataset**"
      ],
      "metadata": {
        "id": "5ESaGHxvmHAO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **14 Bus Only**"
      ],
      "metadata": {
        "id": "Dm_QSMHnh5qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# Load dataset from Excel files\n",
        "dataset1 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/14Bus/PF_Dataset_1.xlsx').values\n",
        "dataset2 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/14Bus/PF_Dataset_2.xlsx').values\n",
        "\n",
        "# Split the dataset\n",
        "train_percentage = 100\n",
        "val_percentage = 100\n",
        "\n",
        "train_dataset = slice_dataset(dataset1, train_percentage)\n",
        "val_dataset = slice_dataset(dataset2, val_percentage)\n",
        "\n",
        "n_bus = 14\n",
        "\n",
        "# # Prepare training and validation data\n",
        "x_raw_train, y_raw_train = make_dataset(train_dataset, n_bus)\n",
        "x_raw_val, y_raw_val = make_dataset(val_dataset, n_bus)\n",
        "\n",
        "# Normalize the raw data\n",
        "x_norm_train, y_norm_train, x_train_mean, y_train_mean, x_train_std, y_train_std = normalize_dataset(x_raw_train, y_raw_train)\n",
        "x_norm_val, y_norm_val, x_val_mean, y_val_mean, x_val_std, y_val_std = normalize_dataset(x_raw_val, y_raw_val)\n",
        "\n",
        "# Prepare DataLoader for PyTorch Geometric\n",
        "# Load the IEEE 14-bus test case using pandapower\n",
        "net = nw.case14()\n",
        "\n",
        "# Get the 'from_bus' and 'to_bus' for each line in the network\n",
        "from_buses = net.line['from_bus'].values\n",
        "to_buses = net.line['to_bus'].values\n",
        "\n",
        "# Construct the edge index (bidirectional edges)\n",
        "edge_index = torch.tensor([list(from_buses) + list(to_buses), list(to_buses) + list(from_buses)], dtype=torch.long)\n",
        "\n",
        "print(\"Edge Index for IEEE 14-bus System:\")\n",
        "print(edge_index)\n",
        "\n",
        "# Create Data objects for PyTorch Geometric\n",
        "train_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_train, y_norm_train)]\n",
        "val_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_val, y_norm_val)]\n",
        "\n",
        "# Prepare DataLoaders\n",
        "train_loader = DataLoader(train_data_list, batch_size=16)\n",
        "val_loader = DataLoader(val_data_list, batch_size=16)\n",
        "\n",
        "print(\"Data preparation completed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxr4mBoojyA-",
        "outputId": "cf8e6e53-dae7-431a-e964-316e66cec738"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge Index for IEEE 14-bus System:\n",
            "tensor([[ 0,  0,  1,  1,  1,  2,  3,  5,  5,  5,  8,  8,  9, 11, 12,  1,  4,  2,\n",
            "          3,  4,  3,  4, 10, 11, 12,  9, 13, 10, 12, 13],\n",
            "        [ 1,  4,  2,  3,  4,  3,  4, 10, 11, 12,  9, 13, 10, 12, 13,  0,  0,  1,\n",
            "          1,  1,  2,  3,  5,  5,  5,  8,  8,  9, 11, 12]])\n",
            "Data preparation completed successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **30 Bus Only**\n",
        "\n",
        "1. **Data Preparation:** Load and filter the dataset\n",
        "\n",
        "2. **Normalization:**\n",
        "Normalize the data (normalize_dataset)\n",
        "\n",
        "3. **Filter Constant Features:** Identify and remove constant features"
      ],
      "metadata": {
        "id": "duxl-KR0h-yT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_raw_train.shape)\n",
        "print(y_norm_train.shape)\n",
        "\n",
        "print(x_raw_train.shape)\n",
        "print(x_norm_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtCPIW4MyITc",
        "outputId": "289c65aa-c57a-4d60-f044-00047998a99c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2000, 57, 2])\n",
            "torch.Size([2000, 57, 2])\n",
            "torch.Size([2000, 57, 7])\n",
            "torch.Size([2000, 57, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# Load dataset from Excel files\n",
        "dataset1 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/30Bus/PF_Dataset_1.xlsx').values\n",
        "dataset2 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/30Bus/PF_Dataset_2.xlsx').values\n",
        "\n",
        "# Split the dataset\n",
        "train_percentage = 100\n",
        "val_percentage = 100\n",
        "\n",
        "train_dataset = slice_dataset(dataset1, train_percentage)\n",
        "val_dataset = slice_dataset(dataset2, val_percentage)\n",
        "\n",
        "n_bus = 30\n",
        "\n",
        "# Prepare training and validation data\n",
        "x_raw_train, y_raw_train = make_dataset(train_dataset, n_bus)\n",
        "x_raw_val, y_raw_val = make_dataset(val_dataset, n_bus)\n",
        "\n",
        "# Normalize the raw data\n",
        "x_norm_train, y_norm_train, x_train_mean, y_train_mean, x_train_std, y_train_std = normalize_dataset(x_raw_train, y_raw_train)\n",
        "x_norm_val, y_norm_val, x_val_mean, y_val_mean, x_val_std, y_val_std = normalize_dataset(x_raw_val, y_raw_val)\n",
        "\n",
        "# Prepare DataLoader for PyTorch Geometric\n",
        "# Load the IEEE 30-bus test case using pandapower\n",
        "net = nw.case30()\n",
        "\n",
        "# Get the 'from_bus' and 'to_bus' for each line in the network\n",
        "from_buses = net.line['from_bus'].values\n",
        "to_buses = net.line['to_bus'].values\n",
        "\n",
        "# Construct the edge index (bidirectional edges)\n",
        "edge_index = torch.tensor([list(from_buses) + list(to_buses), list(to_buses) + list(from_buses)], dtype=torch.long)\n",
        "\n",
        "print(\"Edge Index for IEEE 30-bus System:\")\n",
        "print(edge_index)\n",
        "\n",
        "# Create Data objects for PyTorch Geometric\n",
        "train_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_train, y_norm_train)]\n",
        "val_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_val, y_norm_val)]\n",
        "\n",
        "# Prepare DataLoaders\n",
        "train_loader = DataLoader(train_data_list, batch_size=16)\n",
        "val_loader = DataLoader(val_data_list, batch_size=16)\n",
        "\n",
        "print(\"Data preparation completed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaQbb0UuLiUa",
        "outputId": "1d158dab-3083-466e-c524-7c196c18ecfc"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge Index for IEEE 30-bus System:\n",
            "tensor([[ 0,  0,  1,  2,  1,  1,  3,  4,  5,  5,  5,  5,  8,  8,  3, 11, 11, 11,\n",
            "         11, 13, 15, 14, 17, 18,  9,  9,  9,  9, 20, 14, 21, 22, 23, 24, 24, 27,\n",
            "         26, 26, 28,  7,  5,  1,  2,  3,  3,  4,  5,  5,  6,  6,  7,  8,  9, 10,\n",
            "          9, 11, 12, 13, 14, 15, 14, 16, 17, 18, 19, 19, 16, 20, 21, 21, 22, 23,\n",
            "         23, 24, 25, 26, 26, 28, 29, 29, 27, 27],\n",
            "        [ 1,  2,  3,  3,  4,  5,  5,  6,  6,  7,  8,  9, 10,  9, 11, 12, 13, 14,\n",
            "         15, 14, 16, 17, 18, 19, 19, 16, 20, 21, 21, 22, 23, 23, 24, 25, 26, 26,\n",
            "         28, 29, 29, 27, 27,  0,  0,  1,  2,  1,  1,  3,  4,  5,  5,  5,  5,  8,\n",
            "          8,  3, 11, 11, 11, 11, 13, 15, 14, 17, 18,  9,  9,  9,  9, 20, 14, 21,\n",
            "         22, 23, 24, 24, 27, 26, 26, 28,  7,  5]])\n",
            "Data preparation completed successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "RP6v7qQi0qnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(\"x_std_raw:\", x_std_raw)\n",
        "#print(\"y_std_raw:\", y_std_raw)\n",
        "\n",
        "# print(\"Number of NaNs in x_norm_train:\", torch.isnan(x_norm_train).sum().item())\n",
        "# print(\"Number of NaNs in y_norm_train:\", torch.isnan(y_norm_train).sum().item())\n",
        "print(x_raw_train)\n",
        "print(\"Standard deviation of features:\", x_val_std)\n",
        "#print(\"y_val_mean:\", y_val_mean)\n",
        "print(\"y_val_std:\", y_val_std)\n",
        "\n",
        "#print(f\"Number of non-constant input features: {num_filtered_features}\")\n",
        "#print(f\"Number of non-constant target features: {num_filtered_targets}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ubhNQHZ003L",
        "outputId": "b0568906-1883-46de-d44b-b242b253dfa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [14.40134, 13.22018,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 2.99126,  1.21511,  0.98492,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.97893,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 2.91809,  0.84565,  0.97803,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [12.16662,  1.42966,  0.96580,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [13.52838,  9.30579,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 1.90479,  0.94073,  0.98512,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.97815,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 1.76046,  0.89814,  0.98310,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 9.43754,  1.22884,  0.97348,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [13.81231, 12.01729,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 2.23502,  1.32606,  0.97863,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.96654,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 2.21770,  0.68536,  0.98190,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 9.79359,  1.63231,  0.97117,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [20.66368, 14.85904,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 2.15676,  1.25817,  0.98560,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.97962,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 1.51396,  1.01141,  0.98318,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 7.97616,  2.07334,  0.97348,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [17.38465, 11.98350,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 3.13643,  0.73614,  0.97972,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.96866,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 2.23619,  1.00753,  0.97945,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 9.43333,  2.64651,  0.96758,  ...,  0.00000,  1.00000,  0.00000]],\n",
            "\n",
            "        [[ 0.00000,  0.00000,  1.00000,  ...,  0.00000,  0.00000,  1.00000],\n",
            "         [15.96255, 14.98837,  1.00000,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [ 1.56813,  0.96419,  0.98209,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         ...,\n",
            "         [ 0.00000,  0.00000,  0.97111,  ...,  1.00000,  0.00000,  0.00000],\n",
            "         [ 2.90847,  1.07888,  0.97534,  ...,  0.00000,  1.00000,  0.00000],\n",
            "         [12.82191,  2.13076,  0.96133,  ...,  0.00000,  1.00000,  0.00000]]])\n",
            "Standard deviation of features: tensor([[    1.00000,     1.00000,     1.00000,     1.00000,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    4.95715,     2.83815,     1.00000,     0.33012,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    0.55418,     0.27189,     0.00219,     0.45438,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.64608,     0.38219,     0.00260,     0.55069,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.00000,     1.00000,     0.00259,     0.54931,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.00000,     1.00000,     0.00374,     0.65627,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    5.33772,     2.50600,     0.00434,     0.69879,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    6.99489,     6.54410,     0.00610,     0.76207,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.00000,     1.00000,     0.00187,     0.85719,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.30770,     0.46450,     0.00107,     0.98041,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.00000,     1.00000,     0.00187,     0.85719,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    2.57805,     1.69892,     0.00143,     0.91030,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.00000,     1.00000,     1.00000,     0.90971,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.38806,     0.37511,     0.00198,     0.98429,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.94597,     0.59907,     0.00146,     1.00125,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    0.79628,     0.42073,     0.00159,     0.94965,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    2.13873,     1.35644,     0.00187,     0.99095,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    0.72156,     0.21066,     0.00228,     1.05924,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    2.20251,     0.79195,     0.00271,     1.09259,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    0.51077,     0.16810,     0.00221,     1.05909,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    3.98444,     2.57810,     0.00058,     1.05649,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.00000,     1.00000,     1.00000,     1.05166,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    0.71375,     0.36211,     1.00000,     1.03885,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    2.01110,     1.50627,     0.00183,     1.05539,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.00000,     1.00000,     0.00124,     1.01371,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    0.82968,     0.51582,     0.00408,     1.06244,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.00000,     1.00000,     1.00000,     1.01502,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    1.00000,     1.00000,     0.00389,     0.70583,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    0.56719,     0.20231,     0.00301,     1.20450,     1.00000,\n",
            "             1.00000,     1.00000],\n",
            "        [    2.55452,     0.45199,     0.00575,     1.43059,     1.00000,\n",
            "             1.00000,     1.00000]])\n",
            "y_val_mean: tensor([[ 1.00000,  0.00000],\n",
            "        [ 1.00000, -0.42324],\n",
            "        [ 0.98309, -1.53195],\n",
            "        [ 0.98004, -1.80655],\n",
            "        [ 0.98234, -1.87577],\n",
            "        [ 0.97312, -2.28116],\n",
            "        [ 0.96726, -2.66657],\n",
            "        [ 0.96055, -2.74309],\n",
            "        [ 0.98047, -3.01077],\n",
            "        [ 0.98439, -3.38839],\n",
            "        [ 0.98047, -3.01077],\n",
            "        [ 0.98541, -1.55897],\n",
            "        [ 1.00000,  1.45430],\n",
            "        [ 0.97649, -2.33461],\n",
            "        [ 0.98017, -2.32759],\n",
            "        [ 0.97738, -2.66021],\n",
            "        [ 0.97690, -3.40597],\n",
            "        [ 0.96836, -3.49055],\n",
            "        [ 0.96522, -3.96757],\n",
            "        [ 0.96912, -3.88047],\n",
            "        [ 0.99340, -3.50054],\n",
            "        [ 1.00000, -3.40409],\n",
            "        [ 1.00000, -1.59945],\n",
            "        [ 0.98856, -2.63437],\n",
            "        [ 0.99029, -1.70243],\n",
            "        [ 0.97252, -2.15509],\n",
            "        [ 1.00000, -0.84582],\n",
            "        [ 0.97465, -2.28123],\n",
            "        [ 0.97957, -2.14844],\n",
            "        [ 0.96770, -3.07453]])\n",
            "y_val_std: tensor([[    1.00000,     1.00000],\n",
            "        [    1.00000,     0.33012],\n",
            "        [    0.00219,     0.45438],\n",
            "        [    0.00260,     0.55069],\n",
            "        [    0.00259,     0.54931],\n",
            "        [    0.00374,     0.65627],\n",
            "        [    0.00434,     0.69879],\n",
            "        [    0.00610,     0.76207],\n",
            "        [    0.00187,     0.85719],\n",
            "        [    0.00107,     0.98041],\n",
            "        [    0.00187,     0.85719],\n",
            "        [    0.00143,     0.91030],\n",
            "        [    1.00000,     0.90971],\n",
            "        [    0.00198,     0.98429],\n",
            "        [    0.00146,     1.00125],\n",
            "        [    0.00159,     0.94965],\n",
            "        [    0.00187,     0.99095],\n",
            "        [    0.00228,     1.05924],\n",
            "        [    0.00271,     1.09259],\n",
            "        [    0.00221,     1.05909],\n",
            "        [    0.00058,     1.05649],\n",
            "        [    1.00000,     1.05166],\n",
            "        [    1.00000,     1.03885],\n",
            "        [    0.00183,     1.05539],\n",
            "        [    0.00124,     1.01371],\n",
            "        [    0.00408,     1.06244],\n",
            "        [    1.00000,     1.01502],\n",
            "        [    0.00389,     0.70583],\n",
            "        [    0.00301,     1.20450],\n",
            "        [    0.00575,     1.43059]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **57 Bus Only**"
      ],
      "metadata": {
        "id": "jkFs_7lLiDgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# Load dataset from Excel files\n",
        "dataset1 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/57Bus/PF_Dataset_1.xlsx').values\n",
        "dataset2 = pd.read_excel('/content/GNN-OptimalPowerFlow/Datasets/57Bus/PF_Dataset_2.xlsx').values\n",
        "\n",
        "# Split the dataset\n",
        "train_percentage = 100\n",
        "val_percentage = 100\n",
        "\n",
        "train_dataset = slice_dataset(dataset1, train_percentage)\n",
        "val_dataset = slice_dataset(dataset2, val_percentage)\n",
        "\n",
        "n_bus = 57\n",
        "\n",
        "# # Prepare training and validation data\n",
        "x_raw_train, y_raw_train = make_dataset(train_dataset, n_bus)\n",
        "x_raw_val, y_raw_val = make_dataset(val_dataset, n_bus)\n",
        "\n",
        "# Normalize the raw data\n",
        "x_norm_train, y_norm_train, x_train_mean, y_train_mean, x_train_std, y_train_std = normalize_dataset(x_raw_train, y_raw_train)\n",
        "x_norm_val, y_norm_val, x_val_mean, y_val_mean, x_val_std, y_val_std = normalize_dataset(x_raw_val, y_raw_val)\n",
        "\n",
        "# Prepare DataLoader for PyTorch Geometric\n",
        "# Load the IEEE 57-bus test case using pandapower\n",
        "net = nw.case57()\n",
        "\n",
        "# Get the 'from_bus' and 'to_bus' for each line in the network\n",
        "from_buses = net.line['from_bus'].values\n",
        "to_buses = net.line['to_bus'].values\n",
        "\n",
        "# Construct the edge index (bidirectional edges)\n",
        "edge_index = torch.tensor([list(from_buses) + list(to_buses), list(to_buses) + list(from_buses)], dtype=torch.long)\n",
        "\n",
        "print(\"Edge Index for IEEE 57-bus System:\")\n",
        "print(edge_index)\n",
        "\n",
        "# Create Data objects for PyTorch Geometric\n",
        "train_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_train, y_norm_train)]\n",
        "val_data_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_val, y_norm_val)]\n",
        "\n",
        "# Prepare DataLoaders\n",
        "train_loader = DataLoader(train_data_list, batch_size=16)\n",
        "val_loader = DataLoader(val_data_list, batch_size=16)\n",
        "\n",
        "print(\"Data preparation completed successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W8Sef5XiCt-",
        "outputId": "0e6678fe-3290-4d51-ce70-2ce67033d2f9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge Index for IEEE 57-bus System:\n",
            "tensor([[ 0,  1,  2,  3,  3,  5,  5,  7,  8,  8,  8,  8, 12, 12,  0,  0,  0,  2,\n",
            "          4,  6,  9, 10, 11, 11, 11, 13, 17, 18, 20, 21, 22, 25, 26, 27, 24, 29,\n",
            "         30, 31, 33, 34, 35, 36, 36, 35, 21, 40, 40, 37, 45, 46, 47, 48, 49, 28,\n",
            "         51, 52, 53, 43, 55, 55, 56, 37, 37,  1,  2,  3,  4,  5,  6,  7,  8,  9,\n",
            "         10, 11, 12, 13, 14, 14, 15, 16, 14,  5,  7, 11, 12, 12, 15, 16, 14, 18,\n",
            "         19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 39, 37,\n",
            "         41, 42, 43, 46, 47, 48, 49, 50, 51, 52, 53, 54, 44, 40, 41, 55, 48, 47],\n",
            "        [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 14, 15, 16, 14,\n",
            "          5,  7, 11, 12, 12, 15, 16, 14, 18, 19, 21, 22, 23, 26, 27, 28, 29, 30,\n",
            "         31, 32, 34, 35, 36, 37, 38, 39, 37, 41, 42, 43, 46, 47, 48, 49, 50, 51,\n",
            "         52, 53, 54, 44, 40, 41, 55, 48, 47,  0,  1,  2,  3,  3,  5,  5,  7,  8,\n",
            "          8,  8,  8, 12, 12,  0,  0,  0,  2,  4,  6,  9, 10, 11, 11, 11, 13, 17,\n",
            "         18, 20, 21, 22, 25, 26, 27, 24, 29, 30, 31, 33, 34, 35, 36, 36, 35, 21,\n",
            "         40, 40, 37, 45, 46, 47, 48, 49, 28, 51, 52, 53, 43, 55, 55, 56, 37, 37]])\n",
            "Data preparation completed successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Initial GNN Model**\n",
        "\n",
        "We will use a simple GCN as the first model and later extend it to include other GNN topologies:"
      ],
      "metadata": {
        "id": "IwMNOyWDpPIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class My_GNN_Model(nn.Module):\n",
        "    def __init__(self, in_channels=7, hidden_channels=8, out_channels=2):\n",
        "        super(My_GNN_Model, self).__init__()\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        # the GNN layers\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # the output GNN layer for direct prediction\n",
        "        self.conv_out = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        if out_channels is None:\n",
        "            out_channels = 2\n",
        "\n",
        "        self.lin = Linear(hidden_channels * n_bus, out_channels * n_bus)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "\n",
        "\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # GCN layers with ReLU activation\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        # Reshape x for the Linear layer\n",
        "        batch_size = data.num_graphs  # be 8\n",
        "        x = x.view(batch_size, n_bus * self.hidden_channels)\n",
        "\n",
        "        # Apply the output Linear layer\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # Reshape to get the final output shape\n",
        "        return x.view(batch_size * n_bus, 2)\n",
        "\n",
        "\n",
        "# Initialize the model\n",
        "model = My_GNN_Model(in_channels=7, out_channels=2)\n"
      ],
      "metadata": {
        "id": "tjqoOjKEu8bJ"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch Size=1:**"
      ],
      "metadata": {
        "id": "d6FSlADZvciE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class My_GNN_Model(nn.Module):\n",
        "    def __init__(self, in_channels=7, hidden_channels=8, out_channels=2):\n",
        "        super(My_GNN_Model, self).__init__()\n",
        "        # Define the GNN layers\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Define the output GNN layer for direct prediction\n",
        "        self.conv_out = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        if out_channels is None:\n",
        "            out_channels = 2\n",
        "\n",
        "        self.lin = Linear(hidden_channels * n_bus, out_channels * n_bus)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        '''\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        x = x.view(-1)\n",
        "        x = self.lin(x)\n",
        "        return x.view(-1, num_filtered_targets)\n",
        "        ;'''\n",
        "\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply GCN layers with ReLU activation\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        # Apply the output GCN layer\n",
        "        x = self.lin(x.view(-1))\n",
        "\n",
        "        return x.view(-1, 2)\n",
        "\n",
        "# Initialize the model with the correct input and output sizes\n",
        "model = My_GNN_Model(in_channels=7, out_channels=2)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "WvkgOj-sQHys"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "_KGnM5dw1F2t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "class My_GNN_Model(nn.Module):\n",
        "    def __init__(self, in_channels=7, hidden_channels=16, out_channels=2):\n",
        "        super(My_GNN_Model, self).__init__()\n",
        "        # Define the GNN layers\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "\n",
        "        # Define the output GNN layer for direct prediction\n",
        "        self.conv_out = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "        if out_channels is None:\n",
        "            out_channels = 2\n",
        "\n",
        "        self.lin = Linear(hidden_channels * n_bus, out_channels * n_bus)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        '''\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        x = x.view(-1)\n",
        "        x = self.lin(x)\n",
        "        return x.view(-1, num_filtered_targets)\n",
        "        ;'''\n",
        "\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # Apply GCN layers with ReLU activation\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "\n",
        "        # Apply the output GCN layer\n",
        "        x = self.lin(x.view(-1))\n",
        "\n",
        "        return x.view(-1, 2)\n",
        "\n",
        "# Initialize the model with the correct input and output sizes\n",
        "model = My_GNN_Model(in_channels=7, out_channels=2)\n"
      ],
      "metadata": {
        "id": "Tid42BkhcQOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#**Update Edge Index**\n",
        "\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "# Get the list of non-constant nodes\n",
        "filtered_nodes = np.where(non_constant_x.numpy())[0]\n",
        "print(f\"Filtered Nodes: {filtered_nodes}\")\n",
        "\n",
        "# Create a mapping from old node indices to new filtered indices\n",
        "node_mapping = {old_idx: new_idx for new_idx, old_idx in enumerate(filtered_nodes)}\n",
        "\n",
        "# Update the edge index using the filtered node indices\n",
        "new_from_buses = []\n",
        "new_to_buses = []\n",
        "\n",
        "for from_bus, to_bus in zip(from_buses, to_buses):\n",
        "    # Check if both 'from_bus' and 'to_bus' are in the filtered nodes\n",
        "    if from_bus in node_mapping and to_bus in node_mapping:\n",
        "        new_from_buses.append(node_mapping[from_bus])\n",
        "        new_to_buses.append(node_mapping[to_bus])\n",
        "\n",
        "# Construct the new edge index with updated indices\n",
        "edge_index = torch.tensor([new_from_buses + new_to_buses, new_to_buses + new_from_buses], dtype=torch.long)\n",
        "\n",
        "print(\"Updated Edge Index:\")\n",
        "print(edge_index)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "-HBtSfds1OCB",
        "outputId": "5523e2d4-c708-4f39-964b-eb3316b1edff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-75-370784a66dcd>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-75-370784a66dcd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    **Update Edge Index**\"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)\n",
        "print(y_val_mean.shape)\n",
        "print(y_val_std.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "ofHG-SUh1wNu",
        "outputId": "1ba3e4cd-affb-4b76-ced5-db85ecf4c7b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-ceb5c6fe59d9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_mean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Initial Training Loop**"
      ],
      "metadata": {
        "id": "B0345-HgpZa8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimizer with L2 regularization (weight decay)\n",
        "lambda_l2 = 1e-6  # L2 regularization\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5, weight_decay=lambda_l2)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0  # Track the total loss for the epoch\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(batch)\n",
        "        target = batch.y  # Use only the filtered target features\n",
        "\n",
        "        # Reshape y_pred to have the shape [batch_size * n_bus, 2]\n",
        "        batch_size = batch.num_graphs\n",
        "        y_pred = y_pred.view(batch_size * n_bus, 2)\n",
        "\n",
        "        # Expand y_val_mean and y_val_std to match the batch size\n",
        "        y_val_mean_expanded = y_val_mean.repeat(batch_size, 1)\n",
        "        y_val_std_expanded = y_val_std.repeat(batch_size, 1)\n",
        "\n",
        "        # Compute loss using the expanded mean and std\n",
        "        loss = MSE(\n",
        "            denormalize_output(y_pred, y_val_mean_expanded, y_val_std_expanded),\n",
        "            denormalize_output(target, y_val_mean_expanded, y_val_std_expanded)\n",
        "        )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss for reporting\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print the average loss for each epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Step the scheduler based on the average loss\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIsTcrjHxHKQ",
        "outputId": "b2d6209f-6497-4b44-b1a1-5f2a40f76dd1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 0.926918\n",
            "Epoch 2, Average Loss: 0.826624\n",
            "Epoch 3, Average Loss: 0.733274\n",
            "Epoch 4, Average Loss: 0.647646\n",
            "Epoch 5, Average Loss: 0.569572\n",
            "Epoch 6, Average Loss: 0.495670\n",
            "Epoch 7, Average Loss: 0.423409\n",
            "Epoch 8, Average Loss: 0.353758\n",
            "Epoch 9, Average Loss: 0.290151\n",
            "Epoch 10, Average Loss: 0.236091\n",
            "Epoch 11, Average Loss: 0.193403\n",
            "Epoch 12, Average Loss: 0.161692\n",
            "Epoch 13, Average Loss: 0.138953\n",
            "Epoch 14, Average Loss: 0.122646\n",
            "Epoch 15, Average Loss: 0.110579\n",
            "Epoch 16, Average Loss: 0.101238\n",
            "Epoch 17, Average Loss: 0.093679\n",
            "Epoch 18, Average Loss: 0.087354\n",
            "Epoch 19, Average Loss: 0.081947\n",
            "Epoch 20, Average Loss: 0.077249\n",
            "Epoch 21, Average Loss: 0.073122\n",
            "Epoch 22, Average Loss: 0.069472\n",
            "Epoch 23, Average Loss: 0.066226\n",
            "Epoch 24, Average Loss: 0.063315\n",
            "Epoch 25, Average Loss: 0.060693\n",
            "Epoch 26, Average Loss: 0.058319\n",
            "Epoch 27, Average Loss: 0.056160\n",
            "Epoch 28, Average Loss: 0.054182\n",
            "Epoch 29, Average Loss: 0.052358\n",
            "Epoch 30, Average Loss: 0.050668\n",
            "Epoch 31, Average Loss: 0.049090\n",
            "Epoch 32, Average Loss: 0.047608\n",
            "Epoch 33, Average Loss: 0.046207\n",
            "Epoch 34, Average Loss: 0.044873\n",
            "Epoch 35, Average Loss: 0.043602\n",
            "Epoch 36, Average Loss: 0.042387\n",
            "Epoch 37, Average Loss: 0.041221\n",
            "Epoch 38, Average Loss: 0.040098\n",
            "Epoch 39, Average Loss: 0.039013\n",
            "Epoch 40, Average Loss: 0.037960\n",
            "Epoch 41, Average Loss: 0.036938\n",
            "Epoch 42, Average Loss: 0.035944\n",
            "Epoch 43, Average Loss: 0.034978\n",
            "Epoch 44, Average Loss: 0.034039\n",
            "Epoch 45, Average Loss: 0.033125\n",
            "Epoch 46, Average Loss: 0.032234\n",
            "Epoch 47, Average Loss: 0.031368\n",
            "Epoch 48, Average Loss: 0.030526\n",
            "Epoch 49, Average Loss: 0.029707\n",
            "Epoch 50, Average Loss: 0.028908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch Size=1**"
      ],
      "metadata": {
        "id": "A292k3swxQIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# optimizer with L2 regularization (weight decay)\n",
        "lambda_l2 = 1e-4  # L2 regularization strength 1e-4\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=lambda_l2)\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0.0  # Track the total loss for the epoch\n",
        "\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(batch)\n",
        "        target = batch.y # Use only the filtered target features\n",
        "\n",
        "\n",
        "        # Reshape y_pred to have the shape [n_bus, 4]\n",
        "        y_pred = y_pred.view(n_bus, 2)\n",
        "\n",
        "        # Compute loss using the masked predictions and targets\n",
        "        loss = MSE(\n",
        "            denormalize_output(y_pred, y_val_mean, y_val_std),\n",
        "            denormalize_output(target, y_val_mean, y_val_std)\n",
        "        )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss for reporting\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Print the average loss for each epoch\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "\n",
        "   # Step the scheduler based on the average loss\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, Average Loss: {avg_loss:.6f}\")\n",
        "    \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ue-47I31Q-RW",
        "outputId": "0283f764-6619-476c-aba3-7b52afd050bb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "shape '[30, 2]' is invalid for input of size 240",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-9849ee74e55d>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Reshape y_pred to have the shape [n_bus, 4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# Compute loss using the masked predictions and targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[30, 2]' is invalid for input of size 240"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Backup"
      ],
      "metadata": {
        "id": "4sIrVikD1cFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(batch)\n",
        "\n",
        "        # Flatten the prediction and match the filtered target size\n",
        "        y_pred = y_pred.view(-1)[:num_filtered_targets] # Ensure it matches the filtered target size\n",
        "        target = batch.y[:num_filtered_targets] # Use only the filtered target features\n",
        "\n",
        "        # Debugging prints for shapes\n",
        "        print(f\"Shape of input (batch.x): {batch.x.shape}\")\n",
        "        print(f\"Shape of prediction (y_pred): {y_pred.shape}\")\n",
        "        print(f\"Shape of target (batch.y): {batch.y.shape}\")\n",
        "\n",
        "\n",
        "        # Compute loss using the filtered targets\n",
        "        loss = MSE(denormalize_output(y_pred, y_val_mean[:num_filtered_targets], y_val_std[:num_filtered_targets]),\n",
        "                   denormalize_output(target, y_val_mean[:num_filtered_targets], y_val_std[:num_filtered_targets]))\n",
        "\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print the loss for each epoch\n",
        "    print(f\"Epoch {epoch + 1}, Loss: {loss.item():.6f}\")\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NNzVG1YN2Bb",
        "outputId": "57c35fcc-0cac-4cb2-f8a4-3b24a4553936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (18x4 and 18x8)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-210-aa452a8c8e0a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Flatten the prediction and match the filtered target size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-207-278b28dbb96a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    258\u001b[0m                     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \"\"\"\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (18x4 and 18x8)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of y_pred: {y_pred.shape}\")\n",
        "print(f\"Shape of y_pred_filtered: {y_pred_filtered.shape}\")\n",
        "print(f\"Shape of target_filtered: {target_filtered.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFdqP9ZJSp6Y",
        "outputId": "be142000-2586-4cd4-c465-5486df8a325f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred_filtered' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-202-9e63b2ee23cb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of y_pred: {y_pred.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of y_pred_filtered: {y_pred_filtered.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of target_filtered: {target_filtered.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred_filtered' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.isnan(y_pred_filtered).any() or torch.isnan(target_filtered).any():\n",
        "    print(\"NaNs detected in predictions or targets!\")\n",
        "    break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g98p8RIRZ41b",
        "outputId": "ae31570d-ff9d-4fda-e0d4-c64970840f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "'break' outside loop (<ipython-input-201-175092088542>, line 3)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-201-175092088542>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    break\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m 'break' outside loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape after conv1: {x.shape}\")\n",
        "print(f\"Shape after conv2: {x.shape}\")\n",
        "print(f\"Shape before Linear layer: {x.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F120MKswWMeo",
        "outputId": "8ec2836f-d5c1-49cb-fc3b-6903b4e57a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-198-9cf19e096ece>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape after conv1: {x.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape after conv2: {x.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape before Linear layer: {x.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Topologies to Test:**\n",
        "The following topologies will be tested to compare the effectiveness of different GNN architecture.\n",
        "\n",
        "Each topology offers different strengths, such as handling local versus long-range relationships, incorporating attention mechanisms, and scaling to larger grid sizes.\n",
        "\n",
        "1. **Graph Convolutional Networks (GCN):**\n",
        "\n",
        " GCN is a basic form of GNN where each node aggregates features from its immediate neighbors. It’s simplicity makes it a good first model. It is widely used for node classification and regression tasks. GCN will serves as a baseline model that can handle local relationships effectively but may struggle with long-range dependencies.\n",
        "\n",
        "2. **Graph Attention Networks (GAT):**\n",
        "'GATConv'\n",
        "\n",
        "GAT assigns different attention weights to each neighboring node during aggregation and help the network focus on the most important nodes. It allows dynamic weighting of neighbors, which is useful when certain nodes (like generator buses) have more influence\n",
        "in OPF.\n",
        "\n",
        "3. **Chebyshev Networks (ChebNet):**\n",
        "'ChebConv'\n",
        "\n",
        "ChebNet approximates graph convolutions using Chebyshev polynomials and can capture information from nodes multiple hops away without needing many layers. ChebNet can effectively model multi-hop relationships while reducing the need for deep GCNs, which is important for capturing system-wide behavior in the grid.\n",
        "\n",
        "4. **GraphSAGE (SAmple and aggreGatE):**\n",
        "'SAGEConv'\n",
        "\n",
        "GraphSAGE is designed for inductive learning and allows us to sample a fixed-size neighborhood of nodes which will make it scalable to large graphs.\n",
        "GraphSAGE could be useful for OPF tasks in large power grids, as it can efficiently scale to larger\n",
        "networks.\n",
        "\n",
        "5. **GraphConv (GraphConv):**\n",
        "\n",
        "GraphConv is designed to enhance feature learning by incorporating self-loops (each node aggregates its own feature along with its neighbors).\n",
        "It performs a weighted sum of neighbor features, including the node’s own feature. This helps in capturing more node-specific information.\n",
        "It is useful when self-loops or enhanced node feature aggregation can improve model performance. It might perform better on grids where local node information (like generator buses) is crucial.\n",
        "\n",
        "6. **Multi-Head Graph Attention Networks (MH-GAT):**\n",
        "\n",
        "Multi-head attention computes multiple\n",
        "attention distributions in parallel, capturing various aspects of node relationships. This topology\n",
        "could be valuable for learning different aspects of node and edge interactions, especially when OPF\n",
        "solutions are influenced by both local and distant nodes"
      ],
      "metadata": {
        "id": "edjbvxFqU8dK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experiment Order:** (and an Idea for the comparison paper?)"
      ],
      "metadata": {
        "id": "BTFYOHpKWwj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Baseline:** GCN (to set a benchmark).\n",
        "\n",
        "**Attention-Based:** GATConv (to see if attention helps in OPF tasks).\n",
        "\n",
        "**Multi-Hop Relationship:** ChebConv (to model long-range dependencies).\n",
        "\n",
        "**Scalability Test:** SAGEConv (to see how well it scales to larger bus systems).\n",
        "\n",
        "**Enhanced Node Feature Learning:** GraphConv (to check if self-loops improve performance)."
      ],
      "metadata": {
        "id": "Dp6u3VjWWLxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_GNN_GNN_NN(nn.Module):\n",
        "    def __init__(self, node_size, feat_in, feat_size1, feat_size2, hidden_size1, output_size, gnn_type='GCN', dropout=0, use_batch_norm=False):\n",
        "        super(My_GNN_GNN_NN, self).__init__()\n",
        "\n",
        "        self.use_batch_norm = use_batch_norm\n",
        "        self.node_size = node_size\n",
        "        self.feat_size2 = feat_size2\n",
        "\n",
        "        # GNN Layer Selection\n",
        "        if gnn_type == 'GCN':\n",
        "            self.conv1 = GCNConv(feat_in, feat_size1)\n",
        "            self.conv2 = GCNConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'GraphConv':\n",
        "            self.conv1 = GraphConv(feat_in, feat_size1)\n",
        "            self.conv2 = GraphConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'SAGEConv':\n",
        "            self.conv1 = SAGEConv(feat_in, feat_size1)\n",
        "            self.conv2 = SAGEConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'GATConv':\n",
        "            self.conv1 = GATConv(feat_in, feat_size1)\n",
        "            self.conv2 = GATConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'ChebConv':\n",
        "            self.conv1 = ChebConv(feat_in, feat_size1, K=2)\n",
        "            self.conv2 = ChebConv(feat_size1, feat_size2, K=2)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid GNN type. Choose from 'GCN', 'GraphConv', 'SAGEConv', 'GATConv', 'ChebConv'.\")\n",
        "\n",
        "        # Batch Normalization Layers (Optional)\n",
        "        if use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm1d(feat_size1)\n",
        "            self.bn2 = nn.BatchNorm1d(feat_size2)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.lin1 = nn.Linear(node_size * feat_size2, hidden_size1)\n",
        "        self.lin2 = nn.Linear(hidden_size1, output_size)\n",
        "\n",
        "        # Dropout Layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        batch_size = data.num_graphs\n",
        "\n",
        "        # GNN Layer 1\n",
        "        x = self.conv1(x, edge_index)\n",
        "        if self.use_batch_norm:\n",
        "            x = self.bn1(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # GNN Layer 2\n",
        "        x = self.conv2(x, edge_index)\n",
        "        if self.use_batch_norm:\n",
        "            x = self.bn2(x)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        # Reshape x for the Fully Connected layer\n",
        "        x = x.view(batch_size, self.node_size * self.feat_size2)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def save_weights(self, filename):\n",
        "        torch.save(self.state_dict(), filename)\n",
        "\n",
        "    def load_weights(self, filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "        self.eval()\n"
      ],
      "metadata": {
        "id": "vL4Pdhz51I1A"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch Size=1**"
      ],
      "metadata": {
        "id": "_ftmcK3i1hBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "class My_GNN_GNN_NN(nn.Module):\n",
        "    def __init__(self, node_size, feat_in, feat_size1, feat_size2, hidden_size1, output_size, gnn_type='GCN', dropout=0.4, use_batch_norm=False):\n",
        "        super(My_GNN_GNN_NN, self).__init__()\n",
        "\n",
        "        self.use_batch_norm = use_batch_norm\n",
        "\n",
        "        # GNN Layer Selection\n",
        "        if gnn_type == 'GCN':\n",
        "            self.conv1 = GCNConv(feat_in, feat_size1)\n",
        "            self.conv2 = GCNConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'GraphConv':\n",
        "            self.conv1 = GraphConv(feat_in, feat_size1)\n",
        "            self.conv2 = GraphConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'SAGEConv':\n",
        "            self.conv1 = SAGEConv(feat_in, feat_size1)\n",
        "            self.conv2 = SAGEConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'GATConv':\n",
        "            self.conv1 = GATConv(feat_in, feat_size1)\n",
        "            self.conv2 = GATConv(feat_size1, feat_size2)\n",
        "        elif gnn_type == 'ChebConv':\n",
        "            self.conv1 = ChebConv(feat_in, feat_size1, K=2)\n",
        "            self.conv2 = ChebConv(feat_size1, feat_size2, K=2)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid GNN type. Choose from 'GCN', 'GraphConv', 'SAGEConv', 'GATConv', 'ChebConv'.\")\n",
        "\n",
        "        # Batch Normalization Layers (Optional)\n",
        "        if use_batch_norm:\n",
        "            self.bn1 = nn.BatchNorm1d(feat_size1)\n",
        "            self.bn2 = nn.BatchNorm1d(feat_size2)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        self.lin1 = Linear(node_size * feat_size2, hidden_size1)\n",
        "        self.lin2 = Linear(hidden_size1, output_size)\n",
        "\n",
        "        # Dropout Layer\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # GNN Layer 1\n",
        "        x = self.conv1(x, edge_index)\n",
        "        if self.use_batch_norm:\n",
        "            x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # GNN Layer 2\n",
        "        x = self.conv2(x, edge_index)\n",
        "        if self.use_batch_norm:\n",
        "            x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Flatten the node features for fully connected layers\n",
        "        x = x.flatten(start_dim=0)\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def save_weights(self, filename):\n",
        "        torch.save(self.state_dict(), filename)\n",
        "\n",
        "    def load_weights(self, filename):\n",
        "        self.load_state_dict(torch.load(filename))\n",
        "        self.eval()\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "Q6CBvBJIjDjX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "46cb1c34-e289-429d-aa63-7650fa07d9a2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-37-79d40bcba103>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-79d40bcba103>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Initialization**"
      ],
      "metadata": {
        "id": "lM4NMS22ggeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "feat_in = 7  # Number of input features per node (P, Q, V, delta, bus type)\n",
        "feat_size1 = 12  # Size of the first GNN layer 16\n",
        "feat_size2 = 12   # Size of the second GNN layer 8\n",
        "hidden_size1 = 128  # Size of the first fully connected layer\n",
        "output_size = n_bus * 2  # Output size (P and Q for each bus)\n",
        "gnn_type = 'GCN'  # Choose from 'GCN', 'GraphConv', 'SAGEConv', 'GATConv', 'ChebConv'\n",
        "dropout = 0 # Dropout rate\n",
        "use_batch_norm = True  # Use Batch Normalization\n",
        "\n",
        "# Initialize the model with specified hyperparameters\n",
        "model = My_GNN_GNN_NN(\n",
        "    node_size=n_bus,\n",
        "    feat_in=feat_in,\n",
        "    feat_size1=feat_size1,\n",
        "    feat_size2=feat_size2,\n",
        "    hidden_size1=hidden_size1,\n",
        "    output_size=output_size,\n",
        "    gnn_type=gnn_type,\n",
        "    dropout=dropout,\n",
        "    use_batch_norm=use_batch_norm\n",
        ")\n",
        "\n",
        "# Print model details for verification\n",
        "print(\"Initialized Model:\")\n",
        "print(model)\n",
        "\n",
        "# The optimizer and learning rate scheduler\n",
        "learning_rate = 0.00005 #1e-4\n",
        "lambda_l2 = 1e-6  # L2 regularization strength\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=lambda_l2)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, mode='min', factor=0.5, patience=40, verbose=True\n",
        ")\n",
        "\n",
        "# Print model parameter details\n",
        "print(\"\\nModel Parameters:\")\n",
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"{name}: {param.size()}\")\n",
        "\n",
        "# Calculate the total number of trainable parameters\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nTotal number of trainable parameters: {total_params:,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFdksTBy3xJk",
        "outputId": "2adff72f-149c-4570-a8c2-1d27646d7bab"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized Model:\n",
            "My_GNN_GNN_NN(\n",
            "  (conv1): GCNConv(7, 12)\n",
            "  (conv2): GCNConv(12, 12)\n",
            "  (bn1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (bn2): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (lin1): Linear(in_features=168, out_features=128, bias=True)\n",
            "  (lin2): Linear(in_features=128, out_features=28, bias=True)\n",
            "  (dropout): Dropout(p=0, inplace=False)\n",
            ")\n",
            "\n",
            "Model Parameters:\n",
            "conv1.bias: torch.Size([12])\n",
            "conv1.lin.weight: torch.Size([12, 7])\n",
            "conv2.bias: torch.Size([12])\n",
            "conv2.lin.weight: torch.Size([12, 12])\n",
            "bn1.weight: torch.Size([12])\n",
            "bn1.bias: torch.Size([12])\n",
            "bn2.weight: torch.Size([12])\n",
            "bn2.bias: torch.Size([12])\n",
            "lin1.weight: torch.Size([128, 168])\n",
            "lin1.bias: torch.Size([128])\n",
            "lin2.weight: torch.Size([28, 128])\n",
            "lin2.bias: torch.Size([28])\n",
            "\n",
            "Total number of trainable parameters: 25,544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hyperparameters Save**"
      ],
      "metadata": {
        "id": "Ea-koONh8CGh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Define a dictionary to store hyperparameters\n",
        "hyperparams = {\n",
        "    \"Number of Buses\": n_bus,\n",
        "    \"Learning Rate\": learning_rate,\n",
        "    \"L2 Regularization (Lambda)\": lambda_l2,\n",
        "    \"Dropout Rate\": dropout,\n",
        "    \"Use Batch Norm\": use_batch_norm,\n",
        "    \"Input Features\": feat_in,\n",
        "    \"GNN Layer 1 Size\": feat_size1,\n",
        "    \"GNN Layer 2 Size\": feat_size2,\n",
        "    \"Hidden Layer Size (FC)\": hidden_size1,\n",
        "    \"Output Size\": output_size,\n",
        "    \"GNN Type\": gnn_type,\n",
        "    \"Number of GNN Layers\": 2,  # Since we have two GNN layers (conv1 and conv2)\n",
        "    \"Number of Fully Connected Layers\": 2,  # lin1 and lin2\n",
        "    \"Total Trainable Parameters\": total_params,\n",
        "}\n",
        "\n",
        "# Print the hyperparameters\n",
        "print(\"\\nHyperparameters Summary:\")\n",
        "for key, value in hyperparams.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "json_filename = f\"[{n_bus} bus] Model_Hyperparameters.json\"\n",
        "\n",
        "# Save the hyperparameters\n",
        "with open(json_filename, \"w\") as file:\n",
        "    json.dump(hyperparams, file, indent=4)\n",
        "\n",
        "print(f\"\\nHyperparameters saved to '{json_filename}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePbEFeTF8Edn",
        "outputId": "e01aa50d-1c5a-47dd-95a1-934a02dd44ff"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hyperparameters Summary:\n",
            "Number of Buses: 14\n",
            "Learning Rate: 5e-05\n",
            "L2 Regularization (Lambda): 1e-06\n",
            "Dropout Rate: 0\n",
            "Use Batch Norm: True\n",
            "Input Features: 7\n",
            "GNN Layer 1 Size: 12\n",
            "GNN Layer 2 Size: 12\n",
            "Hidden Layer Size (FC): 128\n",
            "Output Size: 28\n",
            "GNN Type: GCN\n",
            "Number of GNN Layers: 2\n",
            "Number of Fully Connected Layers: 2\n",
            "Total Trainable Parameters: 25544\n",
            "\n",
            "Hyperparameters saved to '[14 bus] Model_Hyperparameters.json'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Enhanced Training Loop**"
      ],
      "metadata": {
        "id": "9IniYKPphG0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to store loss values\n",
        "train_loss_list, val_loss_list = [], []\n",
        "\n",
        "# Early stopping parameters\n",
        "patience_count = 90\n",
        "count = 0\n",
        "best_epoch = 0\n",
        "lossMin = float('inf')\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(800):  # Number of epochs\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # Training phase\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Get the batch size (number of graphs in the batch)\n",
        "        batch_size = batch.num_graphs\n",
        "\n",
        "        # Expand y_val_mean and y_val_std to match the batch size\n",
        "        y_val_mean_expanded = y_val_mean.view(-1).repeat(batch_size)\n",
        "        y_val_std_expanded = y_val_std.view(-1).repeat(batch_size)\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(batch)\n",
        "        y_pred = y_pred.view(-1)  # Flatten predictions\n",
        "\n",
        "        # Compute loss using the expanded mean and std\n",
        "        loss = MSE(\n",
        "            denormalize_output(y_pred, y_val_mean_expanded, y_val_std_expanded),\n",
        "            denormalize_output(batch.y.view(-1), y_val_mean_expanded, y_val_std_expanded)\n",
        "        )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        train_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    # Compute average training loss\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            # Get the batch size for validation\n",
        "            batch_size = batch.num_graphs\n",
        "\n",
        "            # Expand y_val_mean and y_val_std to match the batch size\n",
        "            y_val_mean_expanded = y_val_mean.view(-1).repeat(batch_size)\n",
        "            y_val_std_expanded = y_val_std.view(-1).repeat(batch_size)\n",
        "\n",
        "            # Forward pass for validation\n",
        "            y_val_pred = model(batch)\n",
        "            y_val_pred = y_val_pred.view(-1)\n",
        "\n",
        "            # Compute validation loss using expanded mean and std\n",
        "            loss = MSE(\n",
        "                denormalize_output(y_val_pred, y_val_mean_expanded, y_val_std_expanded),\n",
        "                denormalize_output(batch.y.view(-1), y_val_mean_expanded, y_val_std_expanded)\n",
        "            )\n",
        "            val_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    # Compute average validation loss\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_loss_list.append(val_loss)\n",
        "\n",
        "    # Learning rate adjustment based on validation loss\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Early stopping mechanism\n",
        "    if val_loss < lossMin:\n",
        "        lossMin = val_loss\n",
        "        count = 0\n",
        "        best_epoch = epoch\n",
        "        best_train_loss = train_loss\n",
        "        best_val_loss = val_loss\n",
        "\n",
        "        # Save the best model weights\n",
        "        model_filename = f\"[{n_bus} bus] Best_GNN_GNN_NN_model.pt\"\n",
        "        model.save_weights(model_filename)\n",
        "\n",
        "    else:\n",
        "        count += 1\n",
        "        if count > patience_count:\n",
        "            print(f\"Early stopping at epoch {epoch} | Best epoch: {best_epoch}\")\n",
        "            print(f\"Best train loss: {best_train_loss:.7f} | Best val loss: {best_val_loss:.7f}\")\n",
        "            break\n",
        "\n",
        "    # Log progress every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch} | Train loss: {train_loss:.7f} | Val loss: {val_loss:.7f}\")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(f\"Best Epoch: {best_epoch} | Best Train Loss: {best_train_loss:.7f} | Best Val Loss: {best_val_loss:.7f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dudo0sJr1xFa",
        "outputId": "016671d7-e642-4024-a802-8043d6021096"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Train loss: 0.8394173 | Val loss: 0.6198740\n",
            "Epoch 10 | Train loss: 0.0865104 | Val loss: 0.0377930\n",
            "Epoch 20 | Train loss: 0.0648112 | Val loss: 0.0235942\n",
            "Epoch 30 | Train loss: 0.0551599 | Val loss: 0.0188000\n",
            "Epoch 40 | Train loss: 0.0493267 | Val loss: 0.0165927\n",
            "Epoch 50 | Train loss: 0.0449181 | Val loss: 0.0151923\n",
            "Epoch 60 | Train loss: 0.0412727 | Val loss: 0.0141603\n",
            "Epoch 70 | Train loss: 0.0381315 | Val loss: 0.0133431\n",
            "Epoch 80 | Train loss: 0.0353989 | Val loss: 0.0126629\n",
            "Epoch 90 | Train loss: 0.0331003 | Val loss: 0.0121538\n",
            "Epoch 100 | Train loss: 0.0310999 | Val loss: 0.0117403\n",
            "Epoch 110 | Train loss: 0.0293333 | Val loss: 0.0114774\n",
            "Epoch 120 | Train loss: 0.0277894 | Val loss: 0.0112694\n",
            "Epoch 130 | Train loss: 0.0263847 | Val loss: 0.0111045\n",
            "Epoch 140 | Train loss: 0.0251131 | Val loss: 0.0110021\n",
            "Epoch 150 | Train loss: 0.0239519 | Val loss: 0.0109314\n",
            "Epoch 160 | Train loss: 0.0228825 | Val loss: 0.0108207\n",
            "Epoch 170 | Train loss: 0.0218881 | Val loss: 0.0107780\n",
            "Epoch 180 | Train loss: 0.0209944 | Val loss: 0.0107337\n",
            "Epoch 190 | Train loss: 0.0201581 | Val loss: 0.0107097\n",
            "Epoch 200 | Train loss: 0.0193544 | Val loss: 0.0106682\n",
            "Epoch 210 | Train loss: 0.0185996 | Val loss: 0.0106377\n",
            "Epoch 220 | Train loss: 0.0178667 | Val loss: 0.0105868\n",
            "Epoch 230 | Train loss: 0.0171659 | Val loss: 0.0105217\n",
            "Epoch 240 | Train loss: 0.0164843 | Val loss: 0.0104669\n",
            "Epoch 250 | Train loss: 0.0158430 | Val loss: 0.0104098\n",
            "Epoch 260 | Train loss: 0.0152364 | Val loss: 0.0103582\n",
            "Epoch 270 | Train loss: 0.0146540 | Val loss: 0.0103307\n",
            "Epoch 280 | Train loss: 0.0141020 | Val loss: 0.0102900\n",
            "Epoch 290 | Train loss: 0.0135752 | Val loss: 0.0102643\n",
            "Epoch 300 | Train loss: 0.0130701 | Val loss: 0.0102267\n",
            "Epoch 310 | Train loss: 0.0125895 | Val loss: 0.0101863\n",
            "Epoch 320 | Train loss: 0.0121338 | Val loss: 0.0101545\n",
            "Epoch 330 | Train loss: 0.0116980 | Val loss: 0.0101233\n",
            "Epoch 340 | Train loss: 0.0112838 | Val loss: 0.0100914\n",
            "Epoch 350 | Train loss: 0.0108798 | Val loss: 0.0100634\n",
            "Epoch 360 | Train loss: 0.0104978 | Val loss: 0.0100196\n",
            "Epoch 370 | Train loss: 0.0101359 | Val loss: 0.0099950\n",
            "Epoch 380 | Train loss: 0.0097835 | Val loss: 0.0099556\n",
            "Epoch 390 | Train loss: 0.0094441 | Val loss: 0.0099209\n",
            "Epoch 400 | Train loss: 0.0091236 | Val loss: 0.0098737\n",
            "Epoch 410 | Train loss: 0.0088118 | Val loss: 0.0098332\n",
            "Epoch 420 | Train loss: 0.0085127 | Val loss: 0.0098041\n",
            "Epoch 430 | Train loss: 0.0082318 | Val loss: 0.0097465\n",
            "Epoch 440 | Train loss: 0.0079627 | Val loss: 0.0097071\n",
            "Epoch 450 | Train loss: 0.0077093 | Val loss: 0.0096540\n",
            "Epoch 460 | Train loss: 0.0074661 | Val loss: 0.0096196\n",
            "Epoch 470 | Train loss: 0.0072372 | Val loss: 0.0095689\n",
            "Epoch 480 | Train loss: 0.0070234 | Val loss: 0.0095359\n",
            "Epoch 490 | Train loss: 0.0068125 | Val loss: 0.0094766\n",
            "Epoch 500 | Train loss: 0.0066073 | Val loss: 0.0094406\n",
            "Epoch 510 | Train loss: 0.0064141 | Val loss: 0.0094091\n",
            "Epoch 520 | Train loss: 0.0062262 | Val loss: 0.0093668\n",
            "Epoch 530 | Train loss: 0.0060486 | Val loss: 0.0093564\n",
            "Epoch 540 | Train loss: 0.0058792 | Val loss: 0.0093179\n",
            "Epoch 550 | Train loss: 0.0057184 | Val loss: 0.0092884\n",
            "Epoch 560 | Train loss: 0.0055695 | Val loss: 0.0092355\n",
            "Epoch 570 | Train loss: 0.0054261 | Val loss: 0.0091730\n",
            "Epoch 580 | Train loss: 0.0052882 | Val loss: 0.0091308\n",
            "Epoch 590 | Train loss: 0.0051533 | Val loss: 0.0090804\n",
            "Epoch 600 | Train loss: 0.0050250 | Val loss: 0.0090254\n",
            "Epoch 610 | Train loss: 0.0049002 | Val loss: 0.0089619\n",
            "Epoch 620 | Train loss: 0.0047832 | Val loss: 0.0089176\n",
            "Epoch 630 | Train loss: 0.0046731 | Val loss: 0.0088612\n",
            "Epoch 640 | Train loss: 0.0045628 | Val loss: 0.0088167\n",
            "Epoch 650 | Train loss: 0.0044576 | Val loss: 0.0087619\n",
            "Epoch 660 | Train loss: 0.0043574 | Val loss: 0.0087137\n",
            "Epoch 670 | Train loss: 0.0042571 | Val loss: 0.0086745\n",
            "Epoch 680 | Train loss: 0.0041651 | Val loss: 0.0086312\n",
            "Epoch 690 | Train loss: 0.0040729 | Val loss: 0.0085871\n",
            "Epoch 700 | Train loss: 0.0039866 | Val loss: 0.0085406\n",
            "Epoch 710 | Train loss: 0.0038987 | Val loss: 0.0085021\n",
            "Epoch 720 | Train loss: 0.0038150 | Val loss: 0.0084425\n",
            "Epoch 730 | Train loss: 0.0037311 | Val loss: 0.0084015\n",
            "Epoch 740 | Train loss: 0.0036539 | Val loss: 0.0083641\n",
            "Epoch 750 | Train loss: 0.0035816 | Val loss: 0.0083376\n",
            "Epoch 760 | Train loss: 0.0035123 | Val loss: 0.0083017\n",
            "Epoch 770 | Train loss: 0.0034437 | Val loss: 0.0082897\n",
            "Epoch 780 | Train loss: 0.0033771 | Val loss: 0.0082653\n",
            "Epoch 790 | Train loss: 0.0033121 | Val loss: 0.0082378\n",
            "Training complete.\n",
            "Best Epoch: 799 | Best Train Loss: 0.0032571 | Best Val Loss: 0.0082114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch Size=1:**"
      ],
      "metadata": {
        "id": "uEV6qiKl1yLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Initialize lists to store loss values\n",
        "train_loss_list, val_loss_list = [], []\n",
        "\n",
        "# Early stopping parameters\n",
        "patience = 60\n",
        "count = 0\n",
        "best_epoch = 0\n",
        "lossMin = float('inf')\n",
        "\n",
        "# Flatten y_val_mean and y_val_std to match the predictions\n",
        "y_val_mean_flattened = y_val_mean.view(-1)  # Shape: [60] for 30-bus system\n",
        "y_val_std_flattened = y_val_std.view(-1)    # Shape: [60] for 30-bus system\n",
        "\n",
        "# Learning rate scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10, verbose=True)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(400):  # Changed from 2001\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # Training phase\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred = model(batch)\n",
        "        y_pred = y_pred.view(-1)  # Flatten predictions to match target shape\n",
        "\n",
        "        # Compute loss using the flattened mean and std\n",
        "        loss = MSE(\n",
        "            denormalize_output(y_pred, y_val_mean_flattened, y_val_std_flattened),\n",
        "            denormalize_output(batch.y.view(-1), y_val_mean_flattened, y_val_std_flattened)\n",
        "        )\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate loss\n",
        "        train_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    # Compute average training loss\n",
        "    train_loss /= len(train_loader.dataset)\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            # Forward pass for validation\n",
        "            y_val_pred = model(batch)\n",
        "            y_val_pred = y_val_pred.view(-1)\n",
        "\n",
        "            # Compute validation loss\n",
        "            loss = MSE(\n",
        "                denormalize_output(y_val_pred, y_val_mean_flattened, y_val_std_flattened),\n",
        "                denormalize_output(batch.y.view(-1), y_val_mean_flattened, y_val_std_flattened)\n",
        "            )\n",
        "            val_loss += loss.item() * batch.num_graphs\n",
        "\n",
        "    # Compute average validation loss\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_loss_list.append(val_loss)\n",
        "\n",
        "    # Learning rate adjustment based on validation loss\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Early stopping mechanism\n",
        "    if val_loss < lossMin:\n",
        "        lossMin = val_loss\n",
        "        count = 0\n",
        "        best_epoch = epoch\n",
        "        best_train_loss = train_loss\n",
        "        best_val_loss = val_loss\n",
        "\n",
        "        # Save the best model weights\n",
        "        #model.save_weights(\"[14 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "        model.save_weights(\"[30 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "        #model.save_weights(\"[57 bus] Best_GNN_GNN_NN_model.pt\")\n",
        "\n",
        "    else:\n",
        "        count += 1\n",
        "        if count > patience:\n",
        "            print(f\"Early stopping at epoch {epoch} | Best epoch: {best_epoch}\")\n",
        "            print(f\"Best train loss: {best_train_loss:.7f} | Best val loss: {best_val_loss:.7f}\")\n",
        "            break\n",
        "\n",
        "    # Log progress every 10 epochs\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch} | Train loss: {train_loss:.7f} | Val loss: {val_loss:.7f}\")\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(f\"Best Epoch: {best_epoch} | Best Train Loss: {best_train_loss:.7f} | Best Val Loss: {best_val_loss:.7f}\")\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "eyGTAYTt5duJ",
        "outputId": "d7349821-3b2f-4319-8cf2-a26b884d2d94"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (240) must match the size of tensor b (60) at non-singleton dimension 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-7eba34e8b168>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Compute loss using the flattened mean and std\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         loss = MSE(\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mdenormalize_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_mean_flattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_std_flattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mdenormalize_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_mean_flattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_std_flattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-7-2cc95821ce5c>\u001b[0m in \u001b[0;36mdenormalize_output\u001b[0;34m(y_norm, y_mean, y_std)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdenormalize_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_std\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0my_norm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_std\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my_mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (240) must match the size of tensor b (60) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotting Loss Curves**"
      ],
      "metadata": {
        "id": "HkhKmVL-hLQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the training and validation loss\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.title(f'Loss Curves for GNN Model Predicting V and δ on IEEE {n_bus}-Bus Dataset', fontsize=14)\n",
        "plt.plot(train_loss_list, label=\"Train Loss\", color='blue', linewidth=2)\n",
        "plt.plot(val_loss_list, label=\"Validation Loss\", color='orange', linewidth=2)\n",
        "#plt.yscale('log')  # Use logarithmic scale for better visualization\n",
        "plt.xlabel(\"Epoch\", fontsize=12)\n",
        "plt.ylabel(\"Loss\", fontsize=12)\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "plt.legend(loc='best', fontsize=12)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Save the figure\n",
        "figure_filename = f\"[{n_bus} bus] Loss Curves.png\"\n",
        "plt.savefig(figure_filename, dpi=300)\n",
        "print(f\"\\nFigure saved as '{figure_filename}'!\")\n",
        "\n",
        "# Print final and best losses\n",
        "print(f\"Last epoch: {epoch + 1}, Train loss: {train_loss:.7f}, Val loss: {val_loss:.7f}\")\n",
        "print(f\"Best epoch: {best_epoch + 1}, Best Train loss: {best_train_loss:.7f}, Best Val loss: {best_val_loss:.7f}\")"
      ],
      "metadata": {
        "id": "YWYYyI3cj-22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "outputId": "d8dff942-43fe-4ccd-eda1-7512504e41d5"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Figure saved as '[14 bus] Loss Curves.png'!\n",
            "Last epoch: 800, Train loss: 0.0032571, Val loss: 0.0082114\n",
            "Best epoch: 800, Best Train loss: 0.0032571, Best Val loss: 0.0082114\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "MhfPkA3bhVX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_val_targets.shape)\n",
        "print(y_val_predictions[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9RFvWquIKR2",
        "outputId": "528400f0-8b7b-460b-8e7b-766427c05390"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2000, 30, 2])\n",
            "torch.Size([30, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Function to calculate regression metrics\n",
        "def evaluate_regression_metrics(y_true, y_pred):\n",
        "    # Denormalize the outputs\n",
        "    y_true = denormalize_output(y_true, y_val_mean, y_val_std)\n",
        "    y_pred = denormalize_output(y_pred, y_val_mean, y_val_std)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    y_true = y_true.detach().cpu().numpy()\n",
        "    y_pred = y_pred.detach().cpu().numpy()\n",
        "\n",
        "    # Calculate metrics\n",
        "    mse = mean_squared_error(y_true.reshape(-1, 2), y_pred.reshape(-1, 2))\n",
        "    rmse = np.sqrt(mse)\n",
        "    nrmse = rmse / np.std(y_true)\n",
        "    mae = mean_absolute_error(y_true.reshape(-1, 2), y_pred.reshape(-1, 2))\n",
        "    r2 = r2_score(y_true.reshape(-1, 2), y_pred.reshape(-1, 2))\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Mean Squared Error (MSE): {mse:.6f}\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.6f}\")\n",
        "    print(f\"Normalized RMSE (NRMSE): {nrmse:.6f}\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.6f}\")\n",
        "    print(f\"R^2 Score: {r2:.6f}\")\n",
        "\n",
        "    return mse, rmse, nrmse, mae, r2\n",
        "\n",
        "# Evaluation after training\n",
        "model.eval()\n",
        "y_val_predictions = []\n",
        "\n",
        "# Collect all predictions and ground truth for the validation set\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        # Forward pass for validation\n",
        "        y_val_pred = model(batch)\n",
        "\n",
        "        # Skip empty batches\n",
        "        if y_val_pred.size(0) == 0:\n",
        "            continue\n",
        "\n",
        "        # Reshape predictions based on the actual size\n",
        "        y_val_pred = y_val_pred.view(-1, n_bus, 2)\n",
        "        y_val_predictions.append(y_val_pred)\n",
        "\n",
        "# Stack predictions and targets with the shape [n_samples, n_bus, 2]\n",
        "y_val_predictions = torch.cat(y_val_predictions, dim=0)\n",
        "y_val_targets = torch.cat([batch.y.view(-1, n_bus, 2) for batch in val_loader], dim=0)\n",
        "\n",
        "# Calculate and print regression metrics\n",
        "mse, rmse, nrmse, mae, r2 = evaluate_regression_metrics(y_val_targets, y_val_predictions)\n",
        "\n",
        "# Save the metrics to a dictionary for later comparison\n",
        "metrics = {\n",
        "    'MSE': mse,\n",
        "    'RMSE': rmse,\n",
        "    'NRMSE': nrmse,\n",
        "    'MAE': mae,\n",
        "    'R2': r2\n",
        "}\n",
        "\n",
        "# Save the metrics to a CSV file\n",
        "metrics_df = pd.DataFrame([metrics])\n",
        "\n",
        "# Save the metrics to the CSV file\n",
        "metrics_filename = f\"[{n_bus} bus] Validation Metrics.csv\"\n",
        "metrics_df.to_csv(metrics_filename, index=False)\n",
        "print(f\"\\nMetrics saved to '{metrics_filename}'.\")\n"
      ],
      "metadata": {
        "id": "jMI26hcw4NVL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049558c0-db6d-411c-c878-bf07a95e2b35"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.008211\n",
            "Root Mean Squared Error (RMSE): 0.090617\n",
            "Normalized RMSE (NRMSE): 0.012362\n",
            "Mean Absolute Error (MAE): 0.046869\n",
            "R^2 Score: 0.996813\n",
            "\n",
            "Metrics saved to '[14 bus] Validation Metrics.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Single datapoint evaluation**"
      ],
      "metadata": {
        "id": "EDe5Wxil6opK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Device configuration (ensure compatibility)\n",
        "device = next(model.parameters()).device\n",
        "\n",
        "# Function for single datapoint evaluation\n",
        "def evaluate_single_datapoint(data, y_mean, y_std, y_raw):\n",
        "    # Move the data to the correct device\n",
        "    data = data.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    y_pred = model(data)\n",
        "\n",
        "    # Handle dimensions based on whether the input is batched or not\n",
        "    if y_pred.dim() == 1:\n",
        "        # Single datapoint scenario (batch size = 1)\n",
        "        y_pred = y_pred.view(n_bus, 2)\n",
        "        data_y = data.y.view(n_bus, 2)\n",
        "    else:\n",
        "        # Batched scenario (consistent with batch size handling)\n",
        "        batch_size = data.y.size(0) // n_bus\n",
        "        y_pred = y_pred.view(batch_size, n_bus, 2)\n",
        "        data_y = data.y.view(batch_size, n_bus, 2)\n",
        "\n",
        "    # Expand y_mean and y_std to match the batch size for denormalization\n",
        "    y_mean_expanded = y_mean.repeat(batch_size, 1)\n",
        "    y_std_expanded = y_std.repeat(batch_size, 1)\n",
        "\n",
        "    # Denormalize the prediction and the ground truth\n",
        "    y_pred_denorm = denormalize_output(y_pred, y_mean_expanded, y_std_expanded)\n",
        "    y_target_denorm = denormalize_output(data_y, y_mean_expanded, y_std_expanded)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = MSE(y_pred_denorm, y_target_denorm)\n",
        "\n",
        "    # Print ground truth and prediction\n",
        "    print(\"Ground-truth:\", y_raw.detach().cpu().numpy())\n",
        "    print(\"Prediction:\", y_pred_denorm.detach().cpu().numpy())\n",
        "    print(f\"Loss (MSE): {loss:.7f}\")\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Evaluate on a single training datapoint\n",
        "print(\"\\nEvaluation on a single training datapoint:\")\n",
        "train_loader_single = DataLoader(train_data_list, batch_size=1, shuffle=False)\n",
        "train_loss_1 = evaluate_single_datapoint(\n",
        "    next(iter(train_loader_single)), y_val_mean, y_val_std, y_raw_train[0]\n",
        ")\n",
        "\n",
        "# Evaluate on a single validation datapoint\n",
        "print(\"\\nEvaluation on a single validation datapoint:\")\n",
        "val_loader_single = DataLoader(val_data_list, batch_size=1, shuffle=False)\n",
        "val_loss_1 = evaluate_single_datapoint(\n",
        "    next(iter(val_loader_single)), y_val_mean, y_val_std, y_raw_val[0]\n",
        ")\n"
      ],
      "metadata": {
        "id": "VafI4QFlAGRe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786e1948-8140-439f-a7f1-f086c1bbac24"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation on a single training datapoint:\n",
            "Ground-truth: [[  1.06      0.     ]\n",
            " [  1.045    -5.31568]\n",
            " [  1.01    -13.48284]\n",
            " [  1.01752 -10.60181]\n",
            " [  1.01947  -9.02479]\n",
            " [  1.07    -14.16715]\n",
            " [  1.05885 -13.0817 ]\n",
            " [  1.09    -13.0817 ]\n",
            " [  1.04986 -14.37424]\n",
            " [  1.04528 -14.46199]\n",
            " [  1.0535  -14.42769]\n",
            " [  1.05376 -15.15695]\n",
            " [  1.04959 -15.12631]\n",
            " [  1.02883 -15.77473]]\n",
            "Prediction: [[[  1.06013   0.00029]\n",
            "  [  1.04491  -5.25713]\n",
            "  [  1.00965 -13.17253]\n",
            "  [  1.01739 -10.52143]\n",
            "  [  1.01928  -8.9801 ]\n",
            "  [  1.06962 -14.10181]\n",
            "  [  1.0605  -12.96308]\n",
            "  [  1.09007 -12.9708 ]\n",
            "  [  1.05246 -14.28261]\n",
            "  [  1.04797 -14.3818 ]\n",
            "  [  1.05606 -14.38525]\n",
            "  [  1.05497 -15.04838]\n",
            "  [  1.05004 -15.06011]\n",
            "  [  1.03277 -15.84725]]]\n",
            "Loss (MSE): 0.0052611\n",
            "\n",
            "Evaluation on a single validation datapoint:\n",
            "Ground-truth: [[  1.06      0.     ]\n",
            " [  1.045    -3.95881]\n",
            " [  1.01    -11.02136]\n",
            " [  1.02143  -8.44376]\n",
            " [  1.02303  -7.14635]\n",
            " [  1.07    -11.76542]\n",
            " [  1.0625  -10.98824]\n",
            " [  1.09    -10.98824]\n",
            " [  1.05567 -12.3122 ]\n",
            " [  1.05089 -12.57172]\n",
            " [  1.05756 -12.30918]\n",
            " [  1.05784 -12.31033]\n",
            " [  1.0525  -12.32222]\n",
            " [  1.04083 -12.85534]]\n",
            "Prediction: [[[  1.06008   0.00025]\n",
            "  [  1.04496  -3.84399]\n",
            "  [  1.00966 -10.61393]\n",
            "  [  1.0209   -8.34884]\n",
            "  [  1.02211  -7.01442]\n",
            "  [  1.06963 -11.5391 ]\n",
            "  [  1.06369 -10.80684]\n",
            "  [  1.09002 -10.78908]\n",
            "  [  1.05876 -12.07929]\n",
            "  [  1.05352 -12.37219]\n",
            "  [  1.05813 -12.11647]\n",
            "  [  1.05566 -12.12934]\n",
            "  [  1.05169 -12.13751]\n",
            "  [  1.04004 -12.57686]]]\n",
            "Loss (MSE): 0.0216082\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Testing on Multiple Datasets**\n",
        "\n",
        "Loading the Best Model"
      ],
      "metadata": {
        "id": "7SXapJIxhdqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = My_GNN_GNN_NN(n_bus, feat_in, feat_size1, feat_size2, hidden_size1, output_size)\n",
        "\n",
        "# Load the saved state dictionary\n",
        "model_filename = f\"[{n_bus} bus] Best_GNN_GNN_NN_model.pt\"\n",
        "state_dict = torch.load(model_filename)\n",
        "print(f\"Loaded model weights from '{model_filename}'.\")\n",
        "\n",
        "best_model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "best_model.eval()"
      ],
      "metadata": {
        "id": "FwIyhE7I7Dkf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c87c46b7-df26-4d5c-bde8-e677c087b385"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model weights from '[14 bus] Best_GNN_GNN_NN_model.pt'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-85-d8ce72a5f2bc>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_filename)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "My_GNN_GNN_NN(\n",
              "  (conv1): GCNConv(7, 12)\n",
              "  (conv2): GCNConv(12, 12)\n",
              "  (lin1): Linear(in_features=168, out_features=128, bias=True)\n",
              "  (lin2): Linear(in_features=128, out_features=28, bias=True)\n",
              "  (dropout): Dropout(p=0, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NRMSE Function**"
      ],
      "metadata": {
        "id": "MF6bivy1Eyhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def NRMSE(yhat, y):\n",
        "    rmse = torch.sqrt(torch.mean((yhat - y) ** 2))\n",
        "    nrmse = rmse / torch.std(y)\n",
        "    return nrmse"
      ],
      "metadata": {
        "id": "v1vG8VRM7y7u"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Dataset Evaluation Loop**"
      ],
      "metadata": {
        "id": "KUMCfL-kE3Wf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "test_loss_list = []\n",
        "\n",
        "for i in range(10):\n",
        "    # Load the test dataset\n",
        "    dataset = pd.read_excel(f'/content/GNN-OptimalPowerFlow/Datasets/14Bus/PF_Dataset_{i + 1}.xlsx').values\n",
        "    #dataset = pd.read_excel(f'/content/GNN-OptimalPowerFlow/Datasets/30Bus/PF_Dataset_{i + 1}.xlsx').values\n",
        "    #dataset = pd.read_excel(f'/content/GNN-OptimalPowerFlow/Datasets/57Bus/PF_Dataset_{i + 1}.xlsx').values\n",
        "\n",
        "    # Use 20% of the test dataset\n",
        "    test_dataset = slice_dataset(dataset, 20)\n",
        "    x_raw_test, y_raw_test = make_dataset(test_dataset, n_bus)\n",
        "    x_norm_test, y_norm_test, y_test_mean, y_test_std, _, _ = normalize_dataset(x_raw_test, y_raw_test)\n",
        "\n",
        "    # target statistics (V and δ)\n",
        "    y_test_mean_targets = y_test_mean[:, :2]\n",
        "    y_test_std_targets = y_test_std[:, :2]\n",
        "\n",
        "    # Prepare the test data loader\n",
        "    data_test_list = [Data(x=x, y=y, edge_index=edge_index) for x, y in zip(x_norm_test, y_norm_test)]\n",
        "    test_loader = DataLoader(data_test_list, batch_size=16)\n",
        "\n",
        "    # Initialize predictions\n",
        "    yhat = torch.empty(0, n_bus, 2).to(device)\n",
        "\n",
        "    # Collect predictions from the model\n",
        "    for batch in test_loader:\n",
        "        batch = batch.to(device)\n",
        "        y_pred = best_model(batch)\n",
        "\n",
        "        # Get the size of y_pred and reshape directly\n",
        "        total_predictions = y_pred.size(0)\n",
        "        if total_predictions == 0:\n",
        "            print(\"Warning: Empty batch encountered, skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Reshape y_pred to [batch_size, n_bus, 2]\n",
        "        y_pred = y_pred.view(-1, n_bus, 2)\n",
        "        yhat = torch.cat((yhat, y_pred), dim=0)\n",
        "\n",
        "    # Ensure yhat is not empty\n",
        "    if yhat.size(0) == 0:\n",
        "        print(\"Error: No predictions collected. Please check the test data and model.\")\n",
        "        continue\n",
        "\n",
        "    # Denormalize predictions and ground truth\n",
        "    yhat_denorm = denormalize_output(yhat, y_test_mean_targets.repeat(yhat.size(0), 1, 1), y_test_std_targets.repeat(yhat.size(0), 1, 1))\n",
        "    y_raw_test_denorm = denormalize_output(y_norm_test[:, :, :2], y_test_mean_targets, y_test_std_targets)\n",
        "\n",
        "    # Calculate NRMSE for the test dataset\n",
        "    try:\n",
        "        test_loss_NRMSE = NRMSE(yhat_denorm, y_raw_test_denorm)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error in NRMSE calculation: {e}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Dataset {i + 1} | Test loss (NRMSE): {test_loss_NRMSE:.7f}\")\n",
        "    test_loss_list.append(test_loss_NRMSE)\n",
        "\n",
        "# Print the summary of test losses\n",
        "print(\"Test Losses for All Datasets:\", test_loss_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90GgN6XJV_3R",
        "outputId": "9e5994ff-3431-4280-d37f-6e566affed59"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 1 | Test loss (NRMSE): 0.3730086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 2 | Test loss (NRMSE): 0.3775059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 3 | Test loss (NRMSE): 0.3727054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 4 | Test loss (NRMSE): 0.3739252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 5 | Test loss (NRMSE): 0.3742661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 6 | Test loss (NRMSE): 0.3727652\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 7 | Test loss (NRMSE): 0.3751188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 8 | Test loss (NRMSE): 0.3751141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 9 | Test loss (NRMSE): 0.3746838\n",
            "Dataset 10 | Test loss (NRMSE): 0.3732651\n",
            "Test Losses for All Datasets: [tensor(0.37301, grad_fn=<DivBackward0>), tensor(0.37751, grad_fn=<DivBackward0>), tensor(0.37271, grad_fn=<DivBackward0>), tensor(0.37393, grad_fn=<DivBackward0>), tensor(0.37427, grad_fn=<DivBackward0>), tensor(0.37277, grad_fn=<DivBackward0>), tensor(0.37512, grad_fn=<DivBackward0>), tensor(0.37511, grad_fn=<DivBackward0>), tensor(0.37468, grad_fn=<DivBackward0>), tensor(0.37327, grad_fn=<DivBackward0>)]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Saving Test Losses**"
      ],
      "metadata": {
        "id": "Sq5bBwEOFib_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the test_loss_list is converted to a format that can be saved\n",
        "new_list = []\n",
        "\n",
        "# Convert each test loss value to a float and detach from the computation graph if needed\n",
        "for x in test_loss_list:\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        new_list.append(x.item())  # Use .item() for scalar tensors\n",
        "    else:\n",
        "        new_list.append(float(x))  # Convert to float if it's already a number\n",
        "\n",
        "# Create a DataFrame from the list\n",
        "test_loss_df = pd.DataFrame(new_list, columns=[\"Test Loss\"])\n",
        "\n",
        "# Save the DataFrame to an Excel file\n",
        "test_loss_filename = f\"[{n_bus} bus] Test Losses.xlsx\"\n",
        "test_loss_df.to_excel(test_loss_filename, index=False)\n",
        "print(f\"\\nTest loss file saved successfully as '{test_loss_filename}'!\")\n"
      ],
      "metadata": {
        "id": "3U-A856gFHz2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e82b200-73f5-45b4-bfec-faf62934d65e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test loss file saved successfully as '[14 bus] Test Losses.xlsx'!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IEEE 14 Bus DataSet Generation**\n",
        "\n",
        "Contains 14 buses, 5 generators (including the slack bus), 11 loads, and 20 branches.\n",
        "\n",
        "Represents a simple transmission network, ideal for educational purposes and testing basic load flow algorithms.\n"
      ],
      "metadata": {
        "id": "ykGQ9gtCyn1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandapower"
      ],
      "metadata": {
        "id": "ESGDJ1_OyqGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Create the output folder\n",
        "output_folder = \"datasets_14Bus\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Create the 14-bus test system using pandapower\n",
        "net = nw.case14()\n",
        "\n",
        "# Number of datasets and samples per dataset\n",
        "num_datasets = 10\n",
        "samples_per_dataset = 2000\n",
        "variation_range = 0.4  # ±40% random load variation\n",
        "\n",
        "# columns for the output Excel file\n",
        "bus_ids = net.bus.index\n",
        "columns = []\n",
        "\n",
        "# column names based on dataset format\n",
        "for bus in bus_ids:\n",
        "    columns.extend([f\"P_{bus + 1} (PQ)\", f\"Q_{bus + 1} (PQ)\", f\"V_{bus + 1}\", f\"d_{bus + 1}\"])\n",
        "\n",
        "# Store original load values for resetting\n",
        "original_p_values = net.load['p_mw'].copy()\n",
        "original_q_values = net.load['q_mvar'].copy()\n",
        "\n",
        "# Generate the datasets\n",
        "for dataset_n in range(1, num_datasets + 1):\n",
        "    print(f\"Generating dataset {dataset_n}...\")\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # initial power flow to stabilize the network\n",
        "    #try:\n",
        "    #    pp.runpp(net, algorithm='nr', max_iteration=20)\n",
        "    #except pp.LoadflowNotConverged:\n",
        "    #    print(f\"Initial load flow did not converge for dataset {dataset_n}, skipping this dataset.\")\n",
        "    #    continue\n",
        "\n",
        "    for sample in range(1, samples_per_dataset + 1):\n",
        "        # Reset the load values to the original values\n",
        "        net.load['p_mw'] = original_p_values\n",
        "        net.load['q_mvar'] = original_q_values\n",
        "\n",
        "        # Apply random variation based on the original values\n",
        "        for load in net.load.index:\n",
        "            net.load.at[load, 'p_mw'] = original_p_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "            net.load.at[load, 'q_mvar'] = original_q_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "\n",
        "        # Run AC power flow with Newton-Raphson algorithm\n",
        "        try:\n",
        "            pp.runpp(net, algorithm='nr', max_iteration=20)\n",
        "        except pp.LoadflowNotConverged:\n",
        "            print(f\"Load flow did not converge for sample {sample} in dataset {dataset_n}, skipping this sample.\")\n",
        "            continue\n",
        "\n",
        "        # Collect data for the current sample\n",
        "        row = []\n",
        "\n",
        "        for bus in bus_ids:\n",
        "            # Extract P and Q values for the bus (PQ buses only)\n",
        "            if bus in net.load['bus'].values:\n",
        "                p_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'p_mw'].sum()\n",
        "                q_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'q_mvar'].sum()\n",
        "            else:\n",
        "                p_load, q_load = 0, 0\n",
        "\n",
        "            # Extract V (voltage magnitude) and d (voltage angle)\n",
        "            v_mag = net.res_bus.at[bus, 'vm_pu']\n",
        "            v_ang = net.res_bus.at[bus, 'va_degree']\n",
        "\n",
        "            # Append data to the row in the specified format\n",
        "            row.extend([p_load, q_load, v_mag, v_ang])\n",
        "\n",
        "        # Add the row to the dataset\n",
        "        data.append(row)\n",
        "\n",
        "    # Create a DataFrame and add headers in the requested format\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "    df.insert(0, \"Data\", [f\"Data {i + 1}\" for i in range(len(df))])\n",
        "    df.insert(0, \"Dataset\", [f\"PF Dataset_{dataset_n}\"] + [\"\"] * (len(df) - 1))\n",
        "\n",
        "    # Save the DataFrame to Excel\n",
        "    output_filename = os.path.join(output_folder, f\"PF_Dataset_{dataset_n}.xlsx\")\n",
        "    df.to_excel(output_filename, index=False)\n",
        "    print(f\"Dataset {dataset_n} saved to {output_filename}\")\n",
        "\n",
        "print(\"All datasets generated successfully.\")\n"
      ],
      "metadata": {
        "id": "x9C1EbHpyr6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **14 Bus Generator Limits**\n",
        "\n",
        " Generated Active and Reactive Power (P and Q) should be bounded by their maximum and minimum capability for each bus.\n",
        "\n",
        " Otherwise the OPF will not converge for the network."
      ],
      "metadata": {
        "id": "_-ZK1sF3yvm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for cleaner output (optional)\n",
        "import pandas as pd\n",
        "\n",
        "# generator bus information\n",
        "gen_buses = net.gen['bus'].values  # The bus indices with generators\n",
        "p_gen = net.res_gen['p_mw'].values\n",
        "q_gen = net.res_gen['q_mvar'].values\n",
        "\n",
        "# detailed information for each generator\n",
        "print(\"Generator Information:\")\n",
        "for i, bus in enumerate(gen_buses):\n",
        "    p_max = net.gen.at[i, 'max_p_mw'] if 'max_p_mw' in net.gen.columns else \"N/A\"\n",
        "    q_max = net.gen.at[i, 'max_q_mvar'] if 'max_q_mvar' in net.gen.columns else \"N/A\"\n",
        "    print(f\"Bus {bus} | Active Power (P_gen): {p_gen[i]:.2f} MW | Reactive Power (Q_gen): {q_gen[i]:.2f} MVar | P_max: {p_max} MW | Q_max: {q_max} MVar\")\n",
        "\n",
        "print(\"\\nFull Generator DataFrame:\")\n",
        "print(net.gen)\n"
      ],
      "metadata": {
        "id": "qmYYKj7wyx1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize lists to track generator outputs\n",
        "p_gen_list = []\n",
        "q_gen_list = []\n",
        "\n",
        "# Run power flow and log generator outputs for multiple test cases\n",
        "for i in range(10):  # 10 datasets\n",
        "    try:\n",
        "        pp.runpp(net, algorithm='nr', max_iteration=20)\n",
        "\n",
        "        # Get generator active and reactive power outputs\n",
        "        p_gen = net.res_gen['p_mw'].values\n",
        "        q_gen = net.res_gen['q_mvar'].values\n",
        "\n",
        "        # Log the generator outputs\n",
        "        p_gen_list.append(p_gen)\n",
        "        q_gen_list.append(q_gen)\n",
        "\n",
        "        print(f\"Test Case {i + 1}:\")\n",
        "        print(\"Active Power (P_gen):\", p_gen)\n",
        "        print(\"Reactive Power (Q_gen):\", q_gen)\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "    except pp.LoadflowNotConverged:\n",
        "        print(f\"Load flow did not converge for Test Case {i + 1}, skipping...\")\n",
        "        continue\n",
        "\n",
        "# Convert to DataFrame for easier comparison\n",
        "p_gen_df = pd.DataFrame(p_gen_list, columns=[f\"P_gen_{i}\" for i in range(len(p_gen))])\n",
        "q_gen_df = pd.DataFrame(q_gen_list, columns=[f\"Q_gen_{i}\" for i in range(len(q_gen))])\n",
        "\n",
        "# Save the results to Excel for further analysis\n",
        "p_gen_df.to_excel(\"P_gen_changes.xlsx\", index=False)\n",
        "q_gen_df.to_excel(\"Q_gen_changes.xlsx\", index=False)\n",
        "\n",
        "print(\"Generator outputs logged and saved to 'P_gen_changes.xlsx' and 'Q_gen_changes.xlsx'.\")\n"
      ],
      "metadata": {
        "id": "JT6iAxFEyz3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IEEE 30 Bus DataSet Generation**\n",
        "\n",
        "It Contains 30 buses, 6 generators, 21 loads, and 41 branches.\n",
        "\n",
        "A classic test case for load flow and optimal power flow (OPF) studies.\n"
      ],
      "metadata": {
        "id": "6_lpkv2gTeoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandapower"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tKJsBPkTioB",
        "outputId": "1b70a494-0874-499e-ba18-ddf8f0f81fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandapower in /usr/local/lib/python3.10/dist-packages (2.14.11)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (2.2.2)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from pandapower) (3.4.2)\n",
            "Requirement already satisfied: scipy<1.14 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pandapower) (24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pandapower) (4.66.6)\n",
            "Requirement already satisfied: deepdiff in /usr/local/lib/python3.10/dist-packages (from pandapower) (8.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: orderly-set==5.2.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff->pandapower) (5.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->pandapower) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Create the output folder\n",
        "output_folder = \"datasets_30Bus\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Create the 30-bus test system using pandapower\n",
        "net = nw.case30()\n",
        "\n",
        "# Number of datasets and samples per dataset\n",
        "num_datasets = 10\n",
        "samples_per_dataset = 2000\n",
        "variation_range = 0.4  # ±40% random load variation\n",
        "\n",
        "# columns for the output Excel file\n",
        "bus_ids = net.bus.index\n",
        "columns = []\n",
        "\n",
        "# column names based on dataset format\n",
        "for bus in bus_ids:\n",
        "    columns.extend([f\"P_{bus + 1} (PQ)\", f\"Q_{bus + 1} (PQ)\", f\"V_{bus + 1}\", f\"d_{bus + 1}\"])\n",
        "\n",
        "# Store original load values for resetting\n",
        "original_p_values = net.load['p_mw'].copy()\n",
        "original_q_values = net.load['q_mvar'].copy()\n",
        "\n",
        "# Generate the datasets\n",
        "for dataset_n in range(1, num_datasets + 1):\n",
        "    print(f\"Generating dataset {dataset_n}...\")\n",
        "\n",
        "    data = []\n",
        "\n",
        "    # initial power flow to stabilize the network\n",
        "    #try:\n",
        "    #    pp.runpp(net, algorithm='nr', max_iteration=20)\n",
        "    #except pp.LoadflowNotConverged:\n",
        "    #    print(f\"Initial load flow did not converge for dataset {dataset_n}, skipping this dataset.\")\n",
        "    #    continue\n",
        "\n",
        "    for sample in range(1, samples_per_dataset + 1):\n",
        "        # Reset the load values to the original values\n",
        "        net.load['p_mw'] = original_p_values\n",
        "        net.load['q_mvar'] = original_q_values\n",
        "\n",
        "        # Apply random variation based on the original values\n",
        "        for load in net.load.index:\n",
        "            net.load.at[load, 'p_mw'] = original_p_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "            net.load.at[load, 'q_mvar'] = original_q_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "\n",
        "        # Run AC power flow with Newton-Raphson algorithm\n",
        "        try:\n",
        "            pp.runpp(net, algorithm='nr', max_iteration=20)\n",
        "        except pp.LoadflowNotConverged:\n",
        "            print(f\"Load flow did not converge for sample {sample} in dataset {dataset_n}, skipping this sample.\")\n",
        "            continue\n",
        "\n",
        "        # Collect data for the current sample\n",
        "        row = []\n",
        "\n",
        "        for bus in bus_ids:\n",
        "            # Extract P and Q values for the bus (PQ buses only)\n",
        "            if bus in net.load['bus'].values:\n",
        "                p_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'p_mw'].sum()\n",
        "                q_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'q_mvar'].sum()\n",
        "            else:\n",
        "                p_load, q_load = 0, 0\n",
        "\n",
        "            # Extract V (voltage magnitude) and d (voltage angle)\n",
        "            v_mag = net.res_bus.at[bus, 'vm_pu']\n",
        "            v_ang = net.res_bus.at[bus, 'va_degree']\n",
        "\n",
        "            # Append data to the row in the specified format\n",
        "            row.extend([p_load, q_load, v_mag, v_ang])\n",
        "\n",
        "        # Add the row to the dataset\n",
        "        data.append(row)\n",
        "\n",
        "    # Create a DataFrame and add headers in the requested format\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "    df.insert(0, \"Data\", [f\"Data {i + 1}\" for i in range(len(df))])\n",
        "    df.insert(0, \"Dataset\", [f\"PF Dataset_{dataset_n}\"] + [\"\"] * (len(df) - 1))\n",
        "\n",
        "    # Save the DataFrame to Excel\n",
        "    output_filename = os.path.join(output_folder, f\"PF_Dataset_{dataset_n}.xlsx\")\n",
        "    df.to_excel(output_filename, index=False)\n",
        "    print(f\"Dataset {dataset_n} saved to {output_filename}\")\n",
        "\n",
        "print(\"All datasets generated successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93oaOPiuTp0B",
        "outputId": "738cff88-02e6-43c0-9e48-5dec8aee9c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dataset 1...\n",
            "Dataset 1 saved to datasets/PF_Dataset_1.xlsx\n",
            "Generating dataset 2...\n",
            "Dataset 2 saved to datasets/PF_Dataset_2.xlsx\n",
            "Generating dataset 3...\n",
            "Dataset 3 saved to datasets/PF_Dataset_3.xlsx\n",
            "Generating dataset 4...\n",
            "Dataset 4 saved to datasets/PF_Dataset_4.xlsx\n",
            "Generating dataset 5...\n",
            "Dataset 5 saved to datasets/PF_Dataset_5.xlsx\n",
            "Generating dataset 6...\n",
            "Dataset 6 saved to datasets/PF_Dataset_6.xlsx\n",
            "Generating dataset 7...\n",
            "Dataset 7 saved to datasets/PF_Dataset_7.xlsx\n",
            "Generating dataset 8...\n",
            "Dataset 8 saved to datasets/PF_Dataset_8.xlsx\n",
            "Generating dataset 9...\n",
            "Dataset 9 saved to datasets/PF_Dataset_9.xlsx\n",
            "Generating dataset 10...\n",
            "Dataset 10 saved to datasets/PF_Dataset_10.xlsx\n",
            "All datasets generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **30 Bus Generator Limits**\n",
        "\n",
        " Generated Active and Reactive Power (P and Q) should be bounded by their maximum and minimum capability for each bus.\n",
        "\n",
        " Otherwise the OPF will not converge for the network."
      ],
      "metadata": {
        "id": "AeQ0MuKV4_o0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for cleaner output (optional)\n",
        "import pandas as pd\n",
        "\n",
        "# generator bus information\n",
        "gen_buses = net.gen['bus'].values  # The bus indices with generators\n",
        "p_gen = net.res_gen['p_mw'].values\n",
        "q_gen = net.res_gen['q_mvar'].values\n",
        "\n",
        "# detailed information for each generator\n",
        "print(\"Generator Information:\")\n",
        "for i, bus in enumerate(gen_buses):\n",
        "    p_max = net.gen.at[i, 'max_p_mw'] if 'max_p_mw' in net.gen.columns else \"N/A\"\n",
        "    q_max = net.gen.at[i, 'max_q_mvar'] if 'max_q_mvar' in net.gen.columns else \"N/A\"\n",
        "    print(f\"Bus {bus} | Active Power (P_gen): {p_gen[i]:.2f} MW | Reactive Power (Q_gen): {q_gen[i]:.2f} MVar | P_max: {p_max} MW | Q_max: {q_max} MVar\")\n",
        "\n",
        "print(\"\\nFull Generator DataFrame:\")\n",
        "print(net.gen)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYArq7UJuCfS",
        "outputId": "6b93e851-7870-483a-f48e-cc3f032748a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Information:\n",
            "Bus 1 | Active Power (P_gen): 60.97 MW | Reactive Power (Q_gen): 37.38 MVar | P_max: 80.0 MW | Q_max: 60.0 MVar\n",
            "Bus 21 | Active Power (P_gen): 21.59 MW | Reactive Power (Q_gen): 40.45 MVar | P_max: 50.0 MW | Q_max: 62.5 MVar\n",
            "Bus 26 | Active Power (P_gen): 26.91 MW | Reactive Power (Q_gen): 11.79 MVar | P_max: 55.0 MW | Q_max: 48.7 MVar\n",
            "Bus 22 | Active Power (P_gen): 19.20 MW | Reactive Power (Q_gen): 7.34 MVar | P_max: 30.0 MW | Q_max: 40.0 MVar\n",
            "Bus 12 | Active Power (P_gen): 37.00 MW | Reactive Power (Q_gen): 10.96 MVar | P_max: 40.0 MW | Q_max: 44.7 MVar\n",
            "\n",
            "Full Generator DataFrame:\n",
            "   name  bus   p_mw  vm_pu  sn_mva  min_q_mvar  max_q_mvar  scaling  slack  \\\n",
            "0  None    1  60.97    1.0     NaN       -20.0        60.0      1.0  False   \n",
            "1  None   21  21.59    1.0     NaN       -15.0        62.5      1.0  False   \n",
            "2  None   26  26.91    1.0     NaN       -15.0        48.7      1.0  False   \n",
            "3  None   22  19.20    1.0     NaN       -10.0        40.0      1.0  False   \n",
            "4  None   12  37.00    1.0     NaN       -15.0        44.7      1.0  False   \n",
            "\n",
            "   in_service  slack_weight  type  controllable  max_p_mw  min_p_mw  \n",
            "0        True           0.0  None          True      80.0       0.0  \n",
            "1        True           0.0  None          True      50.0       0.0  \n",
            "2        True           0.0  None          True      55.0       0.0  \n",
            "3        True           0.0  None          True      30.0       0.0  \n",
            "4        True           0.0  None          True      40.0       0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialize lists to track generator outputs\n",
        "p_gen_list = []\n",
        "q_gen_list = []\n",
        "\n",
        "# Run power flow and log generator outputs for multiple test cases\n",
        "for i in range(10):  # 10 datasets\n",
        "    try:\n",
        "        pp.runpp(net, algorithm='nr', max_iteration=20)\n",
        "\n",
        "        # Get generator active and reactive power outputs\n",
        "        p_gen = net.res_gen['p_mw'].values\n",
        "        q_gen = net.res_gen['q_mvar'].values\n",
        "\n",
        "        # Log the generator outputs\n",
        "        p_gen_list.append(p_gen)\n",
        "        q_gen_list.append(q_gen)\n",
        "\n",
        "        print(f\"Test Case {i + 1}:\")\n",
        "        print(\"Active Power (P_gen):\", p_gen)\n",
        "        print(\"Reactive Power (Q_gen):\", q_gen)\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "    except pp.LoadflowNotConverged:\n",
        "        print(f\"Load flow did not converge for Test Case {i + 1}, skipping...\")\n",
        "        continue\n",
        "\n",
        "# Convert to DataFrame for easier comparison\n",
        "p_gen_df = pd.DataFrame(p_gen_list, columns=[f\"P_gen_{i}\" for i in range(len(p_gen))])\n",
        "q_gen_df = pd.DataFrame(q_gen_list, columns=[f\"Q_gen_{i}\" for i in range(len(q_gen))])\n",
        "\n",
        "# Save the results to Excel for further analysis\n",
        "p_gen_df.to_excel(\"P_gen_changes.xlsx\", index=False)\n",
        "q_gen_df.to_excel(\"Q_gen_changes.xlsx\", index=False)\n",
        "\n",
        "print(\"Generator outputs logged and saved to 'P_gen_changes.xlsx' and 'Q_gen_changes.xlsx'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vn0PtHlwYKz",
        "outputId": "67734627-7d5e-429b-9e22-3b602d611c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Case 1:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 2:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 3:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 4:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 5:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 6:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 7:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 8:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 9:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 10:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 11:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 12:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 13:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 14:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 15:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 16:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 17:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 18:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 19:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 20:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 21:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 22:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 23:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 24:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 25:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 26:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 27:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 28:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 29:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 30:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 31:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 32:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 33:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 34:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 35:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 36:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 37:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 38:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 39:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 40:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 41:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 42:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 43:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 44:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 45:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 46:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 47:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 48:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 49:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 50:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 51:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 52:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 53:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 54:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 55:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 56:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 57:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 58:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 59:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 60:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 61:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 62:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 63:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 64:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 65:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 66:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 67:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 68:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 69:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 70:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 71:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 72:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 73:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 74:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 75:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 76:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 77:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 78:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 79:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 80:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 81:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 82:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 83:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 84:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 85:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 86:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 87:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 88:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 89:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 90:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 91:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 92:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 93:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 94:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 95:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 96:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 97:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 98:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 99:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 100:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 101:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Test Case 102:\n",
            "Active Power (P_gen): [60.97 21.59 26.91 19.2  37.  ]\n",
            "Reactive Power (Q_gen): [37.38115789 40.44738087 11.79165197  7.33633467 10.95915525]\n",
            "========================================\n",
            "Generator outputs logged and saved to 'P_gen_changes.xlsx' and 'Q_gen_changes.xlsx'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **IEEE 57 Bus DataSet Generation**\n",
        "\n",
        "Contains 57 buses, 7 generators, 42 loads, and 80 branches.\n",
        "\n",
        "Commonly used for testing load flow and contingency analysis."
      ],
      "metadata": {
        "id": "ySJfKeBtCDkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandapower"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHOCYB1bOk0i",
        "outputId": "066f7775-07a2-47ca-8d12-3baa89ea6f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandapower in /usr/local/lib/python3.10/dist-packages (2.14.11)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (2.2.2)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.10/dist-packages (from pandapower) (3.4.2)\n",
            "Requirement already satisfied: scipy<1.14 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from pandapower) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pandapower) (24.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pandapower) (4.66.6)\n",
            "Requirement already satisfied: deepdiff in /usr/local/lib/python3.10/dist-packages (from pandapower) (8.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->pandapower) (2024.2)\n",
            "Requirement already satisfied: orderly-set==5.2.2 in /usr/local/lib/python3.10/dist-packages (from deepdiff->pandapower) (5.2.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->pandapower) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandapower as pp\n",
        "import pandapower.networks as nw\n",
        "import pandas as pd\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Create the output folder\n",
        "output_folder = \"datasets_57Bus\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Load the 57-bus test system using pandapower\n",
        "net = nw.case57()\n",
        "\n",
        "# Number of datasets and samples per dataset\n",
        "num_datasets = 10\n",
        "samples_per_dataset = 2000\n",
        "variation_range = 0.4  # ±40% random load variation\n",
        "\n",
        "# Define the columns for the output Excel file\n",
        "bus_ids = net.bus.index\n",
        "columns = []\n",
        "\n",
        "# Create column names based on dataset format\n",
        "for bus in bus_ids:\n",
        "    columns.extend([f\"P_{bus + 1} (PQ)\", f\"Q_{bus + 1} (PQ)\", f\"V_{bus + 1}\", f\"d_{bus + 1}\"])\n",
        "\n",
        "# Store original load values for resetting\n",
        "original_p_values = net.load['p_mw'].copy()\n",
        "original_q_values = net.load['q_mvar'].copy()\n",
        "\n",
        "# Generate the datasets\n",
        "for dataset_n in range(1, num_datasets + 1):\n",
        "    print(f\"Generating dataset {dataset_n}...\")\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for sample in range(1, samples_per_dataset + 1):\n",
        "        # Reset the load values to the original values\n",
        "        net.load['p_mw'] = original_p_values\n",
        "        net.load['q_mvar'] = original_q_values\n",
        "\n",
        "        # Apply random variation based on the original values\n",
        "        for load in net.load.index:\n",
        "            net.load.at[load, 'p_mw'] = original_p_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "            net.load.at[load, 'q_mvar'] = original_q_values[load] * (1 + random.uniform(-variation_range, variation_range))\n",
        "\n",
        "        # Run AC power flow with Newton-Raphson algorithm\n",
        "        try:\n",
        "            pp.runpp(net, algorithm='nr', max_iteration=30)\n",
        "        except pp.LoadflowNotConverged:\n",
        "            print(f\"Load flow did not converge for sample {sample} in dataset {dataset_n}, skipping this sample.\")\n",
        "            continue\n",
        "\n",
        "        # Collect data for the current sample\n",
        "        row = []\n",
        "\n",
        "        for bus in bus_ids:\n",
        "            # Extract P and Q values for the bus (PQ buses only)\n",
        "            if bus in net.load['bus'].values:\n",
        "                p_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'p_mw'].sum()\n",
        "                q_load = net.res_load.loc[net.load[net.load['bus'] == bus].index, 'q_mvar'].sum()\n",
        "            else:\n",
        "                p_load, q_load = 0, 0\n",
        "\n",
        "            # Extract V (voltage magnitude) and d (voltage angle)\n",
        "            v_mag = net.res_bus.at[bus, 'vm_pu']\n",
        "            v_ang = net.res_bus.at[bus, 'va_degree']\n",
        "\n",
        "            # Append data to the row in the specified format\n",
        "            row.extend([p_load, q_load, v_mag, v_ang])\n",
        "\n",
        "        # Add the row to the dataset\n",
        "        data.append(row)\n",
        "\n",
        "    # Create a DataFrame and add headers in the requested format\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    df.insert(0, \"Data\", [f\"Data {i + 1}\" for i in range(len(df))])\n",
        "    df.insert(0, \"Dataset\", [f\"PF Dataset_{dataset_n}\"] + [\"\"] * (len(df) - 1))\n",
        "\n",
        "    # Save the DataFrame to Excel\n",
        "    output_filename = os.path.join(output_folder, f\"PF_Dataset_{dataset_n}.xlsx\")\n",
        "    df.to_excel(output_filename, index=False)\n",
        "    print(f\"Dataset {dataset_n} saved to {output_filename}\")\n",
        "\n",
        "print(\"All datasets generated successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKT0Xj1IOcrf",
        "outputId": "87bdc83d-c839-4026-bc85-e3909a108110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dataset 1...\n",
            "Dataset 1 saved to datasets_57Bus/PF_Dataset_1.xlsx\n",
            "Generating dataset 2...\n",
            "Dataset 2 saved to datasets_57Bus/PF_Dataset_2.xlsx\n",
            "Generating dataset 3...\n",
            "Dataset 3 saved to datasets_57Bus/PF_Dataset_3.xlsx\n",
            "Generating dataset 4...\n",
            "Dataset 4 saved to datasets_57Bus/PF_Dataset_4.xlsx\n",
            "Generating dataset 5...\n",
            "Dataset 5 saved to datasets_57Bus/PF_Dataset_5.xlsx\n",
            "Generating dataset 6...\n",
            "Dataset 6 saved to datasets_57Bus/PF_Dataset_6.xlsx\n",
            "Generating dataset 7...\n",
            "Dataset 7 saved to datasets_57Bus/PF_Dataset_7.xlsx\n",
            "Generating dataset 8...\n",
            "Dataset 8 saved to datasets_57Bus/PF_Dataset_8.xlsx\n",
            "Generating dataset 9...\n",
            "Dataset 9 saved to datasets_57Bus/PF_Dataset_9.xlsx\n",
            "Generating dataset 10...\n",
            "Dataset 10 saved to datasets_57Bus/PF_Dataset_10.xlsx\n",
            "All datasets generated successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**57 Bus Generator Limits**\n",
        "\n",
        " Generated Active and Reactive Power (P and Q) should be bounded by their maximum and minimum capability for each bus.\n",
        "\n",
        " Otherwise the OPF will not converge for the network."
      ],
      "metadata": {
        "id": "0my7n9SIPNvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import pandas for cleaner output\n",
        "import pandas as pd\n",
        "\n",
        "# generator bus information\n",
        "gen_buses = net.gen['bus'].values  # The bus indices with generators\n",
        "p_gen = net.res_gen['p_mw'].values\n",
        "q_gen = net.res_gen['q_mvar'].values\n",
        "\n",
        "# detailed information for each generator\n",
        "print(\"Generator Information:\")\n",
        "for i, bus in enumerate(gen_buses):\n",
        "    p_max = net.gen.at[i, 'max_p_mw'] if 'max_p_mw' in net.gen.columns else \"N/A\"\n",
        "    q_max = net.gen.at[i, 'max_q_mvar'] if 'max_q_mvar' in net.gen.columns else \"N/A\"\n",
        "    print(f\"Bus {bus} | Active Power (P_gen): {p_gen[i]:.2f} MW | Reactive Power (Q_gen): {q_gen[i]:.2f} MVar | P_max: {p_max} MW | Q_max: {q_max} MVar\")\n",
        "\n",
        "print(\"\\nFull Generator DataFrame:\")\n",
        "print(net.gen)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0XK26Y4CDUc",
        "outputId": "339174ab-6db4-4976-9353-ded89e057daf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Information:\n",
            "Bus 1 | Active Power (P_gen): 0.00 MW | Reactive Power (Q_gen): 29.40 MVar | P_max: 100.0 MW | Q_max: 50.0 MVar\n",
            "Bus 2 | Active Power (P_gen): 40.00 MW | Reactive Power (Q_gen): -9.46 MVar | P_max: 140.0 MW | Q_max: 60.0 MVar\n",
            "Bus 5 | Active Power (P_gen): 0.00 MW | Reactive Power (Q_gen): 12.11 MVar | P_max: 100.0 MW | Q_max: 25.0 MVar\n",
            "Bus 7 | Active Power (P_gen): 450.00 MW | Reactive Power (Q_gen): 74.54 MVar | P_max: 550.0 MW | Q_max: 200.0 MVar\n",
            "Bus 8 | Active Power (P_gen): 0.00 MW | Reactive Power (Q_gen): -21.24 MVar | P_max: 100.0 MW | Q_max: 9.0 MVar\n",
            "Bus 11 | Active Power (P_gen): 310.00 MW | Reactive Power (Q_gen): 109.47 MVar | P_max: 410.0 MW | Q_max: 155.0 MVar\n",
            "\n",
            "Full Generator DataFrame:\n",
            "   name  bus   p_mw  vm_pu  sn_mva  min_q_mvar  max_q_mvar  scaling  slack  \\\n",
            "0  None    1    0.0  1.010     NaN       -17.0        50.0      1.0  False   \n",
            "1  None    2   40.0  0.985     NaN       -10.0        60.0      1.0  False   \n",
            "2  None    5    0.0  0.980     NaN        -8.0        25.0      1.0  False   \n",
            "3  None    7  450.0  1.005     NaN      -140.0       200.0      1.0  False   \n",
            "4  None    8    0.0  0.980     NaN        -3.0         9.0      1.0  False   \n",
            "5  None   11  310.0  1.015     NaN      -150.0       155.0      1.0  False   \n",
            "\n",
            "   in_service  slack_weight  type  controllable  max_p_mw  min_p_mw  \n",
            "0        True           0.0  None          True     100.0       0.0  \n",
            "1        True           0.0  None          True     140.0       0.0  \n",
            "2        True           0.0  None          True     100.0       0.0  \n",
            "3        True           0.0  None          True     550.0       0.0  \n",
            "4        True           0.0  None          True     100.0       0.0  \n",
            "5        True           0.0  None          True     410.0       0.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Histogram**\n",
        "\n",
        "Histograms is used to see which architecture has a better and more consistent performance (narrower, left-skewed distribution)\n",
        "\n",
        "Histograms is used to compare:\n",
        "\n",
        "1.   Different bus systems (e.g., 14-bus vs. 30-bus vs. 57-bus) using the same GNN architecture.\n",
        "\n",
        "2.   It can also be used to compare different GNN architectures for a same network to see the effect\n",
        "\n",
        "\n",
        "**Histogram Goal:**\n",
        "\n",
        "\n",
        "\n",
        "*   Mean and Median Values: Lower mean and median values indicate better performance.\n",
        "\n",
        "*   Spread of Distribution: A narrower histogram indicates more consistent performance (less variance).\n",
        "\n",
        "*   Left-Skewed Distribution: A left-skewed histogram (with most losses near zero) indicates good generalization.\n",
        "\n"
      ],
      "metadata": {
        "id": "pmyF3Eb1KKQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the test loss data from each Excel file\n",
        "bus_14_loss_data = pd.read_excel('[14 bus] Test Losses.xlsx').values.flatten()\n",
        "bus_30_loss_data = pd.read_excel('[30 bus] Test Losses.xlsx').values.flatten()\n",
        "\n",
        "# mean and median for each bus system\n",
        "mean_14 = np.mean(bus_14_loss_data)\n",
        "median_14 = np.median(bus_14_loss_data)\n",
        "\n",
        "mean_30 = np.mean(bus_30_loss_data)\n",
        "median_30 = np.median(bus_30_loss_data)\n",
        "\n",
        "\n",
        "# Print the statistics\n",
        "print(f\"14-bus system - Mean: {mean_14:.5f}, Median: {median_14:.5f}\")\n",
        "print(f\"30-bus system - Mean: {mean_30:.5f}, Median: {median_30:.5f}\")\n",
        "\n",
        "# histogram plotting parameters\n",
        "kwargs = dict(histtype='stepfilled', alpha=0.5, density=True, bins=20)\n",
        "\n",
        "# labels for the histograms\n",
        "label_14 = f\"14-bus, Mean: {mean_14:.5f}, Median: {median_14:.5f}\"\n",
        "label_30 = f\"30-bus, Mean: {mean_30:.5f}, Median: {median_30:.5f}\"\n",
        "\n",
        "# Plot the histograms\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(bus_14_loss_data, label=label_14, **kwargs)\n",
        "plt.hist(bus_30_loss_data, label=label_30, **kwargs)\n",
        "\n",
        "# plot details\n",
        "plt.title('Comparison of Test Loss Distributions Across Different Test Case Networks')\n",
        "plt.xlabel('Test Loss (MSE or NRMSE)')\n",
        "plt.ylabel('Density')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Qc_Y31iUKMWJ",
        "outputId": "2f667993-768e-4851-f639-55e1b9b9912a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '[14 bus] Test Losses.xlsx'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-bf62279d52f2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Load the test loss data from each Excel file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbus_14_loss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[14 bus] Test Losses.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbus_30_loss_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[30 bus] Test Losses.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         io = ExcelFile(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1548\u001b[0m                 \u001b[0mext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xls\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1550\u001b[0;31m                 ext = inspect_excel_format(\n\u001b[0m\u001b[1;32m   1551\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m     with get_handle(\n\u001b[0m\u001b[1;32m   1403\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m     ) as handle:\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '[14 bus] Test Losses.xlsx'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Wqd4N8uM6os"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}